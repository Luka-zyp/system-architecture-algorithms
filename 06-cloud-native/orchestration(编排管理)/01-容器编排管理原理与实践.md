# 容器编排管理原理与实践

## 概述

容器编排系统是现代云原生应用管理的核心平台，负责自动化容器的部署、扩展、管理和调度。编排系统通过统一的接口和策略，将分散的容器实例整合为有机的应用整体，提供服务发现、负载均衡、配置管理、健康检查、自我修复等关键能力，是构建弹性、可扩展云原生架构的基础设施。

## 容器编排核心架构

### Kubernetes架构原理

**控制平面与工作节点**：

```java
// Kubernetes API Server核心实现
public class KubernetesApiServer {
    private final EtcdClient etcdClient;
    private final AdmissionController admissionController;
    private final AuthenticationManager authManager;
    private final AuthorizationManager authzManager;
    private final RequestRateLimiter rateLimiter;
    private final EventRecorder eventRecorder;
    
    public KubernetesApiServer() {
        this.etcdClient = new EtcdClient("http://etcd-cluster:2379");
        this.admissionController = new AdmissionController();
        this.authManager = new AuthenticationManager();
        this.authzManager = new AuthorizationManager();
        this.rateLimiter = new RequestRateLimiter();
        this.eventRecorder = new EventRecorder();
    }
    
    // 处理Pod创建请求
    public AdmissionResponse createPod(CreatePodRequest request) {
        try {
            // 1. 身份认证
            User user = authManager.authenticate(request.getUserInfo());
            if (user == null) {
                return AdmissionResponse.denied("Authentication failed");
            }
            
            // 2. 权限检查
            if (!authzManager.authorize(user, "create", "pods", request.getNamespace())) {
                return AdmissionResponse.denied("Authorization failed");
            }
            
            // 3. 限流检查
            if (!rateLimiter.allowRequest(user, request)) {
                return AdmissionResponse.denied("Rate limit exceeded");
            }
            
            // 4. Admission控制
            AdmissionRequest admissionRequest = convertToAdmissionRequest(request);
            AdmissionResponse admissionResponse = admissionController.process(admissionRequest);
            
            if (admissionResponse.isDenied()) {
                eventRecorder.recordEvent(
                    request.getPod(),
                    EventType.WARNING,
                    "FailedAdmission",
                    admissionResponse.getMessage()
                );
                return admissionResponse;
            }
            
            // 5. 保存到etcd
            Pod pod = request.getPod();
            pod.setStatus(PodStatus.PENDING);
            pod.setCreationTimestamp(Instant.now());
            
            String podKey = "/registry/pods/" + request.getNamespace() + "/" + pod.getMetadata().getName();
            etcdClient.put(podKey, serializePod(pod));
            
            // 6. 触发调度
            scheduler.schedulePod(pod);
            
            // 7. 记录事件
            eventRecorder.recordEvent(
                pod,
                EventType.NORMAL,
                "Scheduled",
                "Successfully assigned pod to node"
            );
            
            return AdmissionResponse.allowed();
            
        } catch (Exception e) {
            logger.error("Failed to create pod", e);
            return AdmissionResponse.denied("Internal server error");
        }
    }
    
    // 处理Deployment扩缩容请求
    public AdmissionResponse scaleDeployment(ScaleDeploymentRequest request) {
        try {
            // 1. 验证请求
            Deployment deployment = getDeployment(request.getNamespace(), request.getName());
            if (deployment == null) {
                return AdmissionResponse.denied("Deployment not found");
            }
            
            // 2. 扩缩容策略检查
            ScalingPolicy policy = deployment.getSpec().getScalingPolicy();
            if (!validateScalingRequest(request, policy)) {
                return AdmissionResponse.denied("Scaling violates policy constraints");
            }
            
            // 3. 执行扩缩容
            ReplicaSet newReplicaSet = createReplicaSetForScaling(deployment, request.getReplicas());
            scaleReplicaSet(newReplicaSet, request.getReplicas());
            
            // 4. 更新Deployment状态
            deployment.getStatus().setReplicas(request.getReplicas());
            deployment.getStatus().setReadyReplicas(calculateReadyReplicas(newReplicaSet));
            deployment.getStatus().setUpdatedReplicas(request.getReplicas());
            
            String deploymentKey = "/registry/deployments/" + request.getNamespace() + "/" + request.getName();
            etcdClient.put(deploymentKey, serializeDeployment(deployment));
            
            return AdmissionResponse.allowed();
            
        } catch (Exception e) {
            logger.error("Failed to scale deployment", e);
            return AdmissionResponse.denied("Internal server error");
        }
    }
    
    private boolean validateScalingRequest(ScaleDeploymentRequest request, ScalingPolicy policy) {
        if (policy == null) {
            return true;
        }
        
        // 检查最大最小副本数限制
        int currentReplicas = policy.getCurrentReplicas();
        int requestedReplicas = request.getReplicas();
        
        if (requestedReplicas < policy.getMinReplicas()) {
            return false;
        }
        
        if (policy.getMaxReplicas() != null && requestedReplicas > policy.getMaxReplicas()) {
            return false;
        }
        
        // 检查扩缩容速率限制
        int maxChange = policy.getMaxChangePerInterval();
        if (maxChange > 0) {
            int change = Math.abs(requestedReplicas - currentReplicas);
            if (change > maxChange) {
                return false;
            }
        }
        
        return true;
    }
}

// 容器调度器核心实现
public class KubernetesScheduler {
    private final Queue<Pod> schedulingQueue;
    private final Map<String, Node> nodes;
    private final ScoringAlgorithm scoringAlgorithm;
    private final FilterAlgorithm filterAlgorithm;
    private final BindingController bindingController;
    
    public KubernetesScheduler() {
        this.schedulingQueue = new PriorityQueue<>(new PodPriorityComparator());
        this.nodes = new ConcurrentHashMap<>();
        this.scoringAlgorithm = new ScoringAlgorithm();
        this.filterAlgorithm = new FilterAlgorithm();
        this.bindingController = new BindingController();
        this.scheduledExecutor = Executors.newScheduledThreadPool(4);
        
        // 启动调度循环
        scheduledExecutor.scheduleAtFixedRate(this::schedulingLoop, 100, 100, TimeUnit.MILLISECONDS);
    }
    
    public void schedulePod(Pod pod) {
        if (isPodAlreadyScheduled(pod)) {
            return;
        }
        
        schedulingQueue.offer(pod);
        logger.info("Pod {} added to scheduling queue", pod.getMetadata().getName());
    }
    
    private void schedulingLoop() {
        Pod pod = schedulingQueue.poll();
        if (pod == null) {
            return;
        }
        
        try {
            schedulePodInternal(pod);
        } catch (Exception e) {
            logger.error("Failed to schedule pod", e);
            handleSchedulingFailure(pod, e);
        }
    }
    
    private void schedulePodInternal(Pod pod) {
        // 1. 获取候选节点列表
        List<Node> candidateNodes = getCandidateNodes(pod);
        
        // 2. 过滤节点（Predicates）
        List<Node> feasibleNodes = filterAlgorithm.filter(candidateNodes, pod);
        
        if (feasibleNodes.isEmpty()) {
            handleSchedulingFailure(pod, new SchedulingException("No feasible nodes found"));
            return;
        }
        
        // 3. 节点评分（Priorities）
        Map<String, Double> nodeScores = scoringAlgorithm.score(feasibleNodes, pod);
        
        // 4. 选择最优节点
        String selectedNodeName = selectBestNode(nodeScores);
        Node selectedNode = nodes.get(selectedNodeName);
        
        // 5. 绑定Pod到节点
        bindPodToNode(pod, selectedNode);
        
        // 6. 更新Pod状态
        updatePodStatus(pod, selectedNode);
        
        // 7. 触发容器启动
        kubelet.startPod(pod);
        
        logger.info("Pod {} scheduled to node {}", 
            pod.getMetadata().getName(), selectedNodeName);
    }
    
    private List<Node> getCandidateNodes(Pod pod) {
        List<Node> candidates = new ArrayList<>();
        
        for (Node node : nodes.values()) {
            // 检查节点状态
            if (isNodeSchedulable(node) && !isNodeDrained(node)) {
                candidates.add(node);
            }
        }
        
        return candidates;
    }
    
    // 过滤算法实现
    public static class FilterAlgorithm {
        
        public List<Node> filter(List<Node> nodes, Pod pod) {
            return nodes.stream()
                .filter(node -> satisfiesPredicates(node, pod))
                .collect(Collectors.toList());
        }
        
        private boolean satisfiesPredicates(Node node, Pod pod) {
            // 1. 资源可用性检查
            if (!checkResourceAvailability(node, pod)) {
                return false;
            }
            
            // 2. 亲和性/反亲和性检查
            if (!checkAffinityRules(node, pod)) {
                return false;
            }
            
            // 3. 污点和容忍检查
            if (!checkTaintsAndTolerations(node, pod)) {
                return false;
            }
            
            // 4. 节点选择器检查
            if (!checkNodeSelector(node, pod)) {
                return false;
            }
            
            // 5. 容器运行时检查
            if (!checkRuntimeCompatibility(node, pod)) {
                return false;
            }
            
            return true;
        }
        
        private boolean checkResourceAvailability(Node node, Pod pod) {
            NodeStatus status = node.getStatus();
            
            // 检查CPU资源
            double totalCpu = status.getAllocatableCpu().millis();
            double usedCpu = calculateUsedCpu(node);
            double podCpu = calculateRequiredCpu(pod);
            
            if (usedCpu + podCpu > totalCpu) {
                return false;
            }
            
            // 检查内存资源
            long totalMemory = status.getAllocatableMemory().getValue();
            long usedMemory = calculateUsedMemory(node);
            long podMemory = calculateRequiredMemory(pod);
            
            if (usedMemory + podMemory > totalMemory) {
                return false;
            }
            
            return true;
        }
        
        private boolean checkAffinityRules(Node node, Pod pod) {
            PodAffinityTerm affinity = pod.getSpec().getNodeAffinity();
            
            if (affinity == null) {
                return true;
            }
            
            // 节点亲和性检查
            NodeAffinityTerm nodeAffinity = affinity.getRequiredDuringSchedulingIgnoredDuringExecution();
            if (nodeAffinity != null) {
                return evaluateNodeAffinity(node, nodeAffinity);
            }
            
            return true;
        }
        
        private boolean checkTaintsAndTolerations(Node node, Pod pod) {
            List<Toleration> tolerations = pod.getSpec().getTolerations();
            if (tolerations.isEmpty()) {
                return true;
            }
            
            for (Taint taint : node.getSpec().getTaints()) {
                boolean hasMatchingToleration = tolerations.stream()
                    .anyMatch(toleration -> matchesTaint(toleration, taint));
                
                if (!hasMatchingToleration) {
                    return false;
                }
            }
            
            return true;
        }
    }
    
    // 评分算法实现
    public static class ScoringAlgorithm {
        
        public Map<String, Double> score(List<Node> nodes, Pod pod) {
            Map<String, Double> scores = new HashMap<>();
            
            for (Node node : nodes) {
                double score = calculateNodeScore(node, pod);
                scores.put(node.getMetadata().getName(), score);
            }
            
            // 归一化分数
            normalizeScores(scores);
            
            return scores;
        }
        
        private double calculateNodeScore(Node node, Pod pod) {
            double score = 0.0;
            
            // 1. 资源利用率评分
            score += calculateResourceUtilizationScore(node) * 0.4;
            
            // 2. 亲和性评分
            score += calculateAffinityScore(node, pod) * 0.3;
            
            // 3. 节点条件评分
            score += calculateNodeConditionScore(node) * 0.2;
            
            // 4. 拓扑分布评分
            score += calculateTopologyScore(node) * 0.1;
            
            return score;
        }
        
        private double calculateResourceUtilizationScore(Node node) {
            NodeStatus status = node.getStatus();
            
            // CPU利用率评分（利用率适中得分最高）
            double cpuUtilization = calculateCpuUtilization(node);
            double cpuScore = calculateOptimalUtilizationScore(cpuUtilization);
            
            // 内存利用率评分
            double memoryUtilization = calculateMemoryUtilization(node);
            double memoryScore = calculateOptimalUtilizationScore(memoryUtilization);
            
            return (cpuScore + memoryScore) / 2.0;
        }
        
        private double calculateOptimalUtilizationScore(double utilization) {
            // 最优利用率区间为50%-80%
            if (utilization >= 0.5 && utilization <= 0.8) {
                return 100.0;
            } else if (utilization < 0.5) {
                // 利用率不足，适当惩罚
                return 50.0 + (utilization * 100.0);
            } else {
                // 利用率过高，惩罚较重
                return 80.0 - ((utilization - 0.8) * 200.0);
            }
        }
        
        private double calculateAffinityScore(Node node, Pod pod) {
            // 这里实现亲和性相关的评分逻辑
            // 例如：偏好同机房的节点、负载较轻的节点等
            return 50.0; // 默认分数
        }
        
        private double calculateNodeConditionScore(Node node) {
            double score = 100.0;
            
            // 节点状态检查
            for (NodeCondition condition : node.getStatus().getConditions()) {
                if (NodeConditionType.READY.equals(condition.getType())) {
                    if (ConditionStatus.TRUE.equals(condition.getStatus())) {
                        score += 0.0;
                    } else {
                        score = 0.0; // 不准备好的节点得0分
                    }
                }
            }
            
            // 内存压力检查
            for (NodeCondition condition : node.getStatus().getConditions()) {
                if (NodeConditionType.MEMORY_PRESSURE.equals(condition.getType()) &&
                    ConditionStatus.TRUE.equals(condition.getStatus())) {
                    score -= 20.0;
                }
            }
            
            return Math.max(0.0, score);
        }
    }
}

// 容器运行管理器
public class ContainerRuntimeManager {
    private final ContainerRuntime runtime;
    private final ImageManager imageManager;
    private final VolumeManager volumeManager;
    private final NetworkManager networkManager;
    private final HealthChecker healthChecker;
    
    public void startPod(Pod pod) {
        logger.info("Starting pod {}", pod.getMetadata().getName());
        
        try {
            // 1. 拉取镜像
            pullContainerImages(pod);
            
            // 2. 准备卷
            prepareVolumes(pod);
            
            // 3. 配置网络
            configureNetwork(pod);
            
            // 4. 创建容器
            List<ContainerStatus> containerStatuses = createContainers(pod);
            
            // 5. 启动容器
            startContainers(pod, containerStatuses);
            
            // 6. 设置健康检查
            setupHealthChecks(pod, containerStatuses);
            
            // 7. 启动容器重启控制器
            startRestartController(pod);
            
            // 8. 更新Pod状态
            updatePodStatus(pod, containerStatuses);
            
        } catch (Exception e) {
            logger.error("Failed to start pod", e);
            handlePodStartFailure(pod, e);
        }
    }
    
    private void pullContainerImages(Pod pod) {
        for (Container container : pod.getSpec().getContainers()) {
            String image = container.getImage();
            
            if (!imageManager.isImageAvailable(image)) {
                logger.info("Pulling image {}", image);
                imageManager.pullImage(image);
            }
            
            // 验证镜像完整性
            if (!imageManager.verifyImageIntegrity(image)) {
                throw new RuntimeException("Image verification failed: " + image);
            }
        }
    }
    
    private List<ContainerStatus> createContainers(Pod pod) {
        List<ContainerStatus> containerStatuses = new ArrayList<>();
        
        for (Container container : pod.getSpec().getContainers()) {
            try {
                // 构建容器配置
                ContainerConfig config = buildContainerConfig(pod, container);
                
                // 创建容器
                ContainerId containerId = runtime.createContainer(config);
                
                // 创建容器状态
                ContainerStatus status = new ContainerStatus();
                status.setName(container.getName());
                status.setImage(container.getImage());
                status.setContainerId(containerId);
                status.setRestartCount(0);
                status.setState(ContainerState.WAITING);
                status.setReady(false);
                
                containerStatuses.add(status);
                
                logger.info("Created container {} for pod {}", 
                    container.getName(), pod.getMetadata().getName());
                
            } catch (Exception e) {
                logger.error("Failed to create container {} for pod {}", 
                    container.getName(), pod.getMetadata().getName(), e);
                throw new RuntimeException("Container creation failed", e);
            }
        }
        
        return containerStatuses;
    }
    
    private void startContainers(Pod pod, List<ContainerStatus> containerStatuses) {
        for (ContainerStatus status : containerStatuses) {
            try {
                runtime.startContainer(status.getContainerId());
                
                // 更新容器状态
                status.setState(ContainerState.RUNNING);
                status.setStartedAt(Instant.now());
                status.setReady(true);
                
                logger.info("Started container {} for pod {}", 
                    status.getName(), pod.getMetadata().getName());
                
            } catch (Exception e) {
                logger.error("Failed to start container {} for pod {}", 
                    status.getName(), pod.getMetadata().getName(), e);
                
                // 更新容器状态为失败
                status.setState(ContainerState.WAITING);
                status.setReady(false);
                status.setLastTerminationState(createTerminationState(e));
            }
        }
    }
    
    private void setupHealthChecks(Pod pod, List<ContainerStatus> containerStatuses) {
        for (Container container : pod.getSpec().getContainers()) {
            ContainerStatus status = findContainerStatus(containerStatuses, container.getName());
            
            if (container.getLivenessProbe() != null) {
                startLivenessProbe(pod, container, status);
            }
            
            if (container.getReadinessProbe() != null) {
                startReadinessProbe(pod, container, status);
            }
        }
    }
    
    private void startLivenessProbe(Pod pod, Container container, ContainerStatus status) {
        ProbeConfig probeConfig = container.getLivenessProbe();
        
        ScheduledFuture<?> probeFuture = CompletableFuture.runAsync(() -> {
            while (true) {
                try {
                    // 执行探针检查
                    boolean isHealthy = executeProbe(probeConfig, pod, container);
                    
                    if (!isHealthy) {
                        logger.warn("Liveness probe failed for container {} in pod {}", 
                            container.getName(), pod.getMetadata().getName());
                        
                        // 触发重启
                        handleContainerRestart(pod, container, status);
                        
                        break; // 停止探针，等待重启后重新开始
                    }
                    
                    // 等待下一次检查
                    Thread.sleep(probeConfig.getPeriodSeconds() * 1000);
                    
                } catch (Exception e) {
                    logger.error("Error in liveness probe for container {} in pod {}", 
                        container.getName(), pod.getMetadata().getName(), e);
                }
            }
        });
        
        status.setLivenessProbeFuture(probeFuture);
    }
    
    private boolean executeProbe(ProbeConfig probeConfig, Pod pod, Container container) {
        try {
            switch (probeConfig.getType()) {
                case HTTP_GET:
                    return executeHttpGetProbe(probeConfig, pod, container);
                case TCP_SOCKET:
                    return executeTcpSocketProbe(probeConfig, pod, container);
                case EXEC:
                    return executeExecProbe(probeConfig, pod, container);
                default:
                    return false;
            }
        } catch (Exception e) {
            logger.error("Failed to execute probe", e);
            return false;
        }
    }
    
    private boolean executeHttpGetProbe(ProbeConfig probeConfig, Pod pod, Container container) {
        HttpGet httpGet = probeConfig.getHttpGet();
        
        String url = String.format("http://%s:%d%s", 
            container.getName(), 
            httpGet.getPort().getIntVal(), 
            httpGet.getPath()
        );
        
        try {
            HttpResponse response = httpClient.execute(new HttpGet(url));
            int statusCode = response.getStatusLine().getStatusCode();
            
            // 检查返回状态码
            boolean isHealthy = statusCode >= 200 && statusCode < 400;
            
            if (!isHealthy) {
                logger.warn("HTTP probe failed with status code {} for container {} in pod {}", 
                    statusCode, container.getName(), pod.getMetadata().getName());
            }
            
            return isHealthy;
            
        } catch (Exception e) {
            logger.error("HTTP probe failed for container {} in pod {}", 
                container.getName(), pod.getMetadata().getName(), e);
            return false;
        }
    }
}
```

### 容器生命周期管理

**Pod生命周期控制器**：

```java
// Pod生命周期管理器
public class PodLifecycleManager {
    private final PodStatusUpdater statusUpdater;
    private final EventRecorder eventRecorder;
    private final RestartPolicyExecutor restartPolicyExecutor;
    private final finalizationHandler finalizationHandler;
    
    public void handlePodUpdate(Pod pod) {
        try {
            // 1. 同步Pod状态
            syncPodStatus(pod);
            
            // 2. 处理容器状态变化
            handleContainerStateChanges(pod);
            
            // 3. 检查Pod终止条件
            checkPodTerminationConditions(pod);
            
            // 4. 处理重启策略
            handleRestartPolicy(pod);
            
            // 5. 检查存活性和就绪性探针
            checkProbes(pod);
            
            // 6. 清理已终止的容器
            cleanupTerminatedContainers(pod);
            
            // 7. 更新Pod资源使用情况
            updateResourceUsage(pod);
            
        } catch (Exception e) {
            logger.error("Error handling pod update", e);
            eventRecorder.recordEvent(pod, EventType.WARNING, 
                "PodUpdateError", "Error handling pod update: " + e.getMessage());
        }
    }
    
    private void handleContainerStateChanges(Pod pod) {
        for (ContainerStatus containerStatus : pod.getStatus().getContainerStatuses()) {
            switch (containerStatus.getState()) {
                case WAITING:
                    handleWaitingState(pod, containerStatus);
                    break;
                case RUNNING:
                    handleRunningState(pod, containerStatus);
                    break;
                case TERMINATED:
                    handleTerminatedState(pod, containerStatus);
                    break;
            }
        }
    }
    
    private void handleWaitingState(Pod pod, ContainerStatus containerStatus) {
        String reason = containerStatus.getState().getWaiting().getReason();
        String message = containerStatus.getState().getWaiting().getMessage();
        
        switch (reason) {
            case "ContainerCreating":
                // 容器正在创建，等待完成
                break;
            case "ImagePullBackOff":
                // 镜像拉取失败，可能需要重试
                scheduleImagePullRetry(pod, containerStatus);
                break;
            case "ErrImagePull":
                // 镜像拉取错误
                handleImagePullError(pod, containerStatus, message);
                break;
            case "InvalidImageName":
                // 无效的镜像名称
                handleInvalidImageName(pod, containerStatus);
                break;
        }
    }
    
    private void handleRunningState(Pod pod, ContainerStatus containerStatus) {
        // 容器正在运行，更新就绪状态
        ContainerStateRunning running = containerStatus.getState().getRunning();
        if (running != null) {
            Instant startedAt = running.getStartedAt();
            
            // 如果容器刚启动，运行启动后钩子
            if (isContainerJustStarted(containerStatus)) {
                runPostStartHooks(pod, containerStatus);
            }
            
            // 更新运行时间
            containerStatus.setRunningTime(Duration.between(startedAt, Instant.now()));
        }
        
        // 更新容器就绪状态
        updateContainerReadiness(pod, containerStatus);
    }
    
    private void handleTerminatedState(Pod pod, ContainerStatus containerStatus) {
        ContainerStateTerminated terminated = containerStatus.getState().getTerminated();
        if (terminated == null) {
            return;
        }
        
        // 检查容器是否正常退出
        int exitCode = terminated.getExitCode();
        String reason = terminated.getReason();
        
        if (exitCode == 0 || "Completed".equals(reason)) {
            // 容器正常退出
            handleNormalTermination(pod, containerStatus);
        } else {
            // 容器异常退出
            handleAbnormalTermination(pod, containerStatus, exitCode, reason);
        }
        
        // 检查是否需要重启容器
        if (shouldRestartContainer(pod, containerStatus, exitCode)) {
            scheduleContainerRestart(pod, containerStatus);
        }
        
        // 清理容器
        cleanupContainer(containerStatus);
    }
    
    private void handleRestartPolicy(Pod pod) {
        RestartPolicy restartPolicy = pod.getSpec().getRestartPolicy();
        
        switch (restartPolicy) {
            case Always:
                handleAlwaysRestartPolicy(pod);
                break;
            case OnFailure:
                handleOnFailureRestartPolicy(pod);
                break;
            case Never:
                handleNeverRestartPolicy(pod);
                break;
        }
    }
    
    private void handleAlwaysRestartPolicy(Pod pod) {
        for (ContainerStatus containerStatus : pod.getStatus().getContainerStatuses()) {
            if (containerStatus.getState().isTerminated()) {
                scheduleContainerRestart(pod, containerStatus);
            }
        }
    }
    
    private void handleOnFailureRestartPolicy(Pod pod) {
        for (ContainerStatus containerStatus : pod.getStatus().getContainerStatuses()) {
            if (containerStatus.getState().isTerminated()) {
                ContainerStateTerminated terminated = containerStatus.getState().getTerminated();
                int exitCode = terminated.getExitCode();
                
                if (exitCode != 0) {
                    scheduleContainerRestart(pod, containerStatus);
                }
            }
        }
    }
    
    private void scheduleContainerRestart(Pod pod, ContainerStatus containerStatus) {
        RestartPolicyExecutor.RestartRequest restartRequest = new RestartPolicyExecutor.RestartRequest();
        restartRequest.setPod(pod);
        restartRequest.setContainer(containerStatus);
        restartRequest.setDelay(getRestartDelay(pod));
        
        restartPolicyExecutor.scheduleRestart(restartRequest);
    }
    
    private Duration getRestartDelay(Pod pod) {
        // 实现指数退避算法
        int restartCount = pod.getStatus().getContainerStatuses().stream()
            .mapToInt(ContainerStatus::getRestartCount)
            .max()
            .orElse(0);
        
        // 基础延迟10秒，每次重启延迟翻倍，最大5分钟
        Duration baseDelay = Duration.ofSeconds(10);
        Duration maxDelay = Duration.ofMinutes(5);
        
        Duration delay = baseDelay.multipliedBy((long) Math.pow(2, restartCount));
        return delay.compareTo(maxDelay) > 0 ? maxDelay : delay;
    }
}

// 水平自动扩缩容器(HPA)
public class HorizontalPodAutoscaler {
    private final HPAAnalyzer analyzer;
    private final ScalingController scalingController;
    private final MetricsClient metricsClient;
    private final EventRecorder eventRecorder;
    
    public void processHPAs(List<HorizontalPodAutoscaler> hpas) {
        for (HorizontalPodAutoscaler hpa : hpas) {
            try {
                processHPA(hpa);
            } catch (Exception e) {
                logger.error("Failed to process HPA", e);
                eventRecorder.recordEvent(hpa, EventType.WARNING, 
                    "HPAProcessingError", "Failed to process HPA: " + e.getMessage());
            }
        }
    }
    
    private void processHPA(HorizontalPodAutoscaler hpa) {
        // 1. 获取当前副本数
        int currentReplicas = getCurrentReplicas(hpa);
        
        // 2. 获取目标资源指标
        List<Metric> metrics = getTargetMetrics(hpa);
        
        // 3. 计算期望副本数
        int desiredReplicas = calculateDesiredReplicas(hpa, currentReplicas, metrics);
        
        // 4. 应用扩缩容限制
        desiredReplicas = applyScalingConstraints(hpa, currentReplicas, desiredReplicas);
        
        // 5. 执行扩缩容
        if (desiredReplicas != currentReplicas) {
            executeScaling(hpa, desiredReplicas);
        }
        
        // 6. 记录扩缩容事件
        recordScalingEvent(hpa, currentReplicas, desiredReplicas, metrics);
        
        // 7. 更新HPA状态
        updateHPAStatus(hpa, currentReplicas, desiredReplicas, metrics);
    }
    
    private int calculateDesiredReplicas(HorizontalPodAutoscaler hpa, 
                                       int currentReplicas, List<Metric> metrics) {
        List<RecommendedReplicas> recommendations = new ArrayList<>();
        
        // 为每个指标计算推荐副本数
        for (Metric metric : metrics) {
            int recommendedReplicas = calculateReplicasForMetric(hpa, metric, currentReplicas);
            recommendations.add(new RecommendedReplicas(metric.getName(), recommendedReplicas));
        }
        
        // 选择最大值（保守策略）
        return recommendations.stream()
            .mapToInt(RecommendedReplicas::getReplicas)
            .max()
            .orElse(currentReplicas);
    }
    
    private int calculateReplicasForMetric(HorizontalPodAutoscaler hpa, Metric metric, int currentReplicas) {
        double currentValue = metricsClient.getCurrentMetricValue(metric);
        double targetValue = extractTargetValue(hpa, metric);
        
        // 计算比例
        double ratio = currentValue / targetValue;
        
        // 计算推荐副本数
        int recommendedReplicas = (int) Math.ceil(currentReplicas * ratio);
        
        // 应用最小和最大限制
        int minReplicas = hpa.getSpec().getMinReplicas();
        int maxReplicas = hpa.getSpec().getMaxReplicas();
        
        recommendedReplicas = Math.max(minReplicas, recommendedReplicas);
        recommendedReplicas = Math.min(maxReplicas, recommendedReplicas);
        
        logger.debug("Metric {}: current={}, target={}, ratio={}, recommended={}", 
            metric.getName(), currentValue, targetValue, ratio, recommendedReplicas);
        
        return recommendedReplicas;
    }
    
    private int applyScalingConstraints(HHorizontalPodAutoscaler hpa, int currentReplicas, int desiredReplicas) {
        ScalingPolicy policy = hpa.getSpec().getScalingPolicy();
        if (policy == null) {
            return desiredReplicas;
        }
        
        // 限制单次扩缩容数量
        int maxChange = policy.getMaxChangePerInterval();
        if (maxChange > 0) {
            int change = Math.abs(desiredReplicas - currentReplicas);
            if (change > maxChange) {
                if (desiredReplicas > currentReplicas) {
                    desiredReplicas = currentReplicas + maxChange;
                } else {
                    desiredReplicas = currentReplicas - maxChange;
                }
            }
        }
        
        // 限制扩缩容速率
        Duration scaleUpStabilization = policy.getScaleUpStabilizationWindow();
        Duration scaleDownStabilization = policy.getScaleDownStabilizationWindow();
        
        if (desiredReplicas > currentReplicas && scaleUpStabilization != null) {
            int recentScaleUps = getRecentScaleUpEvents(hpa, scaleUpStabilization);
            if (recentScaleUps > 0) {
                desiredReplicas = currentReplicas; // 延迟扩容
            }
        }
        
        if (desiredReplicas < currentReplicas && scaleDownStabilization != null) {
            int recentScaleDowns = getRecentScaleDownEvents(hpa, scaleDownStabilization);
            if (recentScaleDowns > 0) {
                desiredReplicas = currentReplicas; // 延迟缩容
            }
        }
        
        return desiredReplicas;
    }
    
    private void executeScaling(HorizontalPodAutoscaler hpa, int desiredReplicas) {
        String deploymentName = hpa.getSpec().getScaleTargetRef().getName();
        String namespace = hpa.getMetadata().getNamespace();
        
        ScaleDeploymentRequest request = new ScaleDeploymentRequest();
        request.setName(deploymentName);
        request.setNamespace(namespace);
        request.setReplicas(desiredReplicas);
        
        try {
            scalingController.scaleDeployment(request);
            logger.info("Scaled deployment {} from {} to {} replicas", 
                deploymentName, getCurrentReplicas(hpa), desiredReplicas);
        } catch (Exception e) {
            logger.error("Failed to scale deployment", e);
            throw new ScalingException("Failed to execute scaling", e);
        }
    }
}

// 垂直自动扩缩容器(VPA)
public class VerticalPodAutoscaler {
    private final ResourceEstimator resourceEstimator;
    private final UpdateMode updateMode;
    private final AdmissionController admissionController;
    
    public void processVPAs(List<VerticalPodAutoscaler> vpas) {
        for (VerticalPodAutoscaler vpa : vpas) {
            try {
                processVPA(vpa);
            } catch (Exception e) {
                logger.error("Failed to process VPA", e);
            }
        }
    }
    
    private void processVPA(VerticalPodAutoscaler vpa) {
        // 1. 获取目标Pod列表
        List<Pod> targetPods = getTargetPods(vpa);
        
        // 2. 收集资源使用数据
        ResourceUsageData usageData = collectResourceUsageData(targetPods);
        
        // 3. 计算推荐资源
        ResourceRecommendation recommendation = calculateResourceRecommendation(vpa, usageData);
        
        // 4. 应用更新策略
        applyUpdateStrategy(vpa, targetPods, recommendation);
        
        // 5. 更新VPA状态
        updateVPAStatus(vpa, recommendation);
    }
    
    private ResourceRecommendation calculateResourceRecommendation(
            VerticalPodAutoscaler vpa, ResourceUsageData usageData) {
        
        ResourceEstimationPolicy policy = vpa.getSpec().getResourcePolicy();
        
        ResourceRecommendation recommendation = new ResourceRecommendation();
        
        // CPU推荐
        double cpuRecommendation = estimateCPU(usageData, policy);
        recommendation.setCpuRequest(cpuRecommendation);
        
        // 内存推荐
        double memoryRecommendation = estimateMemory(usageData, policy);
        recommendation.setMemoryRequest(memoryRecommendation);
        
        // 限制计算
        recommendation.setCpuLimit(calculateLimit(cpuRecommendation, policy.getCpuLimitRatio()));
        recommendation.setMemoryLimit(calculateLimit(memoryRecommendation, policy.getMemoryLimitRatio()));
        
        return recommendation;
    }
    
    private double estimateCPU(ResourceUsageData usageData, ResourceEstimationPolicy policy) {
        List<ResourceUsageSample> cpuSamples = usageData.getCpuSamples();
        
        if (cpuSamples.isEmpty()) {
            return policy.getDefaultCpuRequest();
        }
        
        // 使用P95分位数作为推荐值
        List<Double> cpuUsage = cpuSamples.stream()
            .map(ResourceUsageSample::getValue)
            .collect(Collectors.toList());
        
        Collections.sort(cpuUsage);
        double p95Usage = calculatePercentile(cpuUsage, 95);
        
        // 应用安全系数
        double safetyMargin = policy.getSafetyMargin();
        double recommendation = p95Usage * safetyMargin;
        
        // 限制在最小和最大值范围内
        recommendation = Math.max(policy.getMinCpuRequest(), recommendation);
        recommendation = Math.min(policy.getMaxCpuRequest(), recommendation);
        
        return recommendation;
    }
}
```

## 服务网格架构

### Istio服务网格

**数据平面代理**：

```java
// Envoy代理配置生成器
public class EnvoyConfigGenerator {
    private final StaticClusterConfig clusterConfig;
    private final ListenerConfig listenerConfig;
    private final RouteConfig routeConfig;
    private final FilterConfig filterConfig;
    
    public EnvoyConfig generateEnvoyConfig(ServiceInstance service, List<Upstream> upstreams) {
        EnvoyConfig config = new EnvoyConfig();
        
        // 1. 生成集群配置
        List<Cluster> clusters = generateClusters(upstreams);
        config.setClusters(clusters);
        
        // 2. 生成监听器配置
        List<Listener> listeners = generateListeners(service);
        config.setListeners(listeners);
        
        // 3. 生成路由配置
        List<RouteConfiguration> routes = generateRoutes(service, clusters);
        config.setRouteConfigurations(routes);
        
        // 4. 生成过滤器配置
        List<Filter> filters = generateFilters(service);
        config.setFilters(filters);
        
        // 5. 生成管理员配置
        config.setAdmin(getAdminConfig());
        
        return config;
    }
    
    private List<Cluster> generateClusters(List<Upstream> upstreams) {
        return upstreams.stream()
            .map(this::generateCluster)
            .collect(Collectors.toList());
    }
    
    private Cluster generateCluster(Upstream upstream) {
        Cluster cluster = new Cluster();
        cluster.setName(upstream.getName());
        cluster.setType("STRICT_DNS");
        cluster.setConnectTimeout("30s");
        
        // 健康检查配置
        HealthCheck healthCheck = new HealthCheck();
        healthCheck.setTimeout("3s");
        healthCheck.setInterval("10s");
        healthCheck.setUnhealthyThreshold(3);
        healthCheck.setHealthyThreshold(2);
        
        HttpHealthCheck httpHealthCheck = new HttpHealthCheck();
        httpHealthCheck.setPath("/health");
        httpHealthCheck.setExpectedStatuses(Arrays.asList(200, 201));
        healthCheck.setHttpHealthCheck(httpHealthCheck);
        
        cluster.setHealthChecks(Arrays.asList(healthCheck));
        
        // 负载均衡配置
        if ("LEAST_REQUEST".equals(upstream.getLoadBalancingPolicy())) {
            LeastRequestLoadBalancing leastRequest = new LeastRequestLoadBalancing();
            leastRequest.setChoiceCount(2);
            cluster.setLeastRequestLoadBalancing(leastRequest);
        } else if ("RING_HASH".equals(upstream.getLoadBalancingPolicy())) {
            RingHashLoadBalancing ringHash = new RingHashLoadBalancing();
            ringHash.setMinRingSize(1024);
            ringHash.setMaxRingSize(1048576);
            cluster.setRingHashLoadBalancing(ringHash);
        }
        
        // 连接池配置
        HttpConnectionPool httpPool = new HttpConnectionPool();
        httpPool.setMaxRequestsPerConnection(100);
        httpPool.setMaxConcurrentStreams(100);
        httpPool.setKeepAliveTime("30s");
        httpPool.setKeepAliveTimeout("5s");
        httpPool.setKeepAliveInterval("75s");
        cluster.setHttpConnectionPool(httpPool);
        
        return cluster;
    }
    
    private List<Listener> generateListeners(ServiceInstance service) {
        List<Listener> listeners = new ArrayList<>();
        
        // 1. 监听器配置
        Listener listener = new Listener();
        listener.setName(service.getName() + "_listener");
        listener.setAddress(getServiceAddress(service));
        listener.setTrafficDirection(TrafficDirection.INBOUND);
        
        // 2. 过滤器链配置
        FilterChain inboundChain = generateInboundFilterChain(service);
        FilterChain outboundChain = generateOutboundFilterChain(service);
        
        listener.setFilterChains(Arrays.asList(inboundChain, outboundChain));
        
        // 3. 监听器过滤器
        ListenerFilter originalSourceFilter = new ListenerFilter();
        originalSourceFilter.setName("envoy.filters.listener.original_src");
        originalSourceFilter.setTypedConfig(getOriginalSrcFilterConfig());
        
        ListenerFilter envoyFilters = getEnvoyFilters(service);
        listener.setListenerFilters(Arrays.asList(originalSourceFilter, envoyFilters));
        
        listeners.add(listener);
        
        return listeners;
    }
    
    private FilterChain generateInboundFilterChain(ServiceInstance service) {
        FilterChain filterChain = new FilterChain();
        filterChain.setName(service.getName() + "_inbound");
        
        // HTTP连接管理器过滤器
        HttpConnectionManager httpManager = new HttpConnectionManager();
        httpManager.setCodecType("AUTO");
        httpManager.setStatPrefix(service.getName() + "_stats");
        
        // 路由配置
        RouteConfiguration routeConfig = generateInboundRoute(service);
        httpManager.setRouteConfig(routeConfig);
        
        // 过滤器配置
        HttpFilter corsFilter = generateCorsFilter();
        HttpFilter authFilter = generateAuthFilter(service);
        HttpFilter metricsFilter = generateMetricsFilter(service);
        HttpFilter tracingFilter = generateTracingFilter(service);
        
        httpManager.setFilters(Arrays.asList(
            corsFilter, authFilter, metricsFilter, tracingFilter
        ));
        
        // 访问日志配置
        AccessLog accessLog = new AccessLog();
        accessLog.setName("envoy.access_loggers.file");
        accessLog.setTypedConfig(getFileAccessLogConfig(service));
        
        httpManager.setAccessLog(Arrays.asList(accessLog));
        
        // 连接管理配置
        HttpConnectionManagerConfig config = new HttpConnectionManagerConfig();
        config.setMergeSlashes(true);
        config.setStripPortFromHostHeader(true);
        config.setRespectExpect100Continue(false);
        config.setStreamIdleTimeout("300s");
        config.setRequestTimeout("300s");
        config.setDrainTimeout("30s");
        config.setDelayedCloseTimeout("10s");
        httpManager.setConfig(config);
        
        // HTTP过滤器配置
        Filter httpFilter = new Filter();
        httpFilter.setName("envoy.filters.network.http_connection_manager");
        httpFilter.setTypedConfig(serializeToAny(httpManager));
        
        filterChain.setFilters(Arrays.asList(httpFilter));
        
        return filterChain;
    }
    
    private RouteConfiguration generateInboundRoute(ServiceInstance service) {
        RouteConfiguration routeConfig = new RouteConfiguration();
        routeConfig.setName("inbound_" + service.getName() + "_routes");
        
        // 默认路由配置
        VirtualHost virtualHost = new VirtualHost();
        virtualHost.setName(service.getName() + "_virtual_host");
        virtualHost.setDomains(service.getHostnames());
        
        // 健康检查路由
        Route healthCheckRoute = new Route();
        healthCheckRoute.setName("health_check_route");
        
        RouteAction healthCheckAction = new RouteAction();
        healthCheckAction.setCluster(service.getClusterName());
        healthCheckAction.setPrefixRewrite("/");
        healthCheckRoute.setRoute(healthCheckAction);
        
        MatchCondition healthMatch = new MatchCondition();
        healthMatch.setPath("/health");
        healthCheckRoute.setMatch(healthMatch);
        
        // 主要路由配置
        Route mainRoute = new Route();
        mainRoute.setName("main_route");
        
        RouteAction mainAction = new RouteAction();
        mainAction.setCluster(service.getClusterName());
        mainAction.setRetryPolicy(generateRetryPolicy(service));
        mainRoute.setRoute(mainAction);
        
        MatchCondition mainMatch = new MatchCondition();
        mainMatch.setPrefix("/");
        mainRoute.setMatch(mainMatch);
        
        virtualHost.setRoutes(Arrays.asList(healthCheckRoute, mainRoute));
        routeConfig.setVirtualHosts(Arrays.asList(virtualHost));
        
        return routeConfig;
    }
}

// 服务发现和负载均衡
public class ServiceDiscoveryAndLoadBalancing {
    private final ServiceRegistry serviceRegistry;
    private final EndpointResolver endpointResolver;
    private final LoadBalancer loadBalancer;
    private final HealthChecker healthChecker;
    
    public void updateUpstreamEndpoints(Service service, List<Endpoint> endpoints) {
        try {
            // 1. 验证端点
            List<Endpoint> validEndpoints = filterValidEndpoints(endpoints);
            
            // 2. 健康检查
            Map<Endpoint, HealthStatus> healthStatus = checkEndpointHealth(validEndpoints);
            List<Endpoint> healthyEndpoints = filterHealthyEndpoints(healthStatus);
            
            // 3. 负载均衡
            LoadBalancingResult lbResult = loadBalancer.selectEndpoints(
                healthyEndpoints, 
                service.getLoadBalancingPolicy(),
                service.getSessionAffinityConfig()
            );
            
            // 4. 更新Envoy配置
            updateEnvoyClusterConfig(service, lbResult);
            
            // 5. 发布端点更新事件
            publishEndpointUpdateEvent(service, lbResult);
            
        } catch (Exception e) {
            logger.error("Failed to update upstream endpoints", e);
        }
    }
    
    private LoadBalancingResult selectEndpoints(List<Endpoint> endpoints, 
                                               LoadBalancingPolicy policy,
                                               SessionAffinityConfig affinityConfig) {
        
        switch (policy) {
            case ROUND_ROBIN:
                return selectRoundRobinEndpoints(endpoints, affinityConfig);
            case LEAST_REQUEST:
                return selectLeastRequestEndpoints(endpoints, affinityConfig);
            case RING_HASH:
                return selectRingHashEndpoints(endpoints, affinityConfig);
            case RANDOM:
                return selectRandomEndpoints(endpoints, affinityConfig);
            case PASSTHROUGH:
                return selectPassthroughEndpoints(endpoints, affinityConfig);
            default:
                throw new IllegalArgumentException("Unknown load balancing policy: " + policy);
        }
    }
    
    private LoadBalancingResult selectRoundRobinEndpoints(List<Endpoint> endpoints, 
                                                         SessionAffinityConfig affinityConfig) {
        LoadBalancingResult result = new LoadBalancingResult();
        
        // 如果启用会话亲和性，先选择亲和性端点
        if (affinityConfig != null && affinityConfig.isEnabled()) {
            Endpoint affinityEndpoint = selectAffinityEndpoint(endpoints, affinityConfig);
            if (affinityEndpoint != null) {
                result.addPrimaryEndpoint(affinityEndpoint);
            }
        }
        
        // 添加轮询端点
        List<Endpoint> remainingEndpoints = endpoints.stream()
            .filter(ep -> !result.getAllEndpoints().contains(ep))
            .collect(Collectors.toList());
        
        for (int i = 0; i < remainingEndpoints.size(); i++) {
            result.addEndpoint(remainingEndpoints.get(i));
        }
        
        return result;
    }
    
    private LoadBalancingResult selectLeastRequestEndpoints(List<Endpoint> endpoints, 
                                                           SessionAffinityConfig affinityConfig) {
        LoadBalancingResult result = new LoadBalancingResult();
        
        // 收集当前请求数
        Map<Endpoint, Integer> requestCounts = getCurrentRequestCounts(endpoints);
        
        // 按请求数排序
        List<Endpoint> sortedEndpoints = endpoints.stream()
            .sorted(Comparator.comparing(ep -> requestCounts.get(ep)))
            .collect(Collectors.toList());
        
        // 选择请求数最少的端点
        int minRequests = requestCounts.get(sortedEndpoints.get(0));
        List<Endpoint> leastRequestEndpoints = sortedEndpoints.stream()
            .filter(ep -> requestCounts.get(ep) == minRequests)
            .collect(Collectors.toList());
        
        // 如果启用了会话亲和性，在最少请求端点中选择亲和性端点
        if (affinityConfig != null && affinityConfig.isEnabled()) {
            Endpoint affinityEndpoint = selectAffinityEndpoint(leastRequestEndpoints, affinityConfig);
            if (affinityEndpoint != null) {
                result.addPrimaryEndpoint(affinityEndpoint);
            }
        }
        
        // 添加其余端点
        List<Endpoint> remainingEndpoints = leastRequestEndpoints.stream()
            .filter(ep -> !result.getAllEndpoints().contains(ep))
            .collect(Collectors.toList());
        
        for (Endpoint endpoint : remainingEndpoints) {
            result.addEndpoint(endpoint);
        }
        
        return result;
    }
    
    private LoadBalancingResult selectRingHashEndpoints(List<Endpoint> endpoints, 
                                                       SessionAffinityConfig affinityConfig) {
        LoadBalancingResult result = new LoadBalancingResult();
        
        if (affinityConfig == null || affinityConfig.getHashPolicies().isEmpty()) {
            throw new IllegalArgumentException("Ring hash load balancing requires session affinity configuration");
        }
        
        // 构建一致性哈希环
        ConsistentHashRing hashRing = new ConsistentHashRing(endpoints, affinityConfig.getHashPolicies());
        
        // 为每个请求选择哈希环中的端点
        for (String sessionId : getActiveSessionIds()) {
            Endpoint hashedEndpoint = hashRing.getEndpoint(sessionId);
            result.addEndpoint(hashedEndpoint);
        }
        
        // 确保所有端点都被包含
        for (Endpoint endpoint : endpoints) {
            if (!result.getAllEndpoints().contains(endpoint)) {
                result.addEndpoint(endpoint);
            }
        }
        
        return result;
    }
    
    private Map<Endpoint, HealthStatus> checkEndpointHealth(List<Endpoint> endpoints) {
        Map<Endpoint, HealthStatus> healthStatus = new HashMap<>();
        
        // 并行健康检查
        CompletableFuture<HealthStatus>[] futures = endpoints.stream()
            .map(endpoint -> CompletableFuture.supplyAsync(() -> {
                try {
                    return performHealthCheck(endpoint);
                } catch (Exception e) {
                    logger.warn("Health check failed for endpoint", e);
                    return HealthStatus.UNHEALTHY;
                }
            }))
            .toArray(CompletableFuture[]::new);
        
        try {
            CompletableFuture.allOf(futures).get(5, TimeUnit.SECONDS);
            
            for (int i = 0; i < endpoints.size(); i++) {
                try {
                    HealthStatus status = futures[i].get();
                    healthStatus.put(endpoints.get(i), status);
                } catch (Exception e) {
                    healthStatus.put(endpoints.get(i), HealthStatus.UNHEALTHY);
                }
            }
        } catch (Exception e) {
            logger.error("Health check timeout", e);
            // 所有端点标记为不健康
            for (Endpoint endpoint : endpoints) {
                healthStatus.put(endpoint, HealthStatus.UNHEALTHY);
            }
        }
        
        return healthStatus;
    }
    
    private HealthStatus performHealthCheck(Endpoint endpoint) {
        // TCP连接检查
        try (Socket socket = new Socket()) {
            socket.setSoTimeout(2000); // 2秒超时
            socket.connect(new InetSocketAddress(endpoint.getAddress(), endpoint.getPort()), 2000);
            return HealthStatus.HEALTHY;
        } catch (Exception e) {
            return HealthStatus.UNHEALTHY;
        }
    }
}

// 流量管理控制器
public class TrafficManagementController {
    private final ConfigGenerator configGenerator;
    private final ConfigPusher configPusher;
    private final DestinationRuleEngine destinationRuleEngine;
    private final VirtualServiceEngine virtualServiceEngine;
    
    public void processTrafficPolicy(TrafficPolicy trafficPolicy) {
        try {
            // 1. 验证流量策略
            validateTrafficPolicy(trafficPolicy);
            
            // 2. 生成目的地规则
            List<DestinationRule> destinationRules = destinationRuleEngine.generateDestinationRules(trafficPolicy);
            
            // 3. 生成虚拟服务规则
            List<VirtualService> virtualServices = virtualServiceEngine.generateVirtualServices(trafficPolicy);
            
            // 4. 生成网关配置
            List<Gateway> gateways = generateGateways(trafficPolicy);
            
            // 5. 生成服务入口配置
            List<ServiceEntry> serviceEntries = generateServiceEntries(trafficPolicy);
            
            // 6. 推送配置到Envoy
            pushConfiguration(gateways, virtualServices, destinationRules, serviceEntries);
            
            // 7. 记录配置推送事件
            recordConfigurationPushEvent(trafficPolicy);
            
        } catch (Exception e) {
            logger.error("Failed to process traffic policy", e);
            throw new TrafficPolicyException("Failed to process traffic policy", e);
        }
    }
    
    private void pushConfiguration(List<Gateway> gateways, 
                                  List<VirtualService> virtualServices,
                                  List<DestinationRule> destinationRules,
                                  List<ServiceEntry> serviceEntries) {
        
        Configuration config = new Configuration();
        config.setGateways(gateways);
        config.setVirtualServices(virtualServices);
        config.setDestinationRules(destinationRules);
        config.setServiceEntries(serviceEntries);
        
        // 生成完整Envoy配置
        EnvoyConfiguration envoyConfig = configGenerator.generateEnvoyConfiguration(config);
        
        // 推送到所有Envoy代理
        pushToEnvoyInstances(envoyConfig);
        
        // 验证配置推送结果
        validateConfigurationPush(envoyConfig);
    }
    
    private void validateConfigurationPush(EnvoyConfiguration config) {
        // 检查配置完整性
        validateConfigurationCompleteness(config);
        
        // 检查路由配置有效性
        validateRouteConfiguration(config);
        
        // 检查集群配置有效性
        validateClusterConfiguration(config);
        
        // 检查监听器配置有效性
        validateListenerConfiguration(config);
    }
}
```

## 编排管理最佳实践

### 资源管理策略

```java
// 资源配额和限制管理器
public class ResourceManagementStrategy {
    
    // 1. 资源请求和限制配置
    public static class ResourceRequest {
        public static final double DEFAULT_CPU_REQUEST = 0.1; // 0.1 CPU核心
        public static final long DEFAULT_MEMORY_REQUEST = 128 * 1024 * 1024; // 128MB
        public static final double DEFAULT_CPU_LIMIT = 0.5; // 0.5 CPU核心
        public static final long DEFAULT_MEMORY_LIMIT = 512 * 1024 * 1024; // 512MB
        
        public static ResourceRequirements getDefaultRequirements() {
            ResourceRequirements requirements = new ResourceRequirements();
            
            // CPU请求和限制
            ResourceQuantity cpuRequest = new ResourceQuantity(DEFAULT_CPU_REQUEST, "cpu");
            ResourceQuantity cpuLimit = new ResourceQuantity(DEFAULT_CPU_LIMIT, "cpu");
            requirements.setRequests(Map.of("cpu", cpuRequest));
            requirements.setLimits(Map.of("cpu", cpuLimit, "memory", 
                new ResourceQuantity(DEFAULT_MEMORY_LIMIT, "memory")));
            
            return requirements;
        }
    }
    
    // 2. 自动扩缩容策略
    public static class AutoscalingStrategy {
        
        public static HorizontalPodAutoscaler createHPA(String serviceName, 
                                                       String namespace,
                                                       Map<String, Object> customMetrics) {
            HorizontalPodAutoscaler hpa = new HorizontalPodAutoscaler();
            hpa.setApiVersion("autoscaling/v2");
            hpa.setKind("HorizontalPodAutoscaler");
            
            ObjectMeta metadata = new ObjectMeta();
            metadata.setName(serviceName + "-hpa");
            metadata.setNamespace(namespace);
            hpa.setMetadata(metadata);
            
            HorizontalPodAutoscalerSpec spec = new HorizontalPodAutoscalerSpec();
            spec.setMinReplicas(2);
            spec.setMaxReplicas(10);
            
            // CPU使用率指标
            CrossVersionObjectReference scaleTargetRef = new CrossVersionObjectReference();
            scaleTargetRef.setApiVersion("apps/v1");
            scaleTargetRef.setKind("Deployment");
            scaleTargetRef.setName(serviceName);
            spec.setScaleTargetRef(scaleTargetRef);
            
            // 指标配置
            List<MetricSpec> metrics = new ArrayList<>();
            
            // CPU使用率指标
            MetricSpec cpuMetric = new MetricSpec();
            cpuMetric.setType("Resource");
            cpuMetric.setName("cpu");
            
            ResourceMetricSource cpuSource = new ResourceMetricSource();
            cpuSource.setName("cpu");
            cpuSource.setTarget(generateMetricTarget(70.0, ResourceMetricType.AverageUtilization)); // 70%阈值
            cpuMetric.setResource(cpuSource);
            
            metrics.add(cpuMetric);
            
            // 自定义指标（如果有）
            if (customMetrics != null && !customMetrics.isEmpty()) {
                metrics.addAll(createCustomMetricSpecs(customMetrics));
            }
            
            spec.setMetrics(metrics);
            
            // 扩缩容策略
            HPAScalingPolicy scalingPolicy = new HPAScalingPolicy();
            scalingPolicy.setScaleUp(generateScalePolicy(3, 30)); // 最多增加3个，30秒内完成
            scalingPolicy.setScaleDown(generateScalePolicy(1, 60)); // 最多减少1个，60秒内完成
            spec.setScalingPolicy(scalingPolicy);
            
            hpa.setSpec(spec);
            return hpa;
        }
        
        private static MetricTarget generateMetricTarget(double value, ResourceMetricType type) {
            MetricTarget target = new MetricTarget();
            target.setAverageUtilization((int) value);
            return target;
        }
        
        private static List<HPAScalingPolicyRules> generateScalePolicy(int podCount, int intervalSeconds) {
            HPAScalingPolicyRules rule = new HPAScalingPolicyRules();
            rule.setType("Percent");
            rule.setValue(podCount);
            rule.setPeriodSeconds(intervalSeconds);
            
            return Arrays.asList(rule);
        }
    }
    
    // 3. 节点亲和性和污点容忍
    public static class NodeAffinityStrategy {
        
        public static NodeAffinity createNodeAffinity(ComputeRequirements requirements) {
            NodeAffinity affinity = new NodeAffinity();
            
            // 必需亲和性条件
            NodeSelector requiredAffinity = new NodeSelector();
            List<NodeSelectorTerm> requiredTerms = generateRequiredTerms(requirements);
            requiredAffinity.setNodeSelectorTerms(requiredTerms);
            
            affinity.setRequiredDuringSchedulingIgnoredDuringExecution(requiredAffinity);
            
            // 偏好亲和性条件
            PreferredDuringSchedulingIgnoredDuringExecution preferredAffinity = 
                generatePreferredAffinity(requirements);
            affinity.setPreferredDuringSchedulingIgnoredDuringExecution(preferredAffinity);
            
            return affinity;
        }
        
        private static List<NodeSelectorTerm> generateRequiredTerms(ComputeRequirements requirements) {
            List<NodeSelectorTerm> terms = new ArrayList<>();
            
            // 硬件架构要求
            if (requirements.getArchitecture() != null) {
                NodeSelectorRequirement archReq = new NodeSelectorRequirement();
                archReq.setKey("kubernetes.io/arch");
                archReq.setOperator("In");
                archReq.setValues(Arrays.asList(requirements.getArchitecture()));
                
                NodeSelectorTerm archTerm = new NodeSelectorTerm();
                archTerm.setMatchExpressions(Arrays.asList(archReq));
                terms.add(archTerm);
            }
            
            // 内存大小要求
            if (requirements.getMinMemoryGB() > 0) {
                NodeSelectorRequirement memoryReq = new NodeSelectorRequirement();
                memoryReq.setKey("node.kubernetes.io/memory-capacity");
                memoryReq.setOperator("Gt");
                memoryReq.setValues(Arrays.asList(requirements.getMinMemoryGB() + "Gi"));
                
                NodeSelectorTerm memoryTerm = new NodeSelectorTerm();
                memoryTerm.setMatchExpressions(Arrays.asList(memoryReq));
                terms.add(memoryTerm);
            }
            
            return terms;
        }
        
        private static PreferredDuringSchedulingIgnoredDuringExecution generatePreferredAffinity(
                ComputeRequirements requirements) {
            
            List<PreferredSchedulingTerm> preferredTerms = new ArrayList<>();
            
            // 偏好SSD存储
            if (requirements.isRequireSSD()) {
                PreferredSchedulingTerm ssdTerm = new PreferredSchedulingTerm();
                ssdTerm.setWeight(10);
                
                NodeSelectorTerm term = new NodeSelectorTerm();
                NodeSelectorRequirement req = new NodeSelectorRequirement();
                req.setKey("node.kubernetes.io/disk-type");
                req.setOperator("In");
                req.setValues(Arrays.asList("ssd"));
                term.setMatchExpressions(Arrays.asList(req));
                
                ssdTerm.setPreference(term);
                preferredTerms.add(ssdTerm);
            }
            
            // 偏好特定zone
            if (requirements.getPreferredZone() != null) {
                PreferredSchedulingTerm zoneTerm = new PreferredSchedulingTerm();
                zoneTerm.setWeight(5);
                
                NodeSelectorTerm term = new NodeSelectorTerm();
                NodeSelectorRequirement req = new NodeSelectorRequirement();
                req.setKey("failure-domain.beta.kubernetes.io/zone");
                req.setOperator("In");
                req.setValues(Arrays.asList(requirements.getPreferredZone()));
                term.setMatchExpressions(Arrays.asList(req));
                
                zoneTerm.setPreference(term);
                preferredTerms.add(zoneTerm);
            }
            
            return preferredTerms;
        }
    }
    
    // 4. 污点和容忍策略
    public static class TaintTolerationStrategy {
        
        public static Toleration createToleration(String key, String operator, 
                                                String effect, int tolerationSeconds) {
            Toleration toleration = new Toleration();
            toleration.setKey(key);
            toleration.setOperator(operator);
            toleration.setEffect(effect);
            
            if (tolerationSeconds > 0) {
                toleration.setTolerationSeconds(tolerationSeconds);
            }
            
            return toleration;
        }
        
        // 常见污点类型
        public static class CommonTaints {
            public static final String GPU_NODE_TAINT = "nvidia.com/gpu";
            public static final String DEDICATED_TAINT = "dedicated";
            public static final String HIGH_MEMORY_TAINT = "high-memory-node";
            
            public static Toleration createGPUToleration() {
                return createToleration(GPU_NODE_TAINT, "Exists", "PreferNoSchedule", 0);
            }
            
            public static Toleration createDedicatedToleration(String value) {
                Toleration toleration = new Toleration();
                toleration.setKey(DEDICATED_TAINT);
                toleration.setOperator("Equal");
                toleration.setValue(value);
                toleration.setEffect("NoSchedule");
                return toleration;
            }
        }
    }
}
```

### 多集群管理

```java
// 多集群管理控制器
public class MultiClusterManager {
    private final ClusterRegistry clusterRegistry;
    private final FederatedController federatedController;
    private final MultiClusterLoadBalancer loadBalancer;
    private final DisasterRecoveryManager disasterRecovery;
    
    public void syncResourcesAcrossClusters(String resourceType, String resourceName) {
        try {
            // 1. 获取所有集群列表
            List<Cluster> clusters = clusterRegistry.getClusters();
            
            // 2. 获取资源在每个集群中的状态
            Map<Cluster, ResourceStatus> resourceStatusMap = getResourceStatusAcrossClusters(
                clusters, resourceType, resourceName);
            
            // 3. 检测资源状态差异
            ResourceDiff diff = detectResourceDiff(resourceStatusMap);
            
            // 4. 应用同步策略
            applySyncStrategy(resourceType, resourceName, diff);
            
            // 5. 验证同步结果
            validateSyncResult(clusters, resourceType, resourceName);
            
        } catch (Exception e) {
            logger.error("Failed to sync resources across clusters", e);
            handleSyncFailure(resourceType, resourceName, e);
        }
    }
    
    private void applySyncStrategy(String resourceType, String resourceName, ResourceDiff diff) {
        switch (diff.getSyncStrategy()) {
            case PULL:
                applyPullStrategy(diff);
                break;
            case PUSH:
                applyPushStrategy(diff);
                break;
            case MERGE:
                applyMergeStrategy(diff);
                break;
        }
    }
    
    private void applyPullStrategy(ResourceDiff diff) {
        // 从源集群拉取资源，然后推送到其他集群
        Cluster sourceCluster = diff.getSourceCluster();
        ClusterResource resource = federatedController.getResource(
            sourceCluster, resourceType, resourceName);
        
        for (Cluster targetCluster : diff.getTargetClusters()) {
            if (needsSync(targetCluster, resource)) {
                federatedController.syncResource(targetCluster, resource);
            }
        }
    }
    
    private void applyPushStrategy(ResourceDiff diff) {
        // 将主集群的配置推送到其他集群
        Cluster primaryCluster = diff.getPrimaryCluster();
        
        for (Cluster cluster : diff.getClusters()) {
            if (!cluster.equals(primaryCluster)) {
                federatedController.pushConfiguration(primaryCluster, cluster);
            }
        }
    }
    
    // 跨集群负载均衡
    public ServiceEndpoint selectEndpoint(List<ServiceInstance> serviceInstances, 
                                         RequestContext requestContext) {
        
        // 1. 按地理位置分组实例
        Map<String, List<ServiceInstance>> instancesByRegion = serviceInstances.stream()
            .collect(Collectors.groupingBy(this::getRegion));
        
        // 2. 选择最近的区域
        String targetRegion = selectClosestRegion(instancesByRegion.keySet(), requestContext.getClientRegion());
        
        // 3. 在目标区域选择实例
        List<ServiceInstance> regionInstances = instancesByRegion.get(targetRegion);
        
        if (regionInstances.isEmpty()) {
            // 如果目标区域没有实例，选择备选区域
            targetRegion = selectFallbackRegion(instancesByRegion.keySet(), requestContext.getClientRegion());
            regionInstances = instancesByRegion.get(targetRegion);
        }
        
        // 4. 在区域内进行负载均衡
        return loadBalancer.selectEndpoint(regionInstances, requestContext);
    }
    
    private String selectClosestRegion(Set<String> availableRegions, String clientRegion) {
        // 实现地理位置算法
        Map<String, Integer> regionDistances = calculateRegionDistances(availableRegions, clientRegion);
        
        return regionDistances.entrySet().stream()
            .min(Map.Entry.comparingByValue())
            .map(Map.Entry::getKey)
            .orElse(availableRegions.iterator().next());
    }
    
    // 灾难恢复
    public void performDisasterRecovery() {
        try {
            // 1. 检测故障集群
            List<Cluster> failedClusters = detectFailedClusters();
            
            if (failedClusters.isEmpty()) {
                logger.info("No failed clusters detected");
                return;
            }
            
            // 2. 评估业务影响
            DisasterRecoveryImpact impact = assessDisasterImpact(failedClusters);
            
            // 3. 启动故障转移
            if (impact.isRequiresFailover()) {
                initiateFailover(impact.getFailedServices());
            }
            
            // 4. 数据恢复
            if (impact.isRequiresDataRecovery()) {
                performDataRecovery(impact.getAffectedDataServices());
            }
            
            // 5. 监控恢复状态
            monitorRecoveryStatus(failedClusters);
            
        } catch (Exception e) {
            logger.error("Disaster recovery failed", e);
            escalateDisasterRecovery(e);
        }
    }
    
    private void initiateFailover(List<FailedService> failedServices) {
        for (FailedService failedService : failedServices) {
            try {
                // 1. 选择备用集群
                Cluster targetCluster = selectFailoverCluster(failedService);
                
                // 2. 启动备份服务
                federatedController.startBackupService(targetCluster, failedService);
                
                // 3. 更新DNS记录
                updateDNSSettings(failedService, targetCluster);
                
                // 4. 重新配置负载均衡器
                reconfigureLoadBalancer(failedService, targetCluster);
                
                // 5. 验证故障转移
                validateFailover(failedService, targetCluster);
                
                logger.info("Failover completed for service {} to cluster {}", 
                    failedService.getName(), targetCluster.getName());
                    
            } catch (Exception e) {
                logger.error("Failover failed for service {}", failedService.getName(), e);
                handleFailoverFailure(failedService, e);
            }
        }
    }
    
    private Cluster selectFailoverCluster(FailedService failedService) {
        // 选择负载最轻、健康状况良好的集群
        List<Cluster> availableClusters = clusterRegistry.getClusters().stream()
            .filter(cluster -> !isClusterFailed(cluster))
            .filter(cluster -> isClusterHealthy(cluster))
            .collect(Collectors.toList());
        
        // 按负载排序
        availableClusters.sort(Comparator.comparingDouble(this::getClusterLoad));
        
        Cluster selectedCluster = availableClusters.get(0);
        
        // 验证集群有足够资源处理故障转移
        if (!hasSufficientCapacity(selectedCluster, failedService)) {
            throw new CapacityException("Insufficient capacity in cluster " + selectedCluster.getName());
        }
        
        return selectedCluster;
    }
}
```

## 总结

容器编排管理系统是现代云原生架构的核心基础设施，通过智能调度、自动化管理、服务网格和跨集群协调等能力，为应用程序提供高可用、可扩展、可观测的运行环境。

### 核心价值

1. **自动化运维**：大幅减少手工运维工作量，提高运维效率
2. **弹性伸缩**：根据负载自动扩缩容，优化资源利用率
3. **故障自愈**：自动检测和恢复故障，提升系统可用性
4. **服务治理**：提供服务发现、负载均衡、流量管理等服务治理能力
5. **跨集群管理**：支持多集群部署和灾难恢复

### 技术要点

- **调度算法**：资源感知、亲和性/反亲和性、优先级调度等
- **生命周期管理**：容器创建、启动、健康检查、重启等全生命周期管理
- **服务网格**：透明的服务通信、流量管理、安全通信等
- **资源管理**：请求/限制、水平/垂直扩缩容、资源配额等
- **多集群**：跨集群资源同步、负载均衡、灾难恢复等

通过构建完善的容器编排管理系统，可以实现云原生应用的高效运维和可靠运行，是现代企业数字化转型的重要基础设施。