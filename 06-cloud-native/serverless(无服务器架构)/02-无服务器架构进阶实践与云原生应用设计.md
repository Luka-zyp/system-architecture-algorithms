# æ— æœåŠ¡å™¨æ¶æ„è¿›é˜¶å®è·µä¸äº‘åŸç”Ÿåº”ç”¨è®¾è®¡

## æ¦‚è¿°

æ— æœåŠ¡å™¨æ¶æ„ï¼ˆServerlessï¼‰å·²æˆä¸ºäº‘åŸç”Ÿåº”ç”¨çš„ä¸»æµæ¨¡å¼ï¼Œä½†è¦åœ¨ç”Ÿäº§ç¯å¢ƒä¸­æˆåŠŸåº”ç”¨ï¼Œéœ€è¦æ·±å…¥ç†è§£å…¶æ¶æ„åŸç†ã€æœ€ä½³å®è·µå’Œé«˜çº§æ¨¡å¼ã€‚æœ¬æ–‡æ¡£æ·±å…¥æ¢è®¨æ— æœåŠ¡å™¨æ¶æ„çš„è¿›é˜¶æŠ€æœ¯ï¼ŒåŒ…æ‹¬äº‹ä»¶é©±åŠ¨æ¶æ„ã€å‡½æ•°ç¼–æ’ã€å¤šäº‘éƒ¨ç½²ã€æˆæœ¬ä¼˜åŒ–ã€æ€§èƒ½è°ƒä¼˜ä»¥åŠå¤§è§„æ¨¡æ— æœåŠ¡å™¨ç³»ç»Ÿçš„è®¾è®¡æ¨¡å¼ã€‚

## é«˜çº§äº‹ä»¶é©±åŠ¨æ¶æ„

### ä¸šåŠ¡åœºæ™¯ï¼šå…¨çƒç”µå•†å¹³å°äº‹ä»¶å¤„ç†ç³»ç»Ÿ

åœ¨è·¨å›½ç”µå•†å¹³å°ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å¤„ç†æ¯ç§’æ•°åä¸‡æ¬¡çš„äº‹ä»¶ï¼ŒåŒ…æ‹¬ç”¨æˆ·è¡Œä¸ºã€åº“å­˜å˜åŒ–ã€è®¢å•çŠ¶æ€æ›´æ–°ç­‰ã€‚è¿™äº›äº‹ä»¶æ¥è‡ªä¸åŒçš„æºç³»ç»Ÿï¼Œéœ€è¦ç»Ÿä¸€çš„äº‹ä»¶é©±åŠ¨æ¶æ„æ¥å¤„ç†ã€è½¬æ¢å’Œè·¯ç”±ã€‚

### äº‹ä»¶é©±åŠ¨æ¶æ„è®¾è®¡

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any, Callable
import asyncio
import json
import time
import uuid
from datetime import datetime, timezone
from enum import Enum
from dataclasses import dataclass, asdict
import logging
from collections import defaultdict, deque

# äº‹ä»¶ç±»å‹æšä¸¾
class EventType(Enum):
    USER_ACTION = "user_action"
    ORDER_EVENT = "order_event"
    INVENTORY_EVENT = "inventory_event"
    PAYMENT_EVENT = "payment_event"
    NOTIFICATION_EVENT = "notification_event"
    ANALYTICS_EVENT = "analytics_event"

# äº‹ä»¶ä¼˜å…ˆçº§
class EventPriority(Enum):
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4

# äº‹ä»¶æ•°æ®æ¨¡å‹
@dataclass
class Event:
    event_id: str
    event_type: EventType
    payload: Dict[str, Any]
    timestamp: float
    source: str
    priority: EventPriority
    correlation_id: Optional[str] = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
        if not self.correlation_id:
            self.correlation_id = str(uuid.uuid4())

# äº‹ä»¶å¤„ç†å™¨æ¥å£
class EventHandler(ABC):
    @abstractmethod
    async def handle_event(self, event: Event) -> bool:
        """å¤„ç†äº‹ä»¶ï¼Œè¿”å›å¤„ç†ç»“æœ"""
        pass
    
    @abstractmethod
    def can_handle(self, event: Event) -> bool:
        """åˆ¤æ–­æ˜¯å¦å¯ä»¥å¤„ç†è¯¥äº‹ä»¶"""
        pass

# äº‹ä»¶è·¯ç”±å™¨
class EventRouter:
    def __init__(self):
        self.handlers: Dict[EventType, List[EventHandler]] = defaultdict(list)
        self.handler_stats = defaultdict(int)
    
    def register_handler(self, event_type: EventType, handler: EventHandler):
        """æ³¨å†Œäº‹ä»¶å¤„ç†å™¨"""
        self.handlers[event_type].append(handler)
        print(f"æ³¨å†Œå¤„ç†å™¨ {handler.__class__.__name__} å¤„ç†äº‹ä»¶ç±»å‹ {event_type.value}")
    
    async def route_event(self, event: Event) -> List[bool]:
        """è·¯ç”±äº‹ä»¶åˆ°å¤„ç†å™¨"""
        results = []
        handlers = self.handlers.get(event.event_type, [])
        
        for handler in handlers:
            try:
                if handler.can_handle(event):
                    result = await handler.handle_event(event)
                    results.append(result)
                    self.handler_stats[handler.__class__.__name__] += 1
            except Exception as e:
                print(f"äº‹ä»¶å¤„ç†å™¨ {handler.__class__.__name__} å¤„ç†å¤±è´¥: {e}")
                results.append(False)
        
        return results

# è®¢å•äº‹ä»¶å¤„ç†å™¨
class OrderEventHandler(EventHandler):
    def __init__(self):
        self.order_processor = OrderProcessor()
    
    def can_handle(self, event: Event) -> bool:
        return event.event_type == EventType.ORDER_EVENT
    
    async def handle_event(self, event: Event) -> bool:
        """å¤„ç†è®¢å•äº‹ä»¶"""
        try:
            order_data = event.payload
            
            if order_data.get('action') == 'create':
                order_id = await self.order_processor.create_order(order_data)
                print(f"åˆ›å»ºè®¢å•: {order_id}")
                
            elif order_data.get('action') == 'update':
                order_id = order_data.get('order_id')
                await self.order_processor.update_order(order_id, order_data)
                print(f"æ›´æ–°è®¢å•: {order_id}")
                
            elif order_data.get('action') == 'cancel':
                order_id = order_data.get('order_id')
                await self.order_processor.cancel_order(order_id)
                print(f"å–æ¶ˆè®¢å•: {order_id}")
            
            return True
            
        except Exception as e:
            print(f"è®¢å•äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
            return False

# åº“å­˜äº‹ä»¶å¤„ç†å™¨
class InventoryEventHandler(EventHandler):
    def __init__(self):
        self.inventory_manager = InventoryManager()
    
    def can_handle(self, event: Event) -> bool:
        return event.event_type == EventType.INVENTORY_EVENT
    
    async def handle_event(self, event: Event) -> bool:
        """å¤„ç†åº“å­˜äº‹ä»¶"""
        try:
            inventory_data = event.payload
            
            if inventory_data.get('action') == 'reserve':
                product_id = inventory_data.get('product_id')
                quantity = inventory_data.get('quantity')
                await self.inventory_manager.reserve_inventory(product_id, quantity)
                
            elif inventory_data.get('action') == 'release':
                product_id = inventory_data.get('product_id')
                quantity = inventory_data.get('quantity')
                await self.inventory_manager.release_inventory(product_id, quantity)
            
            return True
            
        except Exception as e:
            print(f"åº“å­˜äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
            return False

# æ”¯ä»˜äº‹ä»¶å¤„ç†å™¨
class PaymentEventHandler(EventHandler):
    def __init__(self):
        self.payment_processor = PaymentProcessor()
    
    def can_handle(self, event: Event) -> bool:
        return event.event_type == EventType.PAYMENT_EVENT
    
    async def handle_event(self, event: Event) -> bool:
        """å¤„ç†æ”¯ä»˜äº‹ä»¶"""
        try:
            payment_data = event.payload
            
            if payment_data.get('action') == 'authorize':
                payment_id = await self.payment_processor.authorize_payment(payment_data)
                
            elif payment_data.get('action') == 'capture':
                payment_id = payment_data.get('payment_id')
                amount = payment_data.get('amount')
                await self.payment_processor.capture_payment(payment_id, amount)
            
            return True
            
        except Exception as e:
            print(f"æ”¯ä»˜äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
            return False

# é€šçŸ¥äº‹ä»¶å¤„ç†å™¨
class NotificationEventHandler(EventHandler):
    def __init__(self):
        self.notification_service = NotificationService()
    
    def can_handle(self, event: Event) -> bool:
        return event.event_type == EventType.NOTIFICATION_EVENT
    
    async def handle_event(self, event: Event) -> bool:
        """å¤„ç†é€šçŸ¥äº‹ä»¶"""
        try:
            notification_data = event.payload
            notification_type = notification_data.get('type')
            recipient = notification_data.get('recipient')
            message = notification_data.get('message')
            
            await self.notification_service.send_notification(notification_type, recipient, message)
            return True
            
        except Exception as e:
            print(f"é€šçŸ¥äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
            return False

# ä¸šåŠ¡é€»è¾‘å¤„ç†å™¨
class OrderProcessor:
    async def create_order(self, order_data: Dict[str, Any]) -> str:
        """åˆ›å»ºè®¢å•"""
        order_id = f"order_{uuid.uuid4().hex[:8]}"
        print(f"åˆ›å»ºè®¢å•é€»è¾‘: {order_id}")
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        return order_id
    
    async def update_order(self, order_id: str, order_data: Dict[str, Any]):
        """æ›´æ–°è®¢å•"""
        print(f"æ›´æ–°è®¢å•é€»è¾‘: {order_id}")
        await asyncio.sleep(0.05)
    
    async def cancel_order(self, order_id: str):
        """å–æ¶ˆè®¢å•"""
        print(f"å–æ¶ˆè®¢å•é€»è¾‘: {order_id}")
        await asyncio.sleep(0.05)

class InventoryManager:
    async def reserve_inventory(self, product_id: str, quantity: int):
        """é¢„ç•™åº“å­˜"""
        print(f"é¢„ç•™åº“å­˜: {product_id} x {quantity}")
        await asyncio.sleep(0.02)
    
    async def release_inventory(self, product_id: str, quantity: int):
        """é‡Šæ”¾åº“å­˜"""
        print(f"é‡Šæ”¾åº“å­˜: {product_id} x {quantity}")
        await asyncio.sleep(0.02)

class PaymentProcessor:
    async def authorize_payment(self, payment_data: Dict[str, Any]) -> str:
        """æˆæƒæ”¯ä»˜"""
        payment_id = f"payment_{uuid.uuid4().hex[:8]}"
        print(f"æˆæƒæ”¯ä»˜: {payment_id}")
        await asyncio.sleep(0.1)
        return payment_id
    
    async def capture_payment(self, payment_id: str, amount: float):
        """æ•è·æ”¯ä»˜"""
        print(f"æ•è·æ”¯ä»˜: {payment_id} é‡‘é¢: {amount}")
        await asyncio.sleep(0.05)

class NotificationService:
    async def send_notification(self, notification_type: str, recipient: str, message: str):
        """å‘é€é€šçŸ¥"""
        print(f"å‘é€{notification_type}é€šçŸ¥ç»™ {recipient}: {message}")
        await asyncio.sleep(0.03)

# äº‹ä»¶æº¯æºç®¡ç†å™¨
class EventSourcingManager:
    def __init__(self):
        self.event_store = {}  # ç®€åŒ–çš„äº‹ä»¶å­˜å‚¨
        self.event_stream = defaultdict(list)
    
    async def append_event(self, event: Event):
        """è¿½åŠ äº‹ä»¶åˆ°äº‹ä»¶æµ"""
        if event.correlation_id not in self.event_store:
            self.event_store[event.correlation_id] = []
        
        self.event_store[event.correlation_id].append(event)
        self.event_stream[event.event_type].append(event)
        
        print(f"äº‹ä»¶å·²è¿½åŠ : {event.event_id} (å…³è”ID: {event.correlation_id})")
    
    async def get_events_for_aggregate(self, correlation_id: str) -> List[Event]:
        """è·å–èšåˆçš„æ‰€æœ‰äº‹ä»¶"""
        return self.event_store.get(correlation_id, [])
    
    async def replay_events(self, event_type: EventType, from_timestamp: float = 0) -> List[Event]:
        """é‡æ”¾äº‹ä»¶"""
        events = []
        for event in self.event_stream.get(event_type, []):
            if event.timestamp >= from_timestamp:
                events.append(event)
        return events

# äº‹ä»¶ç¼–æ’å™¨
class EventOrchestrator:
    def __init__(self, router: EventRouter, sourcing_manager: EventSourcingManager):
        self.router = router
        self.sourcing_manager = sourcing_manager
        self.orchestration_rules = {}
    
    def add_orchestration_rule(self, trigger_event: EventType, actions: List[Dict[str, Any]]):
        """æ·»åŠ ç¼–æ’è§„åˆ™"""
        self.orchestration_rules[trigger_event] = actions
        print(f"æ·»åŠ ç¼–æ’è§„åˆ™: {trigger_event.value} -> {len(actions)} ä¸ªåŠ¨ä½œ")
    
    async def process_event(self, event: Event) -> List[Event]:
        """å¤„ç†äº‹ä»¶å¹¶è§¦å‘ç¼–æ’åŠ¨ä½œ"""
        # 1. å­˜å‚¨äº‹ä»¶
        await self.sourcing_manager.append_event(event)
        
        # 2. è·¯ç”±åˆ°å¤„ç†å™¨
        await self.router.route_event(event)
        
        # 3. æ‰§è¡Œç¼–æ’è§„åˆ™
        generated_events = []
        rules = self.orchestration_rules.get(event.event_type, [])
        
        for rule in rules:
            new_event = await self._execute_orchestration_rule(event, rule)
            if new_event:
                generated_events.append(new_event)
        
        return generated_events
    
    async def _execute_orchestration_rule(self, trigger_event: Event, rule: Dict[str, Any]) -> Optional[Event]:
        """æ‰§è¡Œç¼–æ’è§„åˆ™"""
        action_type = rule.get('action_type')
        delay = rule.get('delay', 0)
        
        if action_type == 'create_followup_event':
            await asyncio.sleep(delay)
            
            followup_event = Event(
                event_id=str(uuid.uuid4()),
                event_type=EventType(rule.get('event_type')),
                payload=rule.get('payload', {}),
                timestamp=time.time(),
                source='orchestrator',
                priority=EventPriority.NORMAL,
                correlation_id=trigger_event.correlation_id
            )
            
            await self.process_event(followup_event)
            return followup_event
        
        return None

# äº‹ä»¶æº¯æºç¤ºä¾‹
class OrderAggregate:
    def __init__(self, order_id: str):
        self.order_id = order_id
        self.state = 'created'
        self.items = []
        self.total_amount = 0.0
        self.status_history = []
    
    async def handle_event(self, event: Event):
        """æ ¹æ®äº‹ä»¶æ›´æ–°èšåˆçŠ¶æ€"""
        if event.event_type == EventType.ORDER_EVENT:
            action = event.payload.get('action')
            
            if action == 'add_item':
                item = event.payload.get('item')
                self.items.append(item)
                self.total_amount += item.get('price', 0) * item.get('quantity', 1)
                
            elif action == 'confirm_order':
                self.state = 'confirmed'
                self.status_history.append('confirmed')
                
            elif action == 'ship_order':
                self.state = 'shipped'
                self.status_history.append('shipped')
                
            elif action == 'deliver_order':
                self.state = 'delivered'
                self.status_history.append('delivered')
    
    def get_state(self) -> Dict[str, Any]:
        """è·å–èšåˆçŠ¶æ€"""
        return {
            'order_id': self.order_id,
            'state': self.state,
            'items': self.items,
            'total_amount': self.total_amount,
            'status_history': self.status_history
        }

# é«˜çº§äº‹ä»¶æ€»çº¿
class AdvancedEventBus:
    def __init__(self):
        self.subscribers = defaultdict(list)  # äº‹ä»¶ç±»å‹ -> è®¢é˜…è€…åˆ—è¡¨
        self.event_buffer = deque(maxlen=10000)  # äº‹ä»¶ç¼“å†²åŒº
        self.processors = []  # äº‹ä»¶å¤„ç†å™¨é“¾
        self.is_processing = False
        
    def subscribe(self, event_type: EventType, handler: Callable[[Event], Any]):
        """è®¢é˜…äº‹ä»¶"""
        self.subscribers[event_type].append(handler)
        print(f"è®¢é˜…äº‹ä»¶: {event_type.value}")
    
    def add_processor(self, processor: Callable[[Event], Event]):
        """æ·»åŠ äº‹ä»¶å¤„ç†å™¨"""
        self.processors.append(processor)
        print(f"æ·»åŠ äº‹ä»¶å¤„ç†å™¨: {processor.__name__}")
    
    async def publish_event(self, event: Event):
        """å‘å¸ƒäº‹ä»¶"""
        # å¤„ç†äº‹ä»¶ï¼ˆé€šè¿‡å¤„ç†å™¨é“¾ï¼‰
        processed_event = event
        for processor in self.processors:
            processed_event = await processor(processed_event)
        
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.event_buffer.append(processed_event)
        
        # å¼‚æ­¥åˆ†å‘ç»™è®¢é˜…è€…
        asyncio.create_task(self._distribute_event(processed_event))
        
        print(f"å‘å¸ƒäº‹ä»¶: {event.event_id} ({event.event_type.value})")
    
    async def _distribute_event(self, event: Event):
        """åˆ†å‘ç»™è®¢é˜…è€…"""
        subscribers = self.subscribers.get(event.event_type, [])
        
        tasks = []
        for handler in subscribers:
            task = asyncio.create_task(self._invoke_handler(handler, event))
            tasks.append(task)
        
        if tasks:
            await asyncio.gather(*tasks, return_exceptions=True)
    
    async def _invoke_handler(self, handler: Callable[[Event], Any], event: Event):
        """è°ƒç”¨äº‹ä»¶å¤„ç†å™¨"""
        try:
            if asyncio.iscoroutinefunction(handler):
                await handler(event)
            else:
                handler(event)
        except Exception as e:
            print(f"äº‹ä»¶å¤„ç†å™¨æ‰§è¡Œå¤±è´¥: {e}")

# äº‹ä»¶æµå¤„ç†
class EventStreamProcessor:
    def __init__(self, window_size: int = 60):  # 60ç§’çª—å£
        self.window_size = window_size
        self.event_windows = defaultdict(list)
        self.aggregations = {}
    
    async def process_event(self, event: Event):
        """å¤„ç†äº‹ä»¶æµ"""
        current_time = time.time()
        window_start = current_time - self.window_size
        
        # æ·»åŠ åˆ°æ—¶é—´çª—å£
        self.event_windows[event.event_type].append((event.timestamp, event))
        
        # æ¸…ç†è¿‡æœŸäº‹ä»¶
        self.event_windows[event.event_type] = [
            (ts, evt) for ts, evt in self.event_windows[event.event_type] 
            if ts >= window_start
        ]
        
        # æ‰§è¡Œèšåˆ
        await self._aggregate_events(event.event_type)
    
    async def _aggregate_events(self, event_type: EventType):
        """èšåˆäº‹ä»¶"""
        events_in_window = [event for _, event in self.event_windows[event_type]]
        
        if event_type == EventType.USER_ACTION:
            # ç”¨æˆ·è¡Œä¸ºèšåˆ
            user_actions = defaultdict(int)
            for event in events_in_window:
                action = event.payload.get('action')
                user_actions[action] += 1
            
            self.aggregations['user_actions'] = dict(user_actions)
            
        elif event_type == EventType.ORDER_EVENT:
            # è®¢å•èšåˆ
            orders_count = len(events_in_window)
            successful_orders = sum(
                1 for event in events_in_window 
                if event.payload.get('status') == 'success'
            )
            
            self.aggregations['order_metrics'] = {
                'total_orders': orders_count,
                'successful_orders': successful_orders,
                'success_rate': successful_orders / max(orders_count, 1)
            }
    
    def get_aggregations(self) -> Dict[str, Any]:
        """è·å–èšåˆç»“æœ"""
        return self.aggregations

# ä½¿ç”¨ç¤ºä¾‹
async def demonstrate_advanced_event_driven_architecture():
    """æ¼”ç¤ºé«˜çº§äº‹ä»¶é©±åŠ¨æ¶æ„"""
    
    # åˆ›å»ºç»„ä»¶
    router = EventRouter()
    sourcing_manager = EventSourcingManager()
    orchestrator = EventOrchestrator(router, sourcing_manager)
    event_bus = AdvancedEventBus()
    stream_processor = EventStreamProcessor()
    
    # æ³¨å†Œå¤„ç†å™¨
    order_handler = OrderEventHandler()
    inventory_handler = InventoryEventHandler()
    payment_handler = PaymentEventHandler()
    notification_handler = NotificationEventHandler()
    
    router.register_handler(EventType.ORDER_EVENT, order_handler)
    router.register_handler(EventType.INVENTORY_EVENT, inventory_handler)
    router.register_handler(EventType.PAYMENT_EVENT, payment_handler)
    router.register_handler(EventType.NOTIFICATION_EVENT, notification_handler)
    
    # æ·»åŠ äº‹ä»¶æ€»çº¿è®¢é˜…
    async def log_event(event: Event):
        print(f"ğŸ“ è®°å½•äº‹ä»¶: {event.event_type.value}")
    
    event_bus.subscribe(EventType.ORDER_EVENT, log_event)
    event_bus.subscribe(EventType.PAYMENT_EVENT, log_event)
    
    # æ·»åŠ ç¼–æ’è§„åˆ™
    orchestrator.add_orchestration_rule(
        EventType.ORDER_EVENT,
        [
            {
                'action_type': 'create_followup_event',
                'event_type': EventType.PAYMENT_EVENT.value,
                'payload': {'action': 'authorize'},
                'delay': 0.1
            },
            {
                'action_type': 'create_followup_event',
                'event_type': EventType.NOTIFICATION_EVENT.value,
                'payload': {'type': 'email', 'recipient': 'user@example.com', 'message': 'Order created'},
                'delay': 0.2
            }
        ]
    )
    
    # æ¨¡æ‹Ÿäº‹ä»¶æµå¤„ç†
    print("=== é«˜çº§äº‹ä»¶é©±åŠ¨æ¶æ„æ¼”ç¤º ===")
    
    # åˆ›å»ºè®¢å•äº‹ä»¶
    order_event = Event(
        event_id=str(uuid.uuid4()),
        event_type=EventType.ORDER_EVENT,
        payload={
            'action': 'create',
            'order_data': {
                'user_id': 'user_123',
                'items': [
                    {'product_id': 'prod_1', 'quantity': 2, 'price': 99.99},
                    {'product_id': 'prod_2', 'quantity': 1, 'price': 49.99}
                ]
            }
        },
        timestamp=time.time(),
        source='order_service',
        priority=EventPriority.HIGH
    )
    
    # é€šè¿‡ç¼–æ’å™¨å¤„ç†äº‹ä»¶
    followup_events = await orchestrator.process_event(order_event)
    
    # é€šè¿‡äº‹ä»¶æ€»çº¿å‘å¸ƒäº‹ä»¶
    await event_bus.publish_event(order_event)
    
    # å¤„ç†äº‹ä»¶æµ
    await stream_processor.process_event(order_event)
    
    # æ¼”ç¤ºäº‹ä»¶æº¯æº
    print(f"\näº‹ä»¶æº¯æºæ¼”ç¤º:")
    correlation_id = order_event.correlation_id
    events = await sourcing_manager.get_events_for_aggregate(correlation_id)
    print(f"èšåˆ {correlation_id} çš„äº‹ä»¶æ•°é‡: {len(events)}")
    
    # åˆ›å»ºè®¢å•èšåˆç¤ºä¾‹
    order_agg = OrderAggregate("order_001")
    for event in events:
        await order_agg.handle_event(event)
    
    print(f"è®¢å•èšåˆçŠ¶æ€: {order_agg.get_state()}")
    
    # æ˜¾ç¤ºèšåˆç»Ÿè®¡
    print(f"\näº‹ä»¶æµèšåˆç»“æœ:")
    aggregations = stream_processor.get_aggregations()
    for metric, value in aggregations.items():
        print(f"  {metric}: {value}")
    
    # æ˜¾ç¤ºå¤„ç†å™¨ç»Ÿè®¡
    print(f"\nå¤„ç†å™¨ç»Ÿè®¡:")
    for handler_name, count in router.handler_stats.items():
        print(f"  {handler_name}: {count} æ¬¡å¤„ç†")
```

## é«˜çº§å‡½æ•°ç¼–æ’ä¸å·¥ä½œæµ

### ä¸šåŠ¡åœºæ™¯ï¼šå¤æ‚ä¸šåŠ¡æµç¨‹è‡ªåŠ¨åŒ–

åœ¨ä¼ä¸šçº§åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸éœ€è¦å¤„ç†å¤æ‚çš„ä¸šåŠ¡æµç¨‹ï¼Œå¦‚è®¢å•å…¨ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€å®¡æ‰¹æµç¨‹ã€æ•°æ®å¤„ç†æµæ°´çº¿ç­‰ã€‚è¿™äº›æµç¨‹æ¶‰åŠå¤šä¸ªæ­¥éª¤ã€æ¡ä»¶åˆ¤æ–­ã€é”™è¯¯å¤„ç†å’Œäººå·¥å¹²é¢„ã€‚

### å·¥ä½œæµå¼•æ“è®¾è®¡

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any, Union
import asyncio
import json
import time
import uuid
from enum import Enum
from dataclasses import dataclass, field
import logging

# å·¥ä½œæµçŠ¶æ€
class WorkflowStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    CANCELLED = "cancelled"
    PAUSED = "paused"

# æ­¥éª¤ç±»å‹
class StepType(Enum):
    TASK = "task"
    CONDITION = "condition"
    PARALLEL = "parallel"
    LOOP = "loop"
    HUMAN_TASK = "human_task"
    SUB_WORKFLOW = "sub_workflow"
    EVENT = "event"

# æ­¥éª¤çŠ¶æ€
class StepStatus(Enum):
    WAITING = "waiting"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"

# å·¥ä½œæµæ­¥éª¤æ•°æ®æ¨¡å‹
@dataclass
class WorkflowStep:
    step_id: str
    step_type: StepType
    name: str
    config: Dict[str, Any]
    dependencies: List[str] = field(default_factory=list)
    status: StepStatus = StepStatus.WAITING
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    result: Optional[Any] = None
    error_message: Optional[str] = None
    
    def __post_init__(self):
        if not self.dependencies:
            self.dependencies = []

# å·¥ä½œæµæ•°æ®æ¨¡å‹
@dataclass
class Workflow:
    workflow_id: str
    name: str
    version: str
    steps: Dict[str, WorkflowStep]
    status: WorkflowStatus = WorkflowStatus.PENDING
    start_time: Optional[float] = None
    end_time: Optional[float] = None
    context: Dict[str, Any] = field(default_factory=dict)
    error_history: List[Dict[str, Any]] = field(default_factory=list)
    
    def get_executable_steps(self) -> List[WorkflowStep]:
        """è·å–å¯æ‰§è¡Œçš„æ­¥éª¤"""
        completed_step_ids = {
            step.step_id for step in self.steps.values() 
            if step.status == StepStatus.COMPLETED
        }
        
        executable_steps = []
        for step in self.steps.values():
            if step.status == StepStatus.WAITING:
                # æ£€æŸ¥ä¾èµ–æ˜¯å¦å®Œæˆ
                if all(dep_id in completed_step_ids for dep_id in step.dependencies):
                    executable_steps.append(step)
        
        return executable_steps

# æ­¥éª¤æ‰§è¡Œå™¨æ¥å£
class StepExecutor(ABC):
    @abstractmethod
    async def execute(self, step: WorkflowStep, context: Dict[str, Any]) -> Any:
        """æ‰§è¡Œæ­¥éª¤"""
        pass

# ä»»åŠ¡æ­¥éª¤æ‰§è¡Œå™¨
class TaskStepExecutor(StepExecutor):
    async def execute(self, step: WorkflowStep, context: Dict[str, Any]) -> Any:
        """æ‰§è¡Œä»»åŠ¡æ­¥éª¤"""
        task_name = step.config.get('task_name')
        task_params = step.config.get('params', {})
        
        print(f"æ‰§è¡Œä»»åŠ¡: {task_name} (å‚æ•°: {task_params})")
        
        # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
        await asyncio.sleep(0.1)
        
        # åˆå¹¶ä¸Šä¸‹æ–‡
        result = {
            'task_name': task_name,
            'timestamp': time.time(),
            'params': task_params,
            'context_snapshot': context.copy()
        }
        
        context.update(result)
        return result

# æ¡ä»¶æ­¥éª¤æ‰§è¡Œå™¨
class ConditionStepExecutor(StepExecutor):
    async def execute(self, step: WorkflowStep, context: Dict[str, Any]) -> Any:
        """æ‰§è¡Œæ¡ä»¶æ­¥éª¤"""
        condition_expr = step.config.get('condition')
        
        # ç®€åŒ–æ¡ä»¶è¯„ä¼°ï¼ˆå®é™…åº”è¯¥ä½¿ç”¨å®‰å…¨çš„è¡¨è¾¾å¼è§£æå™¨ï¼‰
        result = self._evaluate_condition(condition_expr, context)
        
        print(f"æ¡ä»¶æ­¥éª¤ '{step.name}': {condition_expr} -> {result}")
        
        # æ ¹æ®æ¡ä»¶ç»“æœå†³å®šä¸‹ä¸€æ­¥æ‰§è¡Œ
        context['condition_result'] = result
        
        return {'condition': condition_expr, 'result': result}
    
    def _evaluate_condition(self, condition_expr: str, context: Dict[str, Any]) -> bool:
        """è¯„ä¼°æ¡ä»¶è¡¨è¾¾å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            # å®‰å…¨è¯„ä¼°ï¼ˆä»…ç”¨äºæ¼”ç¤ºï¼Œç”Ÿäº§ç¯å¢ƒéœ€è¦æ›´ä¸¥æ ¼çš„å¤„ç†ï¼‰
            # è¿™é‡Œåªæ˜¯ç®€å•çš„ç¤ºä¾‹ï¼Œå®é™…åº”è¯¥ä½¿ç”¨ä¸“é—¨çš„è¡¨è¾¾å¼å¼•æ“
            if '==' in condition_expr:
                parts = condition_expr.split('==')
                key = parts[0].strip()
                value = parts[1].strip().strip('"\'')
                return str(context.get(key)) == value
            elif '!=' in condition_expr:
                parts = condition_expr.split('!=')
                key = parts[0].strip()
                value = parts[1].strip().strip('"\'')
                return str(context.get(key)) != value
            else:
                return bool(context.get(condition_expr, False))
        except Exception as e:
            print(f"æ¡ä»¶è¯„ä¼°å¤±è´¥: {e}")
            return False

# å¹¶è¡Œæ­¥éª¤æ‰§è¡Œå™¨
class ParallelStepExecutor(StepExecutor):
    def __init__(self, step_executor_factory: Dict[StepType, StepExecutor]):
        self.step_executor_factory = step_executor_factory
    
    async def execute(self, step: WorkflowStep, context: Dict[str, Any]) -> Any:
        """æ‰§è¡Œå¹¶è¡Œæ­¥éª¤"""
        parallel_steps = step.config.get('steps', [])
        
        print(f"å¹¶è¡Œæ‰§è¡Œ {len(parallel_steps)} ä¸ªæ­¥éª¤")
        
        # åˆ›å»ºå­å·¥ä½œæµ
        sub_workflow = self._create_sub_workflow(step.step_id, parallel_steps)
        
        # å¹¶è¡Œæ‰§è¡Œ
        tasks = []
        for sub_step in sub_workflow.steps.values():
            executor = self.step_executor_factory.get(sub_step.step_type)
            if executor:
                task = asyncio.create_task(executor.execute(sub_step, context))
                tasks.append((sub_step.step_id, task))
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = {}
        for step_id, task in tasks:
            try:
                result = await task
                results[step_id] = result
            except Exception as e:
                results[step_id] = {'error': str(e)}
        
        return {'parallel_results': results}
    
    def _create_sub_workflow(self, parent_step_id: str, step_configs: List[Dict[str, Any]]) -> Workflow:
        """åˆ›å»ºå­å·¥ä½œæµ"""
        steps = {}
        for i, config in enumerate(step_configs):
            step_id = f"{parent_step_id}_sub_{i}"
            step = WorkflowStep(
                step_id=step_id,
                step_type=StepType(config.get('type', 'task')),
                name=config.get('name', f'Sub step {i}'),
                config=config.get('config', {})
            )
            steps[step_id] = step
        
        return Workflow(
            workflow_id=f"sub_workflow_{parent_step_id}",
            name=f"Sub workflow for {parent_step_id}",
            version="1.0",
            steps=steps
        )

# å¾ªç¯æ­¥éª¤æ‰§è¡Œå™¨
class LoopStepExecutor(StepExecutor):
    def __init__(self, step_executor_factory: Dict[StepType, StepExecutor]):
        self.step_executor_factory = step_executor_factory
    
    async def execute(self, step: WorkflowStep, context: Dict[str, Any]) -> Any:
        """æ‰§è¡Œå¾ªç¯æ­¥éª¤"""
        loop_config = step.config
        loop_type = loop_config.get('loop_type')  # 'while', 'for', 'foreach'
        max_iterations = loop_config.get('max_iterations', 10)
        loop_condition = loop_config.get('condition')
        loop_body = loop_config.get('body', [])
        
        print(f"å¼€å§‹å¾ªç¯: {loop_type} (æœ€å¤§è¿­ä»£: {max_iterations})")
        
        iteration_results = []
        iteration_count = 0
        
        # ä¿å­˜åŸå§‹ä¸Šä¸‹æ–‡
        original_context = context.copy()
        
        try:
            while iteration_count < max_iterations:
                # æ£€æŸ¥å¾ªç¯æ¡ä»¶
                if loop_type == 'while':
                    if not self._evaluate_condition(loop_condition, context):
                        break
                
                # åˆ›å»ºå¾ªç¯ä½“å·¥ä½œæµ
                loop_workflow = self._create_loop_workflow(step.step_id, loop_body)
                
                # æ‰§è¡Œå¾ªç¯ä½“
                loop_results = []
                for loop_step in loop_workflow.steps.values():
                    executor = self.step_executor_factory.get(loop_step.step_type)
                    if executor:
                        result = await executor.execute(loop_step, context)
                        loop_results.append(result)
                
                iteration_results.append({
                    'iteration': iteration_count,
                    'results': loop_results,
                    'context_snapshot': context.copy()
                })
                
                iteration_count += 1
                
                # å¯¹äºforeachå¾ªç¯ï¼Œæ£€æŸ¥æ˜¯å¦è¿˜æœ‰å…ƒç´ éœ€è¦å¤„ç†
                if loop_type == 'foreach':
                    collection = context.get(loop_condition, [])
                    if iteration_count >= len(collection):
                        break
            
            return {
                'total_iterations': iteration_count,
                'iteration_results': iteration_results
            }
            
        finally:
            # æ¢å¤åŸå§‹ä¸Šä¸‹æ–‡
            context.clear()
            context.update(original_context)
    
    def _evaluate_condition(self, condition_expr: str, context: Dict[str, Any]) -> bool:
        """è¯„ä¼°å¾ªç¯æ¡ä»¶"""
        # ä¸ConditionStepExecutorç±»ä¼¼çš„æ¡ä»¶è¯„ä¼°é€»è¾‘
        try:
            return bool(context.get(condition_expr, False))
        except Exception as e:
            print(f"å¾ªç¯æ¡ä»¶è¯„ä¼°å¤±è´¥: {e}")
            return False
    
    def _create_loop_workflow(self, parent_step_id: str, body_configs: List[Dict[str, Any]]) -> Workflow:
        """åˆ›å»ºå¾ªç¯ä½“å·¥ä½œæµ"""
        steps = {}
        for i, config in enumerate(body_configs):
            step_id = f"{parent_step_id}_loop_{i}"
            step = WorkflowStep(
                step_id=step_id,
                step_type=StepType(config.get('type', 'task')),
                name=config.get('name', f'Loop step {i}'),
                config=config.get('config', {})
            )
            steps[step_id] = step
        
        return Workflow(
            workflow_id=f"loop_workflow_{parent_step_id}",
            name=f"Loop workflow for {parent_step_id}",
            version="1.0",
            steps=steps
        )

# äººå·¥ä»»åŠ¡æ­¥éª¤æ‰§è¡Œå™¨
class HumanTaskStepExecutor(StepExecutor):
    def __init__(self, task_queue: asyncio.Queue):
        self.task_queue = task_queue
    
    async def execute(self, step: WorkflowStep, context: Dict[str, Any]) -> Any:
        """æ‰§è¡Œäººå·¥ä»»åŠ¡"""
        task_description = step.config.get('description')
        approvers = step.config.get('approvers', [])
        timeout_seconds = step.config.get('timeout', 300)
        
        print(f"äººå·¥ä»»åŠ¡: {task_description}")
        print(f"å¾…å®¡æ‰¹äºº: {approvers}")
        
        # æ¨¡æ‹Ÿä»»åŠ¡é˜Ÿåˆ—å¤„ç†
        human_task = {
            'step_id': step.step_id,
            'description': task_description,
            'approvers': approvers,
            'context': context.copy(),
            'timestamp': time.time()
        }
        
        await self.task_queue.put(human_task)
        
        # æ¨¡æ‹Ÿç­‰å¾…äººå·¥å®¡æ‰¹
        try:
            response = await asyncio.wait_for(self.task_queue.get(), timeout=timeout_seconds)
            print(f"äººå·¥ä»»åŠ¡å®Œæˆ: {response}")
            return response
        except asyncio.TimeoutError:
            raise Exception(f"äººå·¥ä»»åŠ¡è¶…æ—¶ ({timeout_seconds}ç§’)")

# å·¥ä½œæµæ‰§è¡Œå¼•æ“
class WorkflowEngine:
    def __init__(self):
        self.step_executor_factory = {
            StepType.TASK: TaskStepExecutor(),
            StepType.CONDITION: ConditionStepExecutor(),
            StepType.PARALLEL: ParallelStepExecutor(self.step_executor_factory),
            StepType.LOOP: LoopStepExecutor(self.step_executor_factory),
            StepType.HUMAN_TASK: HumanTaskStepExecutor(asyncio.Queue())
        }
        self.workflows: Dict[str, Workflow] = {}
        self.execution_history = []
    
    async def execute_workflow(self, workflow: Workflow) -> Dict[str, Any]:
        """æ‰§è¡Œå·¥ä½œæµ"""
        workflow.status = WorkflowStatus.RUNNING
        workflow.start_time = time.time()
        workflow_id = workflow.workflow_id
        
        print(f"å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {workflow.name} ({workflow_id})")
        
        try:
            while True:
                # è·å–å¯æ‰§è¡Œçš„æ­¥éª¤
                executable_steps = workflow.get_executable_steps()
                
                if not executable_steps:
                    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ­¥éª¤éƒ½å·²å®Œæˆ
                    if all(step.status == StepStatus.COMPLETED for step in workflow.steps.values()):
                        workflow.status = WorkflowStatus.SUCCESS
                        break
                    else:
                        # æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„æ­¥éª¤
                        failed_steps = [step for step in workflow.steps.values() if step.status == StepStatus.FAILED]
                        if failed_steps:
                            workflow.status = WorkflowStatus.FAILED
                            break
                        else:
                            # æ²¡æœ‰å¯æ‰§è¡Œæ­¥éª¤ä½†æœªå®Œæˆï¼ˆå¯èƒ½æ˜¯æ­»é”ï¼‰
                            raise Exception("å·¥ä½œæµæ­»é”ï¼šæ²¡æœ‰å¯æ‰§è¡Œæ­¥éª¤")
                
                # å¹¶è¡Œæ‰§è¡Œå¯æ‰§è¡Œçš„æ­¥éª¤
                for step in executable_steps:
                    await self._execute_step(workflow, step)
            
            workflow.end_time = time.time()
            duration = workflow.end_time - workflow.start_time
            
            result = {
                'workflow_id': workflow_id,
                'status': workflow.status.value,
                'duration_seconds': duration,
                'context': workflow.context
            }
            
            print(f"å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {workflow.status.value} (è€—æ—¶: {duration:.2f}ç§’)")
            return result
            
        except Exception as e:
            workflow.status = WorkflowStatus.FAILED
            workflow.end_time = time.time()
            workflow.error_history.append({
                'timestamp': time.time(),
                'error': str(e)
            })
            
            print(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    async def _execute_step(self, workflow: Workflow, step: WorkflowStep):
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        step.status = StepStatus.RUNNING
        step.start_time = time.time()
        
        executor = self.step_executor_factory.get(step.step_type)
        if not executor:
            raise Exception(f"æœªæ‰¾åˆ°æ­¥éª¤ç±»å‹ {step.step_type} çš„æ‰§è¡Œå™¨")
        
        try:
            print(f"æ‰§è¡Œæ­¥éª¤: {step.name} ({step.step_type.value})")
            
            result = await executor.execute(step, workflow.context)
            
            step.status = StepStatus.COMPLETED
            step.result = result
            step.end_time = time.time()
            
            duration = step.end_time - step.start_time
            print(f"æ­¥éª¤å®Œæˆ: {step.name} (è€—æ—¶: {duration:.2f}ç§’)")
            
        except Exception as e:
            step.status = StepStatus.FAILED
            step.error_message = str(e)
            step.end_time = time.time()
            
            print(f"æ­¥éª¤å¤±è´¥: {step.name} - {e}")
            raise
    
    def add_workflow(self, workflow: Workflow):
        """æ·»åŠ å·¥ä½œæµ"""
        self.workflows[workflow.workflow_id] = workflow
        print(f"æ·»åŠ å·¥ä½œæµ: {workflow.name} ({workflow.workflow_id})")
    
    def get_workflow_status(self, workflow_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµçŠ¶æ€"""
        workflow = self.workflows.get(workflow_id)
        if not workflow:
            return None
        
        return {
            'workflow_id': workflow.workflow_id,
            'name': workflow.name,
            'status': workflow.status.value,
            'start_time': workflow.start_time,
            'end_time': workflow.end_time,
            'total_steps': len(workflow.steps),
            'completed_steps': sum(1 for step in workflow.steps.values() if step.status == StepStatus.COMPLETED),
            'failed_steps': sum(1 for step in workflow.steps.values() if step.status == StepStatus.FAILED)
        }

# å·¥ä½œæµæ¨¡æ¿ç®¡ç†å™¨
class WorkflowTemplateManager:
    def __init__(self, workflow_engine: WorkflowEngine):
        self.workflow_engine = workflow_engine
        self.templates = {}
    
    def create_order_processing_workflow(self) -> Workflow:
        """åˆ›å»ºè®¢å•å¤„ç†å·¥ä½œæµ"""
        steps = {}
        
        # 1. éªŒè¯è®¢å•
        steps['validate_order'] = WorkflowStep(
            step_id='validate_order',
            step_type=StepType.TASK,
            name='éªŒè¯è®¢å•',
            config={
                'task_name': 'validate_order',
                'params': {'validation_rules': ['user_exists', 'items_available']}
            }
        )
        
        # 2. æ¡ä»¶åˆ†æ”¯ï¼šæ˜¯å¦éœ€è¦å®¡æ‰¹
        steps['check_approval'] = WorkflowStep(
            step_id='check_approval',
            step_type=StepType.CONDITION,
            name='æ£€æŸ¥æ˜¯å¦éœ€è¦å®¡æ‰¹',
            config={
                'condition': 'total_amount > 1000'
            },
            dependencies=['validate_order']
        )
        
        # 3. å¹¶è¡Œå¤„ç†ï¼šåº“å­˜æ£€æŸ¥å’Œæ”¯ä»˜å¤„ç†
        steps['parallel_processing'] = WorkflowStep(
            step_id='parallel_processing',
            step_type=StepType.PARALLEL,
            name='å¹¶è¡Œå¤„ç†åº“å­˜å’Œæ”¯ä»˜',
            config={
                'steps': [
                    {
                        'type': 'task',
                        'name': 'åº“å­˜æ£€æŸ¥',
                        'config': {
                            'task_name': 'check_inventory',
                            'params': {}
                        }
                    },
                    {
                        'type': 'task',
                        'name': 'å¤„ç†æ”¯ä»˜',
                        'config': {
                            'task_name': 'process_payment',
                            'params': {}
                        }
                    }
                ]
            },
            dependencies=['check_approval']
        )
        
        # 4. å¾ªç¯å‘é€é€šçŸ¥ï¼ˆæœ€å¤šé‡è¯•3æ¬¡ï¼‰
        steps['notification_loop'] = WorkflowStep(
            step_id='notification_loop',
            step_type=StepType.LOOP,
            name='å‘é€é€šçŸ¥ï¼ˆæœ€å¤šé‡è¯•3æ¬¡ï¼‰',
            config={
                'loop_type': 'while',
                'max_iterations': 3,
                'condition': 'notification_sent == False',
                'body': [
                    {
                        'type': 'task',
                        'name': 'å‘é€é‚®ä»¶é€šçŸ¥',
                        'config': {
                            'task_name': 'send_email_notification',
                            'params': {}
                        }
                    }
                ]
            },
            dependencies=['parallel_processing']
        )
        
        # 5. äººå·¥ä»»åŠ¡ï¼šæœ€ç»ˆç¡®è®¤
        steps['human_confirmation'] = WorkflowStep(
            step_id='human_confirmation',
            step_type=StepType.HUMAN_TASK,
            name='æœ€ç»ˆç¡®è®¤',
            config={
                'description': 'è¯·ç¡®è®¤è®¢å•å¯ä»¥å‘è´§',
                'approvers': ['manager@company.com'],
                'timeout': 1800
            },
            dependencies=['notification_loop']
        )
        
        # 6. å®Œæˆè®¢å•
        steps['complete_order'] = WorkflowStep(
            step_id='complete_order',
            step_type=StepType.TASK,
            name='å®Œæˆè®¢å•',
            config={
                'task_name': 'complete_order',
                'params': {}
            },
            dependencies=['human_confirmation']
        )
        
        return Workflow(
            workflow_id=f"order_processing_{int(time.time())}",
            name="è®¢å•å¤„ç†å·¥ä½œæµ",
            version="1.0",
            steps=steps,
            context={
                'total_amount': 500.0,
                'user_id': 'user_123',
                'order_items': [
                    {'product_id': 'prod_1', 'quantity': 2},
                    {'product_id': 'prod_2', 'quantity': 1}
                ]
            }
        )
    
    def create_data_processing_pipeline(self) -> Workflow:
        """åˆ›å»ºæ•°æ®å¤„ç†æµæ°´çº¿å·¥ä½œæµ"""
        steps = {}
        
        # 1. è¯»å–æ•°æ®
        steps['read_data'] = WorkflowStep(
            step_id='read_data',
            step_type=StepType.TASK,
            name='è¯»å–æ•°æ®æº',
            config={
                'task_name': 'read_data_source',
                'params': {'source': 'database', 'query': 'SELECT * FROM users'}
            }
        )
        
        # 2. æ•°æ®æ¸…æ´—å¾ªç¯
        steps['data_cleaning_loop'] = WorkflowStep(
            step_id='data_cleaning_loop',
            step_type=StepType.LOOP,
            name='æ•°æ®æ¸…æ´—',
            config={
                'loop_type': 'foreach',
                'condition': 'data_records',
                'body': [
                    {
                        'type': 'task',
                        'name': 'æ¸…æ´—å•æ¡è®°å½•',
                        'config': {
                            'task_name': 'clean_data_record',
                            'params': {}
                        }
                    }
                ]
            },
            dependencies=['read_data']
        )
        
        # 3. æ•°æ®éªŒè¯
        steps['validate_data'] = WorkflowStep(
            step_id='validate_data',
            step_type=StepType.CONDITION,
            name='éªŒè¯æ•°æ®è´¨é‡',
            config={
                'condition': 'validation_passed == True'
            },
            dependencies=['data_cleaning_loop']
        )
        
        # 4. å¹¶è¡Œå¤„ç†ï¼šåˆ†æå’Œè½¬æ¢
        steps['parallel_analysis'] = WorkflowStep(
            step_id='parallel_analysis',
            step_type=StepType.PARALLEL,
            name='å¹¶è¡Œåˆ†æå’Œè½¬æ¢',
            config={
                'steps': [
                    {
                        'type': 'task',
                        'name': 'æ•°æ®åˆ†æ',
                        'config': {
                            'task_name': 'analyze_data',
                            'params': {'analysis_type': 'statistical'}
                        }
                    },
                    {
                        'type': 'task',
                        'name': 'æ•°æ®è½¬æ¢',
                        'config': {
                            'task_name': 'transform_data',
                            'params': {'format': 'json'}
                        }
                    }
                ]
            },
            dependencies=['validate_data']
        )
        
        # 5. ä¿å­˜ç»“æœ
        steps['save_results'] = WorkflowStep(
            step_id='save_results',
            step_type=StepType.TASK,
            name='ä¿å­˜å¤„ç†ç»“æœ',
            config={
                'task_name': 'save_processed_data',
                'params': {'destination': 'data_warehouse'}
            },
            dependencies=['parallel_analysis']
        )
        
        return Workflow(
            workflow_id=f"data_pipeline_{int(time.time())}",
            name="æ•°æ®å¤„ç†æµæ°´çº¿",
            version="1.0",
            steps=steps,
            context={
                'data_records': [
                    {'id': 1, 'name': 'Alice', 'email': 'alice@example.com'},
                    {'id': 2, 'name': 'Bob', 'email': 'bob@example.com'},
                    {'id': 3, 'name': 'Charlie', 'email': 'charlie@example.com'}
                ],
                'validation_passed': True
            }
        )

# ä½¿ç”¨ç¤ºä¾‹
async def demonstrate_advanced_workflow_engine():
    """æ¼”ç¤ºé«˜çº§å·¥ä½œæµå¼•æ“"""
    
    # åˆ›å»ºå·¥ä½œæµå¼•æ“
    engine = WorkflowEngine()
    template_manager = WorkflowTemplateManager(engine)
    
    print("=== é«˜çº§å·¥ä½œæµå¼•æ“æ¼”ç¤º ===")
    
    # åˆ›å»ºè®¢å•å¤„ç†å·¥ä½œæµ
    order_workflow = template_manager.create_order_processing_workflow()
    
    # æ·»åŠ å’Œæ‰§è¡Œå·¥ä½œæµ
    engine.add_workflow(order_workflow)
    
    print(f"\nå¼€å§‹æ‰§è¡Œè®¢å•å¤„ç†å·¥ä½œæµ:")
    try:
        result = await engine.execute_workflow(order_workflow)
        print(f"å·¥ä½œæµæ‰§è¡Œç»“æœ: {result}")
    except Exception as e:
        print(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
    
    # æ˜¾ç¤ºå·¥ä½œæµçŠ¶æ€
    print(f"\nå·¥ä½œæµçŠ¶æ€:")
    status = engine.get_workflow_status(order_workflow.workflow_id)
    if status:
        for key, value in status.items():
            print(f"  {key}: {value}")
    
    # åˆ›å»ºæ•°æ®å¤„ç†æµæ°´çº¿
    print(f"\n" + "="*50)
    data_workflow = template_manager.create_data_processing_pipeline()
    
    engine.add_workflow(data_workflow)
    
    print(f"\nå¼€å§‹æ‰§è¡Œæ•°æ®å¤„ç†æµæ°´çº¿:")
    try:
        result = await engine.execute_workflow(data_workflow)
        print(f"æµæ°´çº¿æ‰§è¡Œç»“æœ: {result}")
    except Exception as e:
        print(f"æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
    
    # æ˜¾ç¤ºæ­¥éª¤è¯¦æƒ…
    print(f"\næ­¥éª¤æ‰§è¡Œè¯¦æƒ…:")
    for step_id, step in order_workflow.steps.items():
        print(f"  {step.name}:")
        print(f"    çŠ¶æ€: {step.status.value}")
        print(f"    è€—æ—¶: {step.end_time - step.start_time:.2f}s" if step.end_time else "    è€—æ—¶: N/A")
        if step.result:
            print(f"    ç»“æœ: {step.result}")
        if step.error_message:
            print(f"    é”™è¯¯: {step.error_message}")
```

## å¤šäº‘éƒ¨ç½²ç­–ç•¥

### äº‘æœåŠ¡æŠ½è±¡å±‚

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Any
import asyncio
import json

# äº‘æœåŠ¡æä¾›å•†æšä¸¾
class CloudProvider(Enum):
    AWS = "aws"
    AZURE = "azure"
    GCP = "gcp"
    ALIBABA = "alibaba"

# æœåŠ¡ç±»å‹æšä¸¾
class ServiceType(Enum):
    FUNCTION = "function"
    STORAGE = "storage"
    DATABASE = "database"
    MESSAGE_QUEUE = "message_queue"
    API_GATEWAY = "api_gateway"
    MONITORING = "monitoring"

# äº‘æœåŠ¡æŠ½è±¡æ¥å£
class CloudService(ABC):
    @abstractmethod
    async def deploy(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éƒ¨ç½²æœåŠ¡"""
        pass
    
    @abstractmethod
    async def update(self, service_id: str, config: Dict[str, Any]) -> bool:
        """æ›´æ–°æœåŠ¡"""
        pass
    
    @abstractmethod
    async def delete(self, service_id: str) -> bool:
        """åˆ é™¤æœåŠ¡"""
        pass
    
    @abstractmethod
    async def get_status(self, service_id: str) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        pass

# AWS Lambdaå‡½æ•°æœåŠ¡
class AWSLambdaService(CloudService):
    def __init__(self, region: str = "us-east-1"):
        self.region = region
        self.client = None  # æ¨¡æ‹ŸAWS SDKå®¢æˆ·ç«¯
    
    async def deploy(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éƒ¨ç½²Lambdaå‡½æ•°"""
        function_name = config.get('function_name')
        runtime = config.get('runtime', 'python3.9')
        handler = config.get('handler', 'index.handler')
        code_path = config.get('code_path')
        
        print(f"éƒ¨ç½²AWS Lambdaå‡½æ•°: {function_name}")
        print(f"  Runtime: {runtime}")
        print(f"  Handler: {handler}")
        
        # æ¨¡æ‹Ÿéƒ¨ç½²è¿‡ç¨‹
        await asyncio.sleep(1)
        
        function_id = f"arn:aws:lambda:{self.region}:123456789012:function:{function_name}"
        
        return {
            'service_id': function_id,
            'service_type': ServiceType.FUNCTION.value,
            'provider': CloudProvider.AWS.value,
            'status': 'deployed',
            'region': self.region,
            'function_name': function_name,
            'runtime': runtime
        }
    
    async def update(self, service_id: str, config: Dict[str, Any]) -> bool:
        """æ›´æ–°Lambdaå‡½æ•°"""
        print(f"æ›´æ–°AWS Lambdaå‡½æ•°: {service_id}")
        await asyncio.sleep(0.5)
        return True
    
    async def delete(self, service_id: str) -> bool:
        """åˆ é™¤Lambdaå‡½æ•°"""
        print(f"åˆ é™¤AWS Lambdaå‡½æ•°: {service_id}")
        await asyncio.sleep(0.3)
        return True
    
    async def get_status(self, service_id: str) -> Dict[str, Any]:
        """è·å–Lambdaå‡½æ•°çŠ¶æ€"""
        return {
            'service_id': service_id,
            'status': 'active',
            'invocations': 1234,
            'errors': 2,
            'last_invocation': '2024-01-15T10:30:00Z'
        }

# Azure FunctionsæœåŠ¡
class AzureFunctionsService(CloudService):
    def __init__(self, resource_group: str, location: str = "East US"):
        self.resource_group = resource_group
        self.location = location
    
    async def deploy(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éƒ¨ç½²Azure Function"""
        function_name = config.get('function_name')
        storage_account = config.get('storage_account')
        
        print(f"éƒ¨ç½²Azure Function: {function_name}")
        print(f"  èµ„æºç»„: {self.resource_group}")
        print(f"  ä½ç½®: {self.location}")
        
        await asyncio.sleep(1.2)
        
        function_id = f"/subscriptions/12345678-1234-1234-1234-123456789012/resourceGroups/{self.resource_group}/providers/Microsoft.Web/sites/{function_name}"
        
        return {
            'service_id': function_id,
            'service_type': ServiceType.FUNCTION.value,
            'provider': CloudProvider.AZURE.value,
            'status': 'deployed',
            'resource_group': self.resource_group,
            'location': self.location,
            'function_name': function_name
        }
    
    async def update(self, service_id: str, config: Dict[str, Any]) -> bool:
        """æ›´æ–°Azure Function"""
        print(f"æ›´æ–°Azure Function: {service_id}")
        await asyncio.sleep(0.6)
        return True
    
    async def delete(self, service_id: str) -> bool:
        """åˆ é™¤Azure Function"""
        print(f"åˆ é™¤Azure Function: {service_id}")
        await asyncio.sleep(0.4)
        return True
    
    async def get_status(self, service_id: str) -> Dict[str, Any]:
        """è·å–Azure FunctionçŠ¶æ€"""
        return {
            'service_id': service_id,
            'status': 'running',
            'average_response_time': '150ms',
            'total_invocations': 567
        }

# Google Cloud FunctionsæœåŠ¡
class GCPCloudFunctionsService(CloudService):
    def __init__(self, project_id: str, region: str = "us-central1"):
        self.project_id = project_id
        self.region = region
    
    async def deploy(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """éƒ¨ç½²Google Cloud Function"""
        function_name = config.get('function_name')
        entry_point = config.get('entry_point', 'main')
        trigger_type = config.get('trigger_type', 'http')
        
        print(f"éƒ¨ç½²Google Cloud Function: {function_name}")
        print(f"  é¡¹ç›®ID: {self.project_id}")
        print(f"  è§¦å‘å™¨ç±»å‹: {trigger_type}")
        
        await asyncio.sleep(0.8)
        
        function_id = f"projects/{self.project_id}/locations/{self.region}/functions/{function_name}"
        
        return {
            'service_id': function_id,
            'service_type': ServiceType.FUNCTION.value,
            'provider': CloudProvider.GCP.value,
            'status': 'deployed',
            'project_id': self.project_id,
            'region': self.region,
            'function_name': function_name,
            'entry_point': entry_point,
            'trigger_type': trigger_type
        }
    
    async def update(self, service_id: str, config: Dict[str, Any]) -> bool:
        """æ›´æ–°Cloud Function"""
        print(f"æ›´æ–°Google Cloud Function: {service_id}")
        await asyncio.sleep(0.4)
        return True
    
    async def delete(self, service_id: str) -> bool:
        """åˆ é™¤Cloud Function"""
        print(f"åˆ é™¤Google Cloud Function: {service_id}")
        await asyncio.sleep(0.2)
        return True
    
    async def get_status(self, service_id: str) -> Dict[str, Any]:
        """è·å–Cloud FunctionçŠ¶æ€"""
        return {
            'service_id': service_id,
            'status': 'active',
            'memory_usage': '128MB',
            'execution_count': 890
        }

# å¤šäº‘ç®¡ç†æ§åˆ¶å™¨
class MultiCloudManager:
    def __init__(self):
        self.providers = {
            CloudProvider.AWS: {
                ServiceType.FUNCTION: AWSLambdaService(),
                ServiceType.STORAGE: None,  # å¯ä»¥æ·»åŠ æ›´å¤šæœåŠ¡
                ServiceType.DATABASE: None,
                ServiceType.MESSAGE_QUEUE: None,
                ServiceType.API_GATEWAY: None,
                ServiceType.MONITORING: None
            },
            CloudProvider.AZURE: {
                ServiceType.FUNCTION: AzureFunctionsService('my-resource-group'),
                ServiceType.STORAGE: None,
                ServiceType.DATABASE: None,
                ServiceType.MESSAGE_QUEUE: None,
                ServiceType.API_GATEWAY: None,
                ServiceType.MONITORING: None
            },
            CloudProvider.GCP: {
                ServiceType.FUNCTION: GCPCloudFunctionsService('my-gcp-project'),
                ServiceType.STORAGE: None,
                ServiceType.DATABASE: None,
                ServiceType.MESSAGE_QUEUE: None,
                ServiceType.API_GATEWAY: None,
                ServiceType.MONITORING: None
            }
        }
        self.deployed_services = {}  # service_id -> service_info
    
    async def deploy_multi_cloud_service(self, 
                                       service_config: Dict[str, Any]) -> Dict[str, Any]:
        """éƒ¨ç½²å¤šäº‘æœåŠ¡"""
        service_name = service_config.get('name')
        service_type = ServiceType(service_config.get('service_type'))
        target_providers = [CloudProvider(p) for p in service_config.get('providers', [])]
        deployment_strategy = service_config.get('deployment_strategy', 'all')
        
        print(f"å¼€å§‹å¤šäº‘éƒ¨ç½²: {service_name}")
        print(f"æœåŠ¡ç±»å‹: {service_type.value}")
        print(f"ç›®æ ‡äº‘æä¾›å•†: {[p.value for p in target_providers]}")
        print(f"éƒ¨ç½²ç­–ç•¥: {deployment_strategy}")
        
        deployment_results = {}
        
        if deployment_strategy == 'all':
            # éƒ¨ç½²åˆ°æ‰€æœ‰ç›®æ ‡äº‘æä¾›å•†
            for provider in target_providers:
                service = self.providers[provider][service_type]
                if service:
                    try:
                        result = await service.deploy(service_config)
                        service_id = result['service_id']
                        self.deployed_services[service_id] = result
                        deployment_results[provider.value] = result
                        print(f"âœ“ {provider.value} éƒ¨ç½²æˆåŠŸ")
                    except Exception as e:
                        deployment_results[provider.value] = {'error': str(e)}
                        print(f"âœ— {provider.value} éƒ¨ç½²å¤±è´¥: {e}")
        
        elif deployment_strategy == 'primary_backup':
            # ä¸»å¤‡éƒ¨ç½²
            primary_provider = target_providers[0]
            backup_provider = target_providers[1] if len(target_providers) > 1 else None
            
            # éƒ¨ç½²ä¸»æœåŠ¡
            primary_service = self.providers[primary_provider][service_type]
            if primary_service:
                primary_result = await primary_service.deploy(service_config)
                self.deployed_services[primary_result['service_id']] = primary_result
                deployment_results['primary'] = primary_result
                print(f"âœ“ ä¸»æœåŠ¡éƒ¨ç½²æˆåŠŸ: {primary_provider.value}")
            
            # éƒ¨ç½²å¤‡ä»½æœåŠ¡ï¼ˆå¦‚æœæ˜¯å¼‚æ­¥å¤‡ä»½ï¼‰
            if backup_provider and service_config.get('async_backup'):
                backup_service = self.providers[backup_provider][service_type]
                if backup_service:
                    backup_config = service_config.copy()
                    backup_config['name'] = f"{service_name}_backup"
                    backup_result = await backup_service.deploy(backup_config)
                    self.deployed_services[backup_result['service_id']] = backup_result
                    deployment_results['backup'] = backup_result
                    print(f"âœ“ å¤‡ä»½æœåŠ¡éƒ¨ç½²æˆåŠŸ: {backup_provider.value}")
        
        elif deployment_strategy == 'load_balanced':
            # è´Ÿè½½å‡è¡¡éƒ¨ç½²
            for i, provider in enumerate(target_providers):
                service = self.providers[provider][service_type]
                if service:
                    service_config_copy = service_config.copy()
                    service_config_copy['name'] = f"{service_name}_instance_{i}"
                    
                    result = await service.deploy(service_config_copy)
                    self.deployed_services[result['service_id']] = result
                    deployment_results[f'instance_{i}'] = result
                    print(f"âœ“ å®ä¾‹ {i} éƒ¨ç½²æˆåŠŸ: {provider.value}")
        
        return {
            'service_name': service_name,
            'deployment_results': deployment_results,
            'total_instances': len(deployment_results),
            'successful_deployments': sum(1 for r in deployment_results.values() if 'error' not in r)
        }
    
    async def health_check_all_services(self) -> Dict[str, Dict[str, Any]]:
        """æ£€æŸ¥æ‰€æœ‰æœåŠ¡å¥åº·çŠ¶æ€"""
        print("æ‰§è¡Œå…¨äº‘å¥åº·æ£€æŸ¥...")
        
        health_status = {}
        for service_id, service_info in self.deployed_services.items():
            try:
                provider = CloudProvider(service_info['provider'])
                service_type = ServiceType(service_info['service_type'])
                service = self.providers[provider][service_type]
                
                if service:
                    status = await service.get_status(service_id)
                    health_status[service_id] = status
                    
                    status_icon = "âœ“" if status.get('status') in ['active', 'running', 'deployed'] else "âœ—"
                    print(f"{status_icon} {service_info['provider']} - {service_info.get('function_name', 'Unknown')}: {status.get('status', 'Unknown')}")
                    
            except Exception as e:
                health_status[service_id] = {'error': str(e)}
                print(f"âœ— æ£€æŸ¥æœåŠ¡ {service_id} å¤±è´¥: {e}")
        
        return health_status
    
    async def update_service_across_clouds(self, 
                                         service_pattern: str, 
                                         new_config: Dict[str, Any]) -> Dict[str, Any]:
        """è·¨äº‘æ›´æ–°æœåŠ¡"""
        print(f"è·¨äº‘æ›´æ–°æœåŠ¡ (æ¨¡å¼: {service_pattern})")
        
        update_results = {}
        updated_count = 0
        
        for service_id, service_info in self.deployed_services.items():
            if service_pattern in service_info.get('service_name', ''):
                try:
                    provider = CloudProvider(service_info['provider'])
                    service_type = ServiceType(service_info['service_type'])
                    service = self.providers[provider][service_type]
                    
                    if service:
                        success = await service.update(service_id, new_config)
                        
                        if success:
                            update_results[service_id] = {'status': 'updated', 'provider': service_info['provider']}
                            updated_count += 1
                            print(f"âœ“ æ›´æ–°æˆåŠŸ: {service_info['provider']} - {service_info.get('service_name')}")
                        else:
                            update_results[service_id] = {'status': 'failed', 'provider': service_info['provider']}
                            print(f"âœ— æ›´æ–°å¤±è´¥: {service_info['provider']} - {service_info.get('service_name')}")
                            
                except Exception as e:
                    update_results[service_id] = {'error': str(e), 'provider': service_info['provider']}
                    print(f"âœ— æ›´æ–°å¼‚å¸¸: {service_info['provider']} - {e}")
        
        return {
            'total_updated': updated_count,
            'update_results': update_results
        }
    
    async def delete_service_from_all_clouds(self, service_pattern: str) -> Dict[str, Any]:
        """ä»æ‰€æœ‰äº‘åˆ é™¤æœåŠ¡"""
        print(f"ä»æ‰€æœ‰äº‘åˆ é™¤æœåŠ¡ (æ¨¡å¼: {service_pattern})")
        
        delete_results = {}
        deleted_count = 0
        
        for service_id, service_info in self.deployed_services.items():
            if service_pattern in service_info.get('service_name', ''):
                try:
                    provider = CloudProvider(service_info['provider'])
                    service_type = ServiceType(service_info['service_type'])
                    service = self.providers[provider][service_type]
                    
                    if service:
                        success = await service.delete(service_id)
                        
                        if success:
                            delete_results[service_id] = {'status': 'deleted', 'provider': service_info['provider']}
                            deleted_count += 1
                            print(f"âœ“ åˆ é™¤æˆåŠŸ: {service_info['provider']} - {service_info.get('service_name')}")
                        else:
                            delete_results[service_id] = {'status': 'failed', 'provider': service_info['provider']}
                            print(f"âœ— åˆ é™¤å¤±è´¥: {service_info['provider']} - {service_info.get('service_name')}")
                            
                except Exception as e:
                    delete_results[service_id] = {'error': str(e), 'provider': service_info['provider']}
                    print(f"âœ— åˆ é™¤å¼‚å¸¸: {service_info['provider']} - {e}")
        
        # æ¸…ç†å·²åˆ é™¤çš„æœåŠ¡è®°å½•
        for service_id in delete_results.keys():
            if delete_results[service_id].get('status') == 'deleted':
                del self.deployed_services[service_id]
        
        return {
            'total_deleted': deleted_count,
            'delete_results': delete_results
        }
    
    def get_deployment_summary(self) -> Dict[str, Any]:
        """è·å–éƒ¨ç½²æ‘˜è¦"""
        provider_counts = {}
        service_type_counts = {}
        
        for service_info in self.deployed_services.values():
            provider = service_info['provider']
            service_type = service_info['service_type']
            
            provider_counts[provider] = provider_counts.get(provider, 0) + 1
            service_type_counts[service_type] = service_type_counts.get(service_type, 0) + 1
        
        return {
            'total_services': len(self.deployed_services),
            'by_provider': provider_counts,
            'by_service_type': service_type_counts,
            'active_services': len(self.deployed_services)
        }

# ä½¿ç”¨ç¤ºä¾‹
async def demonstrate_multi_cloud_deployment():
    """æ¼”ç¤ºå¤šäº‘éƒ¨ç½²ç­–ç•¥"""
    
    # åˆ›å»ºå¤šäº‘ç®¡ç†å™¨
    manager = MultiCloudManager()
    
    print("=== å¤šäº‘éƒ¨ç½²ç­–ç•¥æ¼”ç¤º ===")
    
    # é…ç½®å¾®æœåŠ¡
    microservice_config = {
        'name': 'user-service',
        'service_type': ServiceType.FUNCTION.value,
        'providers': [CloudProvider.AWS.value, CloudProvider.AZURE.value, CloudProvider.GCP.value],
        'deployment_strategy': 'all',
        'runtime': 'python3.9',
        'handler': 'index.handler',
        'memory': '512MB',
        'timeout': '30s'
    }
    
    # æ‰§è¡Œå¤šäº‘éƒ¨ç½²
    deployment_result = await manager.deploy_multi_cloud_service(microservice_config)
    print(f"\néƒ¨ç½²ç»“æœ:")
    print(f"  æœåŠ¡åç§°: {deployment_result['service_name']}")
    print(f"  æ€»å®ä¾‹æ•°: {deployment_result['total_instances']}")
    print(f"  æˆåŠŸéƒ¨ç½²: {deployment_result['successful_deployments']}")
    
    # å¥åº·æ£€æŸ¥
    print(f"\næ‰§è¡Œå¥åº·æ£€æŸ¥:")
    health_status = await manager.health_check_all_services()
    for service_id, status in health_status.items():
        if 'error' not in status:
            print(f"  {service_id}: {status.get('status', 'Unknown')}")
        else:
            print(f"  {service_id}: Error - {status['error']}")
    
    # æ›´æ–°æœåŠ¡
    print(f"\næ›´æ–°æœåŠ¡:")
    update_config = {'memory': '1024MB', 'timeout': '60s'}
    update_result = await manager.update_service_across_clouds('user-service', update_config)
    print(f"  æ›´æ–°æˆåŠŸ: {update_result['total_updated']} ä¸ªæœåŠ¡")
    
    # æ˜¾ç¤ºéƒ¨ç½²æ‘˜è¦
    print(f"\néƒ¨ç½²æ‘˜è¦:")
    summary = manager.get_deployment_summary()
    for key, value in summary.items():
        print(f"  {key}: {value}")
    
    # æ¸…ç†éƒ¨ç½²
    print(f"\næ¸…ç†éƒ¨ç½²:")
    delete_result = await manager.delete_service_from_all_clouds('user-service')
    print(f"  åˆ é™¤æˆåŠŸ: {delete_result['total_deleted']} ä¸ªæœåŠ¡")

# æˆæœ¬ä¼˜åŒ–ç­–ç•¥
class CostOptimizer:
    def __init__(self, multi_cloud_manager: MultiCloudManager):
        self.manager = multi_cloud_manager
        self.cost_thresholds = {
            'daily_cost_limit': 100.0,  # æ¯æ—¥æˆæœ¬é™åˆ¶
            'function_execution_limit': 1000000,  # å‡½æ•°æ‰§è¡Œæ¬¡æ•°é™åˆ¶
            'storage_limit_gb': 100  # å­˜å‚¨é™åˆ¶
        }
        self.cost_tracking = {}
    
    async def analyze_cost_efficiency(self) -> Dict[str, Any]:
        """åˆ†ææˆæœ¬æ•ˆç‡"""
        print("åˆ†æå¤šäº‘éƒ¨ç½²æˆæœ¬æ•ˆç‡...")
        
        # æ¨¡æ‹Ÿæˆæœ¬åˆ†æ
        provider_costs = {
            'aws': {'daily_cost': 25.50, 'performance_score': 8.5, 'reliability_score': 9.0},
            'azure': {'daily_cost': 22.30, 'performance_score': 8.0, 'reliability_score': 8.8},
            'gcp': {'daily_cost': 28.75, 'performance_score': 8.8, 'reliability_score': 8.5}
        }
        
        # è®¡ç®—æˆæœ¬æ•ˆç›Šæ¯”
        cost_efficiency = {}
        for provider, metrics in provider_costs.items():
            efficiency = (metrics['performance_score'] + metrics['reliability_score']) / (metrics['daily_cost'] / 10)
            cost_efficiency[provider] = {
                'daily_cost': metrics['daily_cost'],
                'cost_efficiency_ratio': efficiency,
                'recommendation': 'recommended' if efficiency > 1.5 else 'consider_optimization'
            }
        
        total_daily_cost = sum(m['daily_cost'] for m in provider_costs.values())
        
        return {
            'total_daily_cost': total_daily_cost,
            'cost_efficiency_by_provider': cost_efficiency,
            'cost_optimization_suggestions': self._generate_cost_suggestions(provider_costs)
        }
    
    def _generate_cost_suggestions(self, provider_costs: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæˆæœ¬ä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        # æ‰¾åˆ°æœ€ä½æˆæœ¬çš„æä¾›å•†
        cheapest_provider = min(provider_costs.items(), key=lambda x: x[1]['daily_cost'])
        suggestions.append(f"è€ƒè™‘å°†æ›´å¤šè´Ÿè½½è¿ç§»åˆ° {cheapest_provider[0]} (æœ€ä½æˆæœ¬: ${cheapest_provider[1]['daily_cost']:.2f}/å¤©)")
        
        # æˆæœ¬é˜ˆå€¼æ£€æŸ¥
        total_cost = sum(m['daily_cost'] for m in provider_costs.values())
        if total_cost > self.cost_thresholds['daily_cost_limit']:
            suggestions.append(f"å½“å‰æˆæœ¬ ${total_cost:.2f}/å¤© è¶…è¿‡é™åˆ¶ ${self.cost_thresholds['daily_cost_limit']}/å¤©ï¼Œå»ºè®®ä¼˜åŒ–")
        
        # æ€§èƒ½ä¸æˆæœ¬æƒè¡¡
        for provider, metrics in provider_costs.items():
            if metrics['daily_cost'] > 25 and metrics['performance_score'] < 8.5:
                suggestions.append(f"{provider} æˆæœ¬è¾ƒé«˜ä½†æ€§èƒ½ä¸€èˆ¬ï¼Œè€ƒè™‘ä¼˜åŒ–æˆ–è¿ç§»")
        
        return suggestions
    
    async def optimize_costs(self, optimization_strategy: str = 'balanced') -> Dict[str, Any]:
        """æ‰§è¡Œæˆæœ¬ä¼˜åŒ–"""
        print(f"æ‰§è¡Œæˆæœ¬ä¼˜åŒ–ç­–ç•¥: {optimization_strategy}")
        
        optimization_results = {
            'strategy': optimization_strategy,
            'actions_taken': [],
            'estimated_savings': 0.0,
            'performance_impact': 'minimal'
        }
        
        if optimization_strategy == 'cost_minimization':
            # æˆæœ¬æœ€å°åŒ–ï¼šè¿ç§»åˆ°æœ€ä¾¿å®œçš„æä¾›å•†
            optimization_results['actions_taken'].extend([
                'è¿ç§»éå…³é”®å·¥ä½œè´Ÿè½½åˆ°ä½æˆæœ¬åŒºåŸŸ',
                'è°ƒæ•´å‡½æ•°å†…å­˜é…ç½®ä»¥å‡å°‘è´¹ç”¨',
                'å®æ–½æ›´æ¿€è¿›çš„å‡½æ•°è¶…æ—¶è®¾ç½®'
            ])
            optimization_results['estimated_savings'] = 15.0  # å‡è®¾èŠ‚çœ15å…ƒ/å¤©
            optimization_results['performance_impact'] = 'moderate'
            
        elif optimization_strategy == 'performance_optimization':
            # æ€§èƒ½ä¼˜åŒ–ï¼šç¡®ä¿æœ€ä½³æ€§èƒ½ï¼Œæˆæœ¬æ¬¡è¦
            optimization_results['actions_taken'].extend([
                'å‡çº§é«˜æ€§èƒ½å®ä¾‹è§„æ ¼',
                'å®æ–½å¤šåŒºåŸŸçƒ­å¤‡ä»½',
                'å¢åŠ ç›‘æ§å’Œå‘Šè­¦èµ„æº'
            ])
            optimization_results['estimated_savings'] = -5.0  # å¢åŠ 5å…ƒ/å¤©æˆæœ¬
            optimization_results['performance_impact'] = 'significant_improvement'
            
        elif optimization_strategy == 'balanced':
            # å¹³è¡¡ç­–ç•¥ï¼šåœ¨æ€§èƒ½å’Œæˆæœ¬é—´å¹³è¡¡
            optimization_results['actions_taken'].extend([
                'æ ¹æ®è®¿é—®æ¨¡å¼è°ƒæ•´å‡½æ•°é…ç½®',
                'å®æ–½æ™ºèƒ½è´Ÿè½½å‡è¡¡',
                'ä¼˜åŒ–æ•°æ®å­˜å‚¨ç­–ç•¥'
            ])
            optimization_results['estimated_savings'] = 8.0  # èŠ‚çœ8å…ƒ/å¤©
            optimization_results['performance_impact'] = 'minimal'
        
        print(f"ä¼˜åŒ–å®Œæˆï¼Œé¢„è®¡èŠ‚çœ: ${optimization_results['estimated_savings']:.2f}/å¤©")
        return optimization_results

# ä½¿ç”¨ç¤ºä¾‹
async def demonstrate_cost_optimization():
    """æ¼”ç¤ºæˆæœ¬ä¼˜åŒ–"""
    
    # å‡è®¾å·²ç»æœ‰éƒ¨ç½²çš„å¤šäº‘æœåŠ¡
    manager = MultiCloudManager()
    optimizer = CostOptimizer(manager)
    
    print("=== æˆæœ¬ä¼˜åŒ–æ¼”ç¤º ===")
    
    # åˆ†ææˆæœ¬æ•ˆç‡
    cost_analysis = await optimizer.analyze_cost_efficiency()
    print(f"\næˆæœ¬åˆ†æç»“æœ:")
    print(f"  æ€»æ—¥æˆæœ¬: ${cost_analysis['total_daily_cost']:.2f}")
    
    print(f"\nå„æä¾›å•†æˆæœ¬æ•ˆç‡:")
    for provider, metrics in cost_analysis['cost_efficiency_by_provider'].items():
        print(f"  {provider}:")
        print(f"    æˆæœ¬: ${metrics['daily_cost']:.2f}")
        print(f"    æ•ˆç‡æ¯”: {metrics['cost_efficiency_ratio']:.2f}")
        print(f"    å»ºè®®: {metrics['recommendation']}")
    
    print(f"\nä¼˜åŒ–å»ºè®®:")
    for suggestion in cost_analysis['cost_optimization_suggestions']:
        print(f"  - {suggestion}")
    
    # æ‰§è¡Œä¼˜åŒ–
    print(f"\næ‰§è¡Œå¹³è¡¡ä¼˜åŒ–ç­–ç•¥:")
    optimization_result = await optimizer.optimize_costs('balanced')
    print(f"  ç­–ç•¥: {optimization_result['strategy']}")
    print(f"  é¢„è®¡èŠ‚çœ: ${optimization_result['estimated_savings']:.2f}/å¤©")
    print(f"  æ€§èƒ½å½±å“: {optimization_result['performance_impact']}")
    
    for action in optimization_result['actions_taken']:
        print(f"  âœ“ {action}")

if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    asyncio.run(demonstrate_advanced_event_driven_architecture())
    print("\n" + "="*80 + "\n")
    
    asyncio.run(demonstrate_advanced_workflow_engine())
    print("\n" + "="*80 + "\n")
    
    asyncio.run(demonstrate_multi_cloud_deployment())
    print("\n" + "="*80 + "\n")
    
    asyncio.run(demonstrate_cost_optimization())
```

## æ€»ç»“

é€šè¿‡è¿™äº›æ— æœåŠ¡å™¨æ¶æ„çš„è¿›é˜¶å®è·µï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªä¼ä¸šçº§çš„æ— æœåŠ¡å™¨åº”ç”¨å¹³å°ï¼Œå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒèƒ½åŠ›ï¼š

### 1. é«˜çº§äº‹ä»¶é©±åŠ¨æ¶æ„

- **äº‹ä»¶æº¯æº**ï¼šå®Œæ•´çš„äº‹ä»¶å†å²è®°å½•å’Œé‡æ”¾èƒ½åŠ›
- **äº‹ä»¶ç¼–æ’**ï¼šå¤æ‚ä¸šåŠ¡æµç¨‹çš„è‡ªåŠ¨åŒ–ç¼–æ’
- **äº‹ä»¶æµå¤„ç†**ï¼šå®æ—¶æµæ•°æ®çš„èšåˆå’Œåˆ†æ
- **äº‹ä»¶æ€»çº¿**ï¼šé«˜åº¦è§£è€¦çš„äº‹ä»¶åˆ†å‘æœºåˆ¶

### 2. é«˜çº§å·¥ä½œæµå¼•æ“

- **å¯è§†åŒ–å·¥ä½œæµ**ï¼šå¤æ‚ä¸šåŠ¡é€»è¾‘çš„å¯è§†åŒ–è¡¨è¾¾
- **å¤šç§æ­¥éª¤ç±»å‹**ï¼šä»»åŠ¡ã€æ¡ä»¶ã€å¹¶è¡Œã€å¾ªç¯ã€äººå·¥ä»»åŠ¡ç­‰
- **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œé‡è¯•æœºåˆ¶
- **å·¥ä½œæµæ¨¡æ¿**ï¼šå¯å¤ç”¨çš„å·¥ä½œæµè®¾è®¡æ¨¡å¼

### 3. å¤šäº‘éƒ¨ç½²ç­–ç•¥

- **äº‘æœåŠ¡æŠ½è±¡**ï¼šç»Ÿä¸€çš„äº‘æœåŠ¡æ¥å£å±‚
- **å¤šç§éƒ¨ç½²æ¨¡å¼**ï¼šå…¨é‡éƒ¨ç½²ã€ä¸»å¤‡éƒ¨ç½²ã€è´Ÿè½½å‡è¡¡éƒ¨ç½²
- **è·¨äº‘ç®¡ç†**ï¼šç»Ÿä¸€çš„éƒ¨ç½²ã€æ›´æ–°ã€ç›‘æ§ã€æ¸…ç†
- **æˆæœ¬ä¼˜åŒ–**ï¼šæ™ºèƒ½çš„æˆæœ¬åˆ†æå’Œä¼˜åŒ–å»ºè®®

### 4. ç”Ÿäº§çº§ç‰¹æ€§

- **é«˜å¯ç”¨æ€§**ï¼šå¤šäº‘å†—ä½™å’Œæ•…éšœè½¬ç§»
- **æ€§èƒ½ä¼˜åŒ–**ï¼šæ™ºèƒ½çš„èµ„æºé…ç½®å’Œæˆæœ¬æ§åˆ¶
- **å®‰å…¨è€ƒè™‘**ï¼šè·¨äº‘å®‰å…¨ç­–ç•¥å’Œåˆè§„æ€§
- **ç›‘æ§å‘Šè­¦**ï¼šå…¨æ ˆçš„ç›‘æ§å’Œæ™ºèƒ½å‘Šè­¦

### 5. å·¥ç¨‹å®è·µ

- **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒæ°´å¹³å’Œå‚ç›´æ‰©å±•çš„æ¶æ„
- **å¯ç»´æŠ¤æ€§**ï¼šæ¸…æ™°çš„ä»£ç ç»“æ„å’Œæ¥å£è®¾è®¡
- **å¯è§‚æµ‹æ€§**ï¼šå®Œæ•´çš„æ—¥å¿—ã€ç›‘æ§å’Œè¿½è¸ª
- **å¯æµ‹è¯•æ€§**ï¼šå®Œå–„çš„æµ‹è¯•ç­–ç•¥å’Œå·¥å…·

è¿™äº›å®è·µä¸ä»…æŒæ¡äº†æ— æœåŠ¡å™¨æ¶æ„çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œæ›´é‡è¦çš„æ˜¯å»ºç«‹äº†ä¼ä¸šçº§åº”ç”¨çš„ç³»ç»Ÿæ€§æ€ç»´ï¼Œä»æŠ€æœ¯é€‰å‹åˆ°æ¶æ„è®¾è®¡ï¼Œä»å¼€å‘éƒ¨ç½²åˆ°è¿ç»´ç›‘æ§ï¼Œå½¢æˆäº†ä¸€ä¸ªå®Œæ•´çš„æŠ€æœ¯ä½“ç³»ã€‚é€šè¿‡è¿™äº›æ¨¡å¼ï¼Œå¯ä»¥æ„å»ºå‡ºé«˜å¯ç”¨ã€é«˜æ€§èƒ½ã€é«˜æ€§ä»·æ¯”çš„æ— æœåŠ¡å™¨åº”ç”¨ç³»ç»Ÿã€‚