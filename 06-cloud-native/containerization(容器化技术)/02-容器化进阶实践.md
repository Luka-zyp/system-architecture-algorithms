# 容器化进阶实践

## 多阶段构建优化

### 生产环境镜像构建

```dockerfile
# 多阶段构建示例
# 构建阶段
FROM node:18-alpine AS builder

WORKDIR /app

# 复制依赖文件
COPY package*.json ./
RUN npm ci --only=production && npm cache clean --force

# 复制源代码并构建
COPY . .
RUN npm run build

# 运行阶段 - 仅包含运行时依赖
FROM node:18-alpine AS production

# 创建非root用户
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001

WORKDIR /app

# 从构建阶段复制生产文件
COPY --from=builder --chown=nextjs:nodejs /app/dist ./dist
COPY --from=builder --chown=nextjs:nodejs /app/node_modules ./node_modules
COPY --from=builder --chown=nextjs:nodejs /app/package.json ./package.json

# 设置健康检查
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

USER nextjs

EXPOSE 3000

CMD ["node", "dist/index.js"]
```

### Java应用多阶段构建

```dockerfile
# Java应用构建
FROM maven:3.8-openjdk-11-slim AS build

WORKDIR /app

# 复制Maven配置文件
COPY pom.xml .
RUN mvn dependency:go-offline -B

# 复制源代码并构建
COPY src ./src
RUN mvn clean package -DskipTests

# 运行时镜像
FROM openjdk:11-jre-slim

# 安装必要工具
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 创建应用用户
RUN groupadd -r app && useradd -r -g app app

WORKDIR /app

# 从构建阶段复制JAR文件
COPY --from=build /app/target/*.jar app.jar

# 设置权限
RUN chown -R app:app /app
USER app

# 健康检查
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
  CMD curl -f http://localhost:8080/actuator/health || exit 1

EXPOSE 8080

ENTRYPOINT ["java", "-jar", "/app/app.jar"]
```

## 容器镜像优化

### 镜像大小优化

```dockerfile
# 使用Alpine Linux
FROM alpine:3.16

# 合并RUN命令减少层数
RUN apk add --no-cache \
    curl \
    && rm -rf /var/cache/apk/*

# 清理缓存和临时文件
RUN curl -sSL https://example.com/script.sh | sh && \
    rm -rf /tmp/* /var/tmp/*

# 使用.dockerignore减少构建上下文
# .dockerignore内容：
# node_modules
# .git
# .gitignore
# README.md
# Dockerfile
# .dockerignore
```

### 安全的镜像构建

```dockerfile
# 安全基础镜像
FROM python:3.9-slim

# 创建非root用户
RUN groupadd -r appuser && useradd -r -g appuser appuser

# 设置工作目录
WORKDIR /app

# 复制依赖文件
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制应用代码
COPY . .

# 更改文件所有权
RUN chown -R appuser:appuser /app

# 切换到非root用户
USER appuser

# 只暴露必要端口
EXPOSE 8000

# 不使用root权限运行
CMD ["python", "app.py"]
```

## 容器编排配置

### Docker Compose高级配置

```yaml
# docker-compose.yml
version: '3.8'

services:
  web:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgres://user:pass@db:5432/myapp
    depends_on:
      - db
      - redis
    networks:
      - app-network
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  db:
    image: postgres:13-alpine
    environment:
      - POSTGRES_DB=myapp
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - app-network
    restart: unless-stopped

  redis:
    image: redis:6-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    networks:
      - app-network
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - web
    networks:
      - app-network
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:

networks:
  app-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

### Kubernetes部署配置

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-app
  namespace: production
  labels:
    app: web-app
    version: v1.0.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: web-app
  template:
    metadata:
      labels:
        app: web-app
        version: v1.0.0
    spec:
      containers:
      - name: web-app
        image: myregistry/web-app:v1.0.0
        ports:
        - containerPort: 3000
          protocol: TCP
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: db-secret
              key: database-url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        volumeMounts:
        - name: logs-volume
          mountPath: /app/logs
      volumes:
      - name: logs-volume
        emptyDir: {}
      securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        fsGroup: 1001
---
apiVersion: v1
kind: Service
metadata:
  name: web-app-service
  namespace: production
spec:
  selector:
    app: web-app
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
  type: ClusterIP
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: web-app-ingress
  namespace: production
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - myapp.example.com
    secretName: web-app-tls
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-app-service
            port:
              number: 80
```

## 容器安全实践

### 安全扫描和合规

```bash
#!/bin/bash
# container-security-scan.sh

# 镜像漏洞扫描
echo "扫描容器镜像漏洞..."
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  aquasec/trivy image myapp:latest

# 检查镜像配置安全
docker run --rm -v $(pwd):/workspace \
  -w /workspace checkov -f Dockerfile

# 镜像内容验证
docker run --rm -v $(pwd):/workspace \
  -w /workspace docker-bench-security
```

### 运行时安全监控

```yaml
# falco配置 - 容器运行时安全
- rule: Unexpected Network Traffic
  desc: 检测异常网络连接
  condition: >
    inbound and not container.image.repository in (nginx, httpd, envoy)
  output: >
    Unexpected inbound network connection 
    (command=%proc.cmdline connection=%fd.name user=%user.name %container.info)
  priority: WARNING

- rule: Privilege Escalation
  desc: 检测权限提升
  condition: >
    spawned_process and 
    (proc.pname in (sudo, su) or proc.name in (sudo, su)) and
    not container.image.repository in (trusted-builder)
  output: >
    Possible privilege escalation detected
    (user=%user.name command=%proc.cmdline parent=%proc.pname %container.info)
  priority: CRITICAL
```

## 容器监控与日志

### Prometheus监控配置

```yaml
# prometheus-config.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "container_rules.yml"

scrape_configs:
  - job_name: 'container-exporter'
    static_configs:
      - targets: ['container-exporter:9100']
    scrape_interval: 10s
    
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']
    scrape_interval: 30s

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093
```

### 日志聚合配置

```yaml
# fluentd配置
<source>
  @type tail
  path /var/log/containers/*.log
  pos_file /var/log/fluentd-containers.log.pos
  tag kubernetes.*
  read_from_head true
  <parse>
    @type json
    time_format %Y-%m-%dT%H:%M:%S.%NZ
  </parse>
</source>

<filter kubernetes.**>
  @type kubernetes_metadata
</filter>

<match kubernetes.**>
  @type elasticsearch
  host elasticsearch.monitoring.svc.cluster.local
  port 9200
  index_name kubernetes
  type_name _doc
</match>
```

### 性能监控脚本

```python
#!/usr/bin/env python3
# container_monitor.py

import docker
import psutil
import time
import json
from datetime import datetime

class ContainerMonitor:
    def __init__(self):
        self.client = docker.from_env()
    
    def get_container_stats(self, container_name):
        """获取容器统计信息"""
        try:
            container = self.client.containers.get(container_name)
            stats = container.stats(stream=False)
            
            # 计算CPU使用率
            cpu_delta = stats['cpu_stats']['cpu_usage']['total_usage'] - \
                       stats['precpu_stats']['cpu_usage']['total_usage']
            system_delta = stats['cpu_stats']['system_cpu_usage'] - \
                          stats['precpu_stats']['system_cpu_usage']
            cpu_usage = (cpu_delta / system_delta) * 100.0
            
            # 内存使用情况
            memory_usage = stats['memory_stats']['usage']
            memory_limit = stats['memory_stats']['limit']
            memory_percent = (memory_usage / memory_limit) * 100.0
            
            # 网络IO
            network_stats = stats['networks']
            network_rx = sum(interface['rx_bytes'] for interface in network_stats.values())
            network_tx = sum(interface['tx_bytes'] for interface in network_stats.values())
            
            # 磁盘IO
            blkio_stats = stats['blkio_stats']
            io_read = sum(entry['value'] for entry in blkio_stats['io_service_bytes_recursive'] 
                         if entry['op'] == 'Read')
            io_write = sum(entry['value'] for entry in blkio_stats['io_service_bytes_recursive'] 
                          if entry['op'] == 'Write')
            
            return {
                'timestamp': datetime.now().isoformat(),
                'container_name': container_name,
                'cpu_percent': round(cpu_usage, 2),
                'memory_usage': memory_usage,
                'memory_limit': memory_limit,
                'memory_percent': round(memory_percent, 2),
                'network_rx': network_rx,
                'network_tx': network_tx,
                'io_read': io_read,
                'io_write': io_write,
                'status': container.status
            }
            
        except Exception as e:
            return {'error': str(e)}
    
    def monitor_all_containers(self):
        """监控所有运行中的容器"""
        containers = self.client.containers.list(filters={"status": "running"})
        results = []
        
        for container in containers:
            stats = self.get_container_stats(container.name)
            if 'error' not in stats:
                results.append(stats)
        
        return results
    
    def generate_report(self):
        """生成监控报告"""
        results = self.monitor_all_containers()
        
        report = {
            'generated_at': datetime.now().isoformat(),
            'total_containers': len(results),
            'containers': results
        }
        
        # 保存到文件
        with open(f'container_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json', 'w') as f:
            json.dump(report, f, indent=2)
        
        return report

if __name__ == "__main__":
    monitor = ContainerMonitor()
    
    while True:
        report = monitor.generate_report()
        print(f"监控报告已生成: {len(report['containers'])} 个容器")
        time.sleep(60)  # 每分钟监控一次
```

## 容器故障处理

### 健康检查脚本

```bash
#!/bin/bash
# health_check.sh

APP_PORT=${APP_PORT:-3000}
MAX_RESPONSE_TIME=${MAX_RESPONSE_TIME:-5}

check_http_health() {
    local url=$1
    local timeout=$2
    
    response=$(curl -s -o /dev/null -w "%{http_code}" \
                 --max-time $timeout \
                 --connect-timeout 5 \
                 "$url")
    
    if [ "$response" = "200" ] || [ "$response" = "204" ]; then
        return 0
    else
        return 1
    fi
}

check_tcp_health() {
    local host=$1
    local port=$2
    
    if timeout 5 bash -c "cat < /dev/null > /dev/tcp/$host/$port"; then
        return 0
    else
        return 1
    fi
}

check_application_health() {
    local health_check_url="http://localhost:$APP_PORT/health"
    
    if check_http_health $health_check_url 10; then
        echo "Application health check passed"
        exit 0
    else
        echo "Application health check failed"
        exit 1
    fi
}

check_dependency_health() {
    # 检查数据库连接
    if check_tcp_health localhost 5432; then
        echo "Database connection OK"
    else
        echo "Database connection failed"
        exit 1
    fi
    
    # 检查Redis连接
    if check_tcp_health localhost 6379; then
        echo "Redis connection OK"
    else
        echo "Redis connection failed"
        exit 1
    fi
}

# 执行健康检查
case "$1" in
    app)
        check_application_health
        ;;
    deps)
        check_dependency_health
        ;;
    all)
        check_dependency_health
        check_application_health
        ;;
    *)
        echo "Usage: $0 {app|deps|all}"
        exit 1
        ;;
esac
```

### 自动恢复脚本

```bash
#!/bin/bash
# auto_recovery.sh

CONTAINER_NAME=$1
MAX_RESTARTS=${MAX_RESTARTS:-3}
RESTART_WINDOW=${RESTART_WINDOW:-300}  # 5分钟窗口

restart_container() {
    echo "重启容器: $CONTAINER_NAME"
    docker restart $CONTAINER_NAME
    
    # 等待容器启动
    sleep 10
    
    # 检查容器状态
    if docker ps --filter "name=$CONTAINER_NAME" --format "{{.Status}}" | grep -q "Up"; then
        echo "容器重启成功"
        return 0
    else
        echo "容器重启失败"
        return 1
    fi
}

check_container_health() {
    local container=$1
    
    # 获取容器状态
    status=$(docker inspect --format='{{.State.Status}}' "$container")
    
    if [ "$status" != "running" ]; then
        echo "容器状态异常: $status"
        return 1
    fi
    
    # 健康检查
    if ! docker exec "$container" /usr/local/bin/health_check.sh app; then
        echo "容器健康检查失败"
        return 1
    fi
    
    return 0
}

main() {
    local restart_count=0
    local window_start=$(date +%s)
    
    while true; do
        if ! check_container_health "$CONTAINER_NAME"; then
            current_time=$(date +%s)
            
            # 重置窗口计数器
            if [ $((current_time - window_start)) -gt $RESTART_WINDOW ]; then
                restart_count=0
                window_start=$current_time
            fi
            
            if [ $restart_count -lt $MAX_RESTARTS ]; then
                if restart_container; then
                    restart_count=$((restart_count + 1))
                    echo "重启次数: $restart_count/$MAX_RESTARTS"
                else
                    echo "重启失败，停止自动恢复"
                    exit 1
                fi
            else
                echo "达到最大重启次数，停止自动恢复"
                exit 1
            fi
        else
            echo "容器运行正常"
            restart_count=0
            window_start=$(date +%s)
        fi
        
        sleep 30
    done
}

main "$@"
```

## 性能调优

### 资源限制优化

```yaml
# 优化的Kubernetes资源限制
apiVersion: v1
kind: Pod
metadata:
  name: optimized-app
spec:
  containers:
  - name: app
    image: myapp:latest
    resources:
      requests:
        memory: "256Mi"
        cpu: "250m"
      limits:
        memory: "512Mi"
        cpu: "500m"
    env:
    - name: GOMAXPROCS
      valueFrom:
        resourceFieldRef:
          resource: limits.cpu
    - name: GOMEMLIMIT
      valueFrom:
        resourceFieldRef:
          resource: limits.memory
```

### 缓存优化配置

```dockerfile
# 缓存优化镜像
FROM node:18-alpine

# 设置镜像源和缓存目录
ENV NPM_CONFIG_CACHE=/tmp/.npm
ENV npm_config_cache=/tmp/.npm

# 安装依赖到缓存目录
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production --cache /tmp/.npm

# 复制应用代码
COPY . .

# 清理临时文件
RUN rm -rf /tmp/.npm /tmp/*

CMD ["node", "app.js"]
```

## 总结

容器化进阶实践涵盖了从镜像构建、安全配置、编排管理到监控运维的完整生命周期。通过合理的多阶段构建、安全加固、性能调优和故障处理，可以构建出高效、安全、可维护的容器化应用系统。

### 关键要点

1. **镜像优化**：使用多阶段构建，减小镜像体积
2. **安全加固**：非root用户运行，最小权限原则
3. **健康监控**：完善的健康检查和监控体系
4. **自动化运维**：自动故障恢复和性能调优
5. **编排管理**：灵活的容器编排和扩展策略