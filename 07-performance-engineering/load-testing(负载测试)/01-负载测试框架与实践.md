# 负载测试框架与实践

## 1. 负载测试基础概念

### 负载测试类型
```python
from enum import Enum
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from abc import ABC, abstractmethod
import time
import threading
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed
import random

class LoadTestType(Enum):
    LOAD_TEST = "load_test"          # 负载测试
    STRESS_TEST = "stress_test"      # 压力测试
    SPIKE_TEST = "spike_test"        # 峰值测试
    VOLUME_TEST = "volume_test"      # 容量测试
    ENDURANCE_TEST = "endurance_test"  # 耐久性测试

@dataclass
class LoadTestConfig:
    test_type: LoadTestType
    target_rps: int = 100           # 目标QPS
    test_duration: int = 300        # 测试持续时间（秒）
    warmup_duration: int = 30       # 预热时间（秒）
    ramp_up_time: int = 60          # 渐进加载时间（秒）
    concurrent_users: int = 50      # 并发用户数
    max_response_time: float = 2.0  # 最大响应时间（秒）
    error_rate_threshold: float = 0.01  # 错误率阈值
    think_time_min: float = 1.0     # 最小思考时间（秒）
    think_time_max: float = 3.0     # 最大思考时间（秒）

@dataclass
class RequestResult:
    timestamp: float
    response_time: float
    status_code: int
    success: bool
    error_message: Optional[str] = None

@dataclass
class TestMetrics:
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    total_response_time: float = 0.0
    min_response_time: float = float('inf')
    max_response_time: float = 0.0
    p50_response_time: float = 0.0
    p95_response_time: float = 0.0
    p99_response_time: float = 0.0
    rps: float = 0.0
    error_rate: float = 0.0
    start_time: float = 0.0
    end_time: float = 0.0

class LoadTestResult:
    """负载测试结果"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.metrics = TestMetrics()
        self.response_times = []
        self.request_results = []
        self.start_timestamp = 0.0
        self.end_timestamp = 0.0
        self.error_messages = []
    
    def add_request_result(self, result: RequestResult):
        """添加请求结果"""
        self.request_results.append(result)
        
        # 更新基础指标
        self.metrics.total_requests += 1
        self.metrics.total_response_time += result.response_time
        
        if result.success:
            self.metrics.successful_requests += 1
        else:
            self.metrics.failed_requests += 1
            if result.error_message:
                self.error_messages.append(result.error_message)
        
        # 更新响应时间指标
        self.response_times.append(result.response_time)
        self.metrics.min_response_time = min(self.metrics.min_response_time, result.response_time)
        self.metrics.max_response_time = max(self.metrics.max_response_time, result.response_time)
    
    def calculate_percentiles(self):
        """计算百分位数"""
        if not self.response_times:
            return
        
        sorted_times = sorted(self.response_times)
        n = len(sorted_times)
        
        self.metrics.p50_response_time = sorted_times[int(n * 0.5)]
        self.metrics.p95_response_time = sorted_times[int(n * 0.95)]
        self.metrics.p99_response_time = sorted_times[int(n * 0.99)]
    
    def finalize_metrics(self):
        """最终化指标计算"""
        self.calculate_percentiles()
        
        if self.metrics.total_requests > 0:
            self.metrics.rps = self.metrics.total_requests / (self.end_timestamp - self.start_timestamp)
            self.metrics.error_rate = self.metrics.failed_requests / self.metrics.total_requests
    
    def is_passed(self) -> bool:
        """判断测试是否通过"""
        # 检查错误率
        if self.metrics.error_rate > self.config.error_rate_threshold:
            return False
        
        # 检查响应时间
        if self.metrics.p95_response_time > self.config.max_response_time:
            return False
        
        # 检查RPS是否达到目标
        if self.metrics.rps < self.config.target_rps * 0.8:  # 允许20%的偏差
            return False
        
        return True
    
    def generate_report(self) -> Dict:
        """生成测试报告"""
        return {
            'test_config': {
                'test_type': self.config.test_type.value,
                'target_rps': self.config.target_rps,
                'test_duration': self.config.test_duration,
                'concurrent_users': self.config.concurrent_users
            },
            'metrics': {
                'total_requests': self.metrics.total_requests,
                'successful_requests': self.metrics.successful_requests,
                'failed_requests': self.metrics.failed_requests,
                'rps': round(self.metrics.rps, 2),
                'error_rate': round(self.metrics.error_rate, 4),
                'avg_response_time': round(self.metrics.total_response_time / self.metrics.total_requests, 2) if self.metrics.total_requests > 0 else 0,
                'min_response_time': round(self.metrics.min_response_time, 3),
                'max_response_time': round(self.metrics.max_response_time, 3),
                'p50_response_time': round(self.metrics.p50_response_time, 3),
                'p95_response_time': round(self.metrics.p95_response_time, 3),
                'p99_response_time': round(self.metrics.p99_response_time, 3)
            },
            'test_duration': self.end_timestamp - self.start_timestamp,
            'test_passed': self.is_passed()
        }
```

### 负载测试执行引擎
```python
import requests
import aiohttp
from typing import Callable, List
import json

class HttpLoadTester:
    """HTTP负载测试器"""
    
    def __init__(self, base_url: str):
        self.base_url = base_url
        self.session = requests.Session()
        self.headers = {'Content-Type': 'application/json'}
    
    def make_request(self, method: str, endpoint: str, **kwargs) -> RequestResult:
        """发起HTTP请求"""
        url = f"{self.base_url}{endpoint}"
        start_time = time.time()
        
        try:
            response = self.session.request(
                method=method,
                url=url,
                headers=self.headers,
                timeout=30,
                **kwargs
            )
            
            response_time = time.time() - start_time
            
            return RequestResult(
                timestamp=start_time,
                response_time=response_time,
                status_code=response.status_code,
                success=200 <= response.status_code < 300
            )
        
        except Exception as e:
            response_time = time.time() - start_time
            
            return RequestResult(
                timestamp=start_time,
                response_time=response_time,
                status_code=0,
                success=False,
                error_message=str(e)
            )

class AsyncLoadTester:
    """异步HTTP负载测试器"""
    
    def __init__(self, base_url: str, max_connections: int = 100):
        self.base_url = base_url
        self.max_connections = max_connections
        self.connector = aiohttp.TCPConnector(limit=max_connections)
    
    async def make_request(self, method: str, endpoint: str, **kwargs) -> RequestResult:
        """发起异步HTTP请求"""
        url = f"{self.base_url}{endpoint}"
        start_time = time.time()
        
        async with aiohttp.ClientSession(
            connector=self.connector,
            timeout=aiohttp.ClientTimeout(total=30)
        ) as session:
            try:
                async with session.request(
                    method=method,
                    url=url,
                    **kwargs
                ) as response:
                    response_time = time.time() - start_time
                    
                    return RequestResult(
                        timestamp=start_time,
                        response_time=response_time,
                        status_code=response.status,
                        success=200 <= response.status < 300
                    )
            
            except Exception as e:
                response_time = time.time() - start_time
                
                return RequestResult(
                    timestamp=start_time,
                    response_time=response_time,
                    status_code=0,
                    success=False,
                    error_message=str(e)
                )

class LoadTestScenario:
    """负载测试场景"""
    
    def __init__(self, name: str):
        self.name = name
        self.steps = []
    
    def add_step(self, method: str, endpoint: str, weight: int = 1, 
                 request_builder: Callable[[], Dict] = None):
        """添加测试步骤"""
        self.steps.append({
            'method': method,
            'endpoint': endpoint,
            'weight': weight,
            'request_builder': request_builder or (lambda: {})
        })
    
    def get_weighted_step(self):
        """获取加权随机步骤"""
        total_weight = sum(step['weight'] for step in self.steps)
        random_weight = random.randint(1, total_weight)
        
        current_weight = 0
        for step in self.steps:
            current_weight += step['weight']
            if random_weight <= current_weight:
                return step
        
        return self.steps[-1]  # 默认返回最后一个

class LoadTestEngine:
    """负载测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.tester = None
        self.scenarios = []
        self.result = LoadTestResult(config)
        self.is_running = False
        self.active_users = 0
        self.lock = threading.Lock()
    
    def add_scenario(self, scenario: LoadTestScenario):
        """添加测试场景"""
        self.scenarios.append(scenario)
    
    def _create_user_session(self) -> Callable[[], None]:
        """创建用户会话"""
        def user_session():
            session_start = time.time()
            
            while self.is_running and (time.time() - session_start) < self.config.test_duration:
                try:
                    # 选择测试场景
                    if self.scenarios:
                        step = random.choice(self.scenarios).get_weighted_step()
                    else:
                        step = {'method': 'GET', 'endpoint': '/health', 'request_builder': lambda: {}}
                    
                    # 构建请求
                    request_data = step['request_builder']()
                    
                    # 执行请求
                    if self.tester:
                        result = self.tester.make_request(step['method'], step['endpoint'], **request_data)
                        self.result.add_request_result(result)
                    
                    # 思考时间
                    think_time = random.uniform(self.config.think_time_min, self.config.think_time_max)
                    time.sleep(think_time)
                    
                except Exception as e:
                    error_result = RequestResult(
                        timestamp=time.time(),
                        response_time=0,
                        status_code=0,
                        success=False,
                        error_message=str(e)
                    )
                    self.result.add_request_result(error_result)
        
        return user_session
    
    def run_sync_test(self) -> LoadTestResult:
        """运行同步负载测试"""
        self.result.start_timestamp = time.time()
        self.is_running = True
        
        # 预热阶段
        print("Starting warmup phase...")
        self._run_warmup()
        
        # 渐进加载阶段
        print("Starting ramp-up phase...")
        self._run_ramp_up()
        
        # 稳定负载阶段
        print("Starting steady load phase...")
        self._run_steady_load()
        
        self.result.end_timestamp = time.time()
        self.result.finalize_metrics()
        self.is_running = False
        
        return self.result
    
    def _run_warmup(self):
        """运行预热阶段"""
        warmup_end_time = time.time() + self.config.warmup_duration
        warmup_tester = HttpLoadTester(self.tester.base_url if self.tester else "http://localhost:8080")
        
        with ThreadPoolExecutor(max_workers=min(10, self.config.concurrent_users)) as executor:
            futures = []
            
            while time.time() < warmup_end_time and self.is_running:
                if len(futures) < self.config.concurrent_users:
                    future = executor.submit(warmup_tester.make_request, 'GET', '/health')
                    futures.append(future)
                
                # 检查完成的任务
                completed = [f for f in futures if f.done()]
                for future in completed:
                    try:
                        result = future.result()
                        # 预热阶段的结果不计入正式测试
                    except Exception:
                        pass
                    futures.remove(future)
                
                time.sleep(0.1)
    
    def _run_ramp_up(self):
        """运行渐进加载阶段"""
        ramp_up_end_time = time.time() + self.config.ramp_up_time
        target_users = self.config.concurrent_users
        
        with ThreadPoolExecutor(max_workers=target_users) as executor:
            user_sessions = []
            
            # 逐步增加用户数
            while time.time() < ramp_up_end_time and self.is_running:
                progress = (time.time() - (ramp_up_end_time - self.config.ramp_up_time)) / self.config.ramp_up_time
                current_users = int(target_users * progress)
                
                # 启动新用户
                while len(user_sessions) < current_users and len(user_sessions) < target_users:
                    future = executor.submit(self._create_user_session())
                    user_sessions.append(future)
                    with self.lock:
                        self.active_users += 1
                
                time.sleep(1)
    
    def _run_steady_load(self):
        """运行稳定负载阶段"""
        steady_end_time = time.time() + (self.config.test_duration - self.config.warmup_duration - self.config.ramp_up_time)
        
        with ThreadPoolExecutor(max_workers=self.config.concurrent_users) as executor:
            futures = []
            
            # 启动所有用户
            for _ in range(self.config.concurrent_users):
                future = executor.submit(self._create_user_session())
                futures.append(future)
            
            # 监控执行情况
            while time.time() < steady_end_time and self.is_running:
                completed_futures = [f for f in futures if f.done()]
                
                for future in completed_futures:
                    try:
                        future.result()  # 等待用户会话完成
                    except Exception as e:
                        print(f"User session error: {e}")
                
                futures = [f for f in futures if not f.done()]
                
                # 如果所有用户会话都完成了，重新启动
                if not futures:
                    for _ in range(self.config.concurrent_users):
                        future = executor.submit(self._create_user_session())
                        futures.append(future)
                
                time.sleep(1)

class AsyncLoadTestEngine:
    """异步负载测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.tester = None
        self.scenarios = []
        self.result = LoadTestResult(config)
        self.is_running = False
    
    async def run_async_test(self) -> LoadTestResult:
        """运行异步负载测试"""
        self.result.start_timestamp = time.time()
        self.is_running = True
        
        # 预热阶段
        print("Starting async warmup phase...")
        await self._run_async_warmup()
        
        # 稳定负载阶段
        print("Starting async steady load phase...")
        await self._run_async_steady_load()
        
        self.result.end_timestamp = time.time()
        self.result.finalize_metrics()
        self.is_running = False
        
        return self.result
    
    async def _run_async_warmup(self):
        """异步预热"""
        warmup_end_time = time.time() + self.config.warmup_duration
        
        async with AsyncLoadTester("http://localhost:8080") as tester:
            tasks = []
            
            while time.time() < warmup_end_time and self.is_running:
                if len(tasks) < 50:  # 限制并发预热请求数
                    task = asyncio.create_task(
                        tester.make_request('GET', '/health')
                    )
                    tasks.append(task)
                
                # 检查完成的任务
                done_tasks = [t for t in tasks if t.done()]
                for task in done_tasks:
                    try:
                        await task  # 预热结果不计入正式测试
                    except Exception:
                        pass
                    tasks.remove(task)
                
                await asyncio.sleep(0.1)
    
    async def _run_async_steady_load(self):
        """异步稳定负载"""
        test_end_time = time.time() + (self.config.test_duration - self.config.warmup_duration)
        
        async with AsyncLoadTester("http://localhost:8080") as tester:
            self.tester = tester
            
            # 创建用户任务
            user_tasks = []
            for _ in range(self.config.concurrent_users):
                task = asyncio.create_task(self._run_user_session())
                user_tasks.append(task)
            
            # 等待测试完成
            await asyncio.gather(*user_tasks, return_exceptions=True)
    
    async def _run_user_session(self):
        """运行用户会话"""
        session_start = time.time()
        
        while self.is_running and (time.time() - session_start) < self.config.test_duration:
            try:
                # 选择测试场景
                if self.scenarios:
                    step = random.choice(self.scenarios).get_weighted_step()
                else:
                    step = {'method': 'GET', 'endpoint': '/health', 'request_builder': lambda: {}}
                
                # 构建请求
                request_data = step['request_builder']()
                
                # 执行异步请求
                result = await self.tester.make_request(step['method'], step['endpoint'], **request_data)
                self.result.add_request_result(result)
                
                # 思考时间
                think_time = random.uniform(self.config.think_time_min, self.config.think_time_max)
                await asyncio.sleep(think_time)
                
            except Exception as e:
                error_result = RequestResult(
                    timestamp=time.time(),
                    response_time=0,
                    status_code=0,
                    success=False,
                    error_message=str(e)
                )
                self.result.add_request_result(error_result)
```

## 2. 高级负载测试模式

### 峰值测试
```python
class SpikeTestEngine(LoadTestEngine):
    """峰值测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        super().__init__(config)
        self.spike_patterns = []
    
    def add_spike_pattern(self, duration: int, target_rps: int, pattern_type: str = "linear"):
        """添加峰值模式"""
        self.spike_patterns.append({
            'duration': duration,
            'target_rps': target_rps,
            'pattern_type': pattern_type
        })
    
    def run_spike_test(self) -> LoadTestResult:
        """运行峰值测试"""
        self.result.start_timestamp = time.time()
        self.is_running = True
        
        total_duration = sum(pattern['duration'] for pattern in self.spike_patterns)
        current_time = 0
        
        with ThreadPoolExecutor(max_workers=100) as executor:
            for pattern in self.spike_patterns:
                pattern_end_time = time.time() + pattern['duration']
                
                print(f"Running spike pattern: {pattern['target_rps']} RPS for {pattern['duration']} seconds")
                
                # 根据目标RPS计算需要的线程数
                target_threads = min(pattern['target_rps'], 100)
                
                futures = []
                while time.time() < pattern_end_time and self.is_running:
                    # 维持目标RPS
                    current_rps = self._calculate_current_rps()
                    
                    if current_rps < pattern['target_rps']:
                        # 启动新线程
                        if len(futures) < target_threads:
                            future = executor.submit(self._create_user_session())
                            futures.append(future)
                    
                    # 清理完成的线程
                    completed_futures = [f for f in futures if f.done()]
                    for future in completed_futures:
                        futures.remove(future)
                    
                    time.sleep(0.1)
        
        self.result.end_timestamp = time.time()
        self.result.finalize_metrics()
        self.is_running = False
        
        return self.result
    
    def _calculate_current_rps(self) -> float:
        """计算当前RPS"""
        # 在实际实现中，这里需要从性能计数器中获取当前的RPS
        # 简化实现，返回估算值
        recent_requests = [r for r in self.result.request_results 
                          if time.time() - r.timestamp < 1]
        return len(recent_requests)

class StressTestEngine(LoadTestEngine):
    """压力测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        super().__init__(config)
        self.max_rps = config.target_rps
        self.step_size = max(10, self.max_rps // 10)
        self.stability_threshold = 60  # 稳定阈值（秒）
    
    def run_stress_test(self) -> LoadTestResult:
        """运行压力测试"""
        self.result.start_timestamp = time.time()
        self.is_running = True
        
        current_rps = self.step_size
        stability_start = None
        
        while current_rps <= self.max_rps and self.is_running:
            print(f"Testing at {current_rps} RPS...")
            
            # 在当前RPS下运行测试
            test_result = self._run_stress_step(current_rps, 60)  # 每步测试60秒
            
            # 分析结果
            if test_result.metrics.error_rate > self.config.error_rate_threshold:
                print(f"Breaking at {current_rps} RPS due to high error rate: {test_result.metrics.error_rate}")
                break
            
            if test_result.metrics.p95_response_time > self.config.max_response_time:
                print(f"Breaking at {current_rps} RPS due to high response time: {test_result.metrics.p95_response_time}")
                break
            
            # 检查稳定性
            if test_result.metrics.error_rate < 0.001 and test_result.metrics.p95_response_time < self.config.max_response_time * 0.5:
                if stability_start is None:
                    stability_start = time.time()
                elif time.time() - stability_start > self.stability_threshold:
                    print(f"System stable at {current_rps} RPS")
                    break
            else:
                stability_start = None
            
            current_rps += self.step_size
        
        self.result.end_timestamp = time.time()
        self.result.finalize_metrics()
        self.is_running = False
        
        return self.result
    
    def _run_stress_step(self, target_rps: int, duration: int) -> LoadTestResult:
        """运行压力测试步骤"""
        step_result = LoadTestResult(self.config)
        step_result.start_timestamp = time.time()
        
        with ThreadPoolExecutor(max_workers=min(target_rps, 100)) as executor:
            futures = []
            step_end_time = time.time() + duration
            
            while time.time() < step_end_time and self.is_running:
                # 维持目标RPS
                current_requests_in_second = len([r for r in step_result.request_results 
                                                 if time.time() - r.timestamp < 1])
                
                if current_requests_in_second < target_rps and len(futures) < 100:
                    future = executor.submit(self._create_stress_request())
                    futures.append(future)
                
                # 处理完成的请求
                completed_futures = [f for f in futures if f.done()]
                for future in completed_futures:
                    try:
                        result = future.result()
                        step_result.add_request_result(result)
                    except Exception as e:
                        error_result = RequestResult(
                            timestamp=time.time(),
                            response_time=0,
                            status_code=0,
                            success=False,
                            error_message=str(e)
                        )
                        step_result.add_request_result(error_result)
                    futures.remove(future)
                
                time.sleep(0.01)
        
        step_result.end_timestamp = time.time()
        step_result.finalize_metrics()
        
        # 合并到主结果中
        for result in step_result.request_results:
            self.result.add_request_result(result)
        
        return step_result
    
    def _create_stress_request(self) -> RequestResult:
        """创建压力测试请求"""
        if self.tester:
            return self.tester.make_request('GET', '/health')
        else:
            # 模拟请求
            start_time = time.time()
            time.sleep(random.uniform(0.01, 0.1))  # 模拟处理时间
            response_time = time.time() - start_time
            
            return RequestResult(
                timestamp=start_time,
                response_time=response_time,
                status_code=200,
                success=True
            )
```

### 容量测试
```python
class VolumeTestEngine(LoadTestEngine):
    """容量测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        super().__init__(config)
        self.data_sizes = [1000, 10000, 100000, 1000000]  # 数据量级别
        self.current_data_level = 0
    
    def run_volume_test(self, data_generator: Callable[[int], List[Dict]]) -> Dict:
        """运行容量测试"""
        results = {}
        
        for data_size in self.data_sizes:
            print(f"Testing with {data_size} records...")
            
            # 生成测试数据
            test_data = data_generator(data_size)
            
            # 运行写入测试
            write_result = self._run_write_test(test_data)
            
            # 运行读取测试
            read_result = self._run_read_test(data_size)
            
            results[data_size] = {
                'write_metrics': write_result.generate_report(),
                'read_metrics': read_result.generate_report()
            }
        
        return results
    
    def _run_write_test(self, test_data: List[Dict]) -> LoadTestResult:
        """运行写入测试"""
        write_config = LoadTestConfig(
            test_type=LoadTestType.VOLUME_TEST,
            target_rps=50,  # 写入通常较慢
            test_duration=300,
            concurrent_users=10
        )
        
        engine = LoadTestEngine(write_config)
        
        # 创建写入场景
        write_scenario = LoadTestScenario("write_scenario")
        write_scenario.add_step('POST', '/api/data', request_builder=lambda: {'json': random.choice(test_data)})
        
        engine.add_scenario(write_scenario)
        engine.tester = self.tester
        
        return engine.run_sync_test()
    
    def _run_read_test(self, data_size: int) -> LoadTestResult:
        """运行读取测试"""
        read_config = LoadTestConfig(
            test_type=LoadTestType.VOLUME_TEST,
            target_rps=200,  # 读取通常较快
            test_duration=300,
            concurrent_users=20
        )
        
        engine = LoadTestEngine(read_config)
        
        # 创建读取场景
        read_scenario = LoadTestScenario("read_scenario")
        read_scenario.add_step('GET', f'/api/data/{random.randint(1, data_size)}')
        
        engine.add_scenario(read_scenario)
        engine.tester = self.tester
        
        return engine.run_sync_test()
```

### 耐久性测试
```python
class EnduranceTestEngine:
    """耐久性测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.result = LoadTestResult(config)
        self.is_running = False
        self.performance_samples = []
        self.memory_samples = []
        self.cpu_samples = []
    
    def run_endurance_test(self, duration_hours: int = 24) -> Dict:
        """运行耐久性测试"""
        test_duration_seconds = duration_hours * 3600
        self.result.start_timestamp = time.time()
        self.is_running = True
        
        print(f"Starting endurance test for {duration_hours} hours...")
        
        # 创建负载生成器
        load_generator = LoadTestEngine(self.config)
        
        # 启动监控线程
        monitor_thread = threading.Thread(target=self._monitor_system_resources, daemon=True)
        monitor_thread.start()
        
        try:
            # 运行长时间负载测试
            load_thread = threading.Thread(target=load_generator.run_sync_test, daemon=True)
            load_thread.start()
            
            # 等待测试完成
            load_thread.join(timeout=test_duration_seconds)
            
        except KeyboardInterrupt:
            print("Endurance test interrupted by user")
        
        finally:
            self.is_running = False
            self.result.end_timestamp = time.time()
            self.result.finalize_metrics()
        
        return self._generate_endurance_report()
    
    def _monitor_system_resources(self):
        """监控系统资源"""
        import psutil
        
        while self.is_running:
            try:
                # 收集系统指标
                self.cpu_samples.append({
                    'timestamp': time.time(),
                    'cpu_percent': psutil.cpu_percent(),
                    'memory_percent': psutil.virtual_memory().percent
                })
                
                # 保持样本数量在合理范围
                if len(self.cpu_samples) > 1000:
                    self.cpu_samples = self.cpu_samples[-500:]
                
                time.sleep(10)  # 每10秒采样一次
                
            except Exception as e:
                print(f"Resource monitoring error: {e}")
                break
    
    def _generate_endurance_report(self) -> Dict:
        """生成耐久性测试报告"""
        test_duration = self.result.end_timestamp - self.result.start_timestamp
        hours = test_duration / 3600
        
        # 计算系统资源统计
        if self.cpu_samples:
            cpu_usage = [sample['cpu_percent'] for sample in self.cpu_samples]
            memory_usage = [sample['memory_percent'] for sample in self.cpu_samples]
            
            cpu_stats = {
                'avg_cpu': sum(cpu_usage) / len(cpu_usage),
                'max_cpu': max(cpu_usage),
                'min_cpu': min(cpu_usage)
            }
            
            memory_stats = {
                'avg_memory': sum(memory_usage) / len(memory_usage),
                'max_memory': max(memory_usage),
                'min_memory': min(memory_usage)
            }
        else:
            cpu_stats = memory_stats = {}
        
        return {
            'test_duration_hours': round(hours, 2),
            'performance_metrics': self.result.generate_report(),
            'system_resources': {
                'cpu_stats': cpu_stats,
                'memory_stats': memory_stats
            },
            'test_stability': self._analyze_stability(),
            'recommendations': self._generate_recommendations()
        }
    
    def _analyze_stability(self) -> Dict:
        """分析测试稳定性"""
        if len(self.result.response_times) < 100:
            return {'stability_score': 0, 'analysis': 'Insufficient data'}
        
        # 计算性能漂移
        window_size = 100
        windows = [self.result.response_times[i:i+window_size] 
                  for i in range(0, len(self.result.response_times) - window_size, window_size//2)]
        
        window_avgs = [sum(window)/len(window) for window in windows]
        
        # 计算平均值的变化
        if len(window_avgs) > 1:
            max_variation = max(window_avgs) - min(window_avgs)
            avg_response_time = sum(self.result.response_times) / len(self.result.response_times)
            stability_score = max(0, 100 - (max_variation / avg_response_time) * 100)
        else:
            stability_score = 100
        
        return {
            'stability_score': round(stability_score, 2),
            'performance_drift': round(max_variation, 3) if 'max_variation' in locals() else 0,
            'analysis': 'Stable' if stability_score > 80 else 'Unstable'
        }
    
    def _generate_recommendations(self) -> List[str]:
        """生成优化建议"""
        recommendations = []
        
        # 基于错误率的建议
        if self.result.metrics.error_rate > 0.01:
            recommendations.append("High error rate detected. Check system stability and error handling.")
        
        # 基于响应时间的建议
        if self.result.metrics.p95_response_time > self.config.max_response_time:
            recommendations.append("High P95 response time. Consider performance optimization.")
        
        # 基于系统资源的建议
        if self.cpu_samples:
            avg_cpu = sum(sample['cpu_percent'] for sample in self.cpu_samples) / len(self.cpu_samples)
            avg_memory = sum(sample['memory_percent'] for sample in self.cpu_samples) / len(self.cpu_samples)
            
            if avg_cpu > 80:
                recommendations.append("High CPU usage detected. Consider scaling up or optimizing algorithms.")
            
            if avg_memory > 80:
                recommendations.append("High memory usage detected. Check for memory leaks and optimize data structures.")
        
        return recommendations
```

## 3. 负载测试报告和分析

### 测试结果分析
```python
class LoadTestAnalyzer:
    """负载测试结果分析器"""
    
    def __init__(self):
        self.thresholds = {
            'response_time_p95': 2.0,
            'response_time_p99': 5.0,
            'error_rate': 0.01,
            'availability': 0.999
        }
    
    def analyze_test_results(self, results: List[Dict]) -> Dict:
        """分析多个测试结果"""
        analysis = {
            'summary': self._generate_summary(results),
            'performance_trends': self._analyze_performance_trends(results),
            'bottlenecks': self._identify_bottlenecks(results),
            'recommendations': self._generate_recommendations(results),
            'comparative_analysis': self._comparative_analysis(results)
        }
        
        return analysis
    
    def _generate_summary(self, results: List[Dict]) -> Dict:
        """生成测试摘要"""
        total_tests = len(results)
        passed_tests = sum(1 for result in results if result.get('test_passed', False))
        
        avg_rps = sum(result['metrics']['rps'] for result in results) / total_tests
        avg_error_rate = sum(result['metrics']['error_rate'] for result in results) / total_tests
        avg_p95_response_time = sum(result['metrics']['p95_response_time'] for result in results) / total_tests
        
        return {
            'total_tests': total_tests,
            'passed_tests': passed_tests,
            'failed_tests': total_tests - passed_tests,
            'success_rate': passed_tests / total_tests,
            'average_metrics': {
                'rps': round(avg_rps, 2),
                'error_rate': round(avg_error_rate, 4),
                'p95_response_time': round(avg_p95_response_time, 3)
            }
        }
    
    def _analyze_performance_trends(self, results: List[Dict]) -> Dict:
        """分析性能趋势"""
        if len(results) < 2:
            return {'trend': 'insufficient_data', 'change_percent': 0}
        
        # 按测试时间排序
        sorted_results = sorted(results, key=lambda x: x.get('start_time', 0))
        
        # 计算性能变化
        first_rps = sorted_results[0]['metrics']['rps']
        last_rps = sorted_results[-1]['metrics']['rps']
        
        rps_change = ((last_rps - first_rps) / first_rps) * 100 if first_rps > 0 else 0
        
        first_error_rate = sorted_results[0]['metrics']['error_rate']
        last_error_rate = sorted_results[-1]['metrics']['error_rate']
        
        error_rate_change = ((last_error_rate - first_error_rate) / first_error_rate) * 100 if first_error_rate > 0 else 0
        
        return {
            'rps_trend': 'improving' if rps_change > 5 else 'degrading' if rps_change < -5 else 'stable',
            'rps_change_percent': round(rps_change, 2),
            'error_rate_trend': 'improving' if error_rate_change < -5 else 'degrading' if error_rate_change > 5 else 'stable',
            'error_rate_change_percent': round(error_rate_change, 2)
        }
    
    def _identify_bottlenecks(self, results: List[Dict]) -> List[Dict]:
        """识别性能瓶颈"""
        bottlenecks = []
        
        for i, result in enumerate(results):
            metrics = result['metrics']
            
            # 检查响应时间瓶颈
            if metrics['p95_response_time'] > self.thresholds['response_time_p95']:
                bottlenecks.append({
                    'test_index': i,
                    'type': 'response_time',
                    'severity': 'high' if metrics['p95_response_time'] > self.thresholds['response_time_p99'] else 'medium',
                    'description': f"P95 response time {metrics['p95_response_time']}s exceeds threshold",
                    'value': metrics['p95_response_time'],
                    'threshold': self.thresholds['response_time_p95']
                })
            
            # 检查错误率瓶颈
            if metrics['error_rate'] > self.thresholds['error_rate']:
                bottlenecks.append({
                    'test_index': i,
                    'type': 'error_rate',
                    'severity': 'high' if metrics['error_rate'] > self.thresholds['error_rate'] * 2 else 'medium',
                    'description': f"Error rate {metrics['error_rate']:.4f} exceeds threshold",
                    'value': metrics['error_rate'],
                    'threshold': self.thresholds['error_rate']
                })
            
            # 检查可用性瓶颈
            availability = 1 - metrics['error_rate']
            if availability < self.thresholds['availability']:
                bottlenecks.append({
                    'test_index': i,
                    'type': 'availability',
                    'severity': 'high',
                    'description': f"Availability {availability:.4f} below threshold",
                    'value': availability,
                    'threshold': self.thresholds['availability']
                })
        
        return bottlenecks
    
    def _generate_recommendations(self, results: List[Dict]) -> List[str]:
        """生成优化建议"""
        recommendations = []
        
        # 基于瓶颈分析的建议
        bottlenecks = self._identify_bottlenecks(results)
        
        response_time_bottlenecks = [b for b in bottlenecks if b['type'] == 'response_time']
        if response_time_bottlenecks:
            recommendations.append("Address response time issues by optimizing database queries, implementing caching, or scaling horizontally.")
        
        error_rate_bottlenecks = [b for b in bottlenecks if b['type'] == 'error_rate']
        if error_rate_bottlenecks:
            recommendations.append("Investigate and resolve error sources. Check system logs, improve error handling, and verify external dependencies.")
        
        # 基于性能趋势的建议
        trends = self._analyze_performance_trends(results)
        if trends['rps_trend'] == 'degrading':
            recommendations.append("Performance is degrading over time. Consider investigating memory leaks or resource exhaustion.")
        
        if trends['error_rate_trend'] == 'degrading':
            recommendations.append("Error rate is increasing. System may be approaching its limits or experiencing degradation.")
        
        # 基于整体指标的建议
        avg_metrics = sum(results, key=lambda x: x['metrics'])['average_metrics']
        
        if avg_metrics['error_rate'] > 0.005:
            recommendations.append("Overall error rate is high. Implement circuit breakers, improve resilience patterns, and add monitoring.")
        
        if avg_metrics['p95_response_time'] > 1.0:
            recommendations.append("Response times are elevated. Consider performance profiling, database optimization, and infrastructure scaling.")
        
        return recommendations
    
    def _comparative_analysis(self, results: List[Dict]) -> Dict:
        """比较分析"""
        if len(results) < 2:
            return {'comparison': 'insufficient_data'}
        
        # 找出最佳和最差性能
        best_result = max(results, key=lambda x: x['metrics']['rps'])
        worst_result = min(results, key=lambda x: x['metrics']['rps'])
        
        return {
            'best_performance': {
                'index': results.index(best_result),
                'rps': best_result['metrics']['rps'],
                'error_rate': best_result['metrics']['error_rate']
            },
            'worst_performance': {
                'index': results.index(worst_result),
                'rps': worst_result['metrics']['rps'],
                'error_rate': worst_result['metrics']['error_rate']
            },
            'performance_gap': {
                'rps_gap': best_result['metrics']['rps'] - worst_result['metrics']['rps'],
                'error_rate_gap': worst_result['metrics']['error_rate'] - best_result['metrics']['error_rate']
            }
        }

class LoadTestReporter:
    """负载测试报告生成器"""
    
    def __init__(self, analyzer: LoadTestAnalyzer):
        self.analyzer = analyzer
    
    def generate_html_report(self, results: List[Dict], output_path: str):
        """生成HTML报告"""
        analysis = self.analyzer.analyze_test_results(results)
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Load Test Report</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ background-color: #f0f0f0; padding: 20px; border-radius: 5px; }}
                .metric {{ display: inline-block; margin: 10px; padding: 15px; background-color: #e0e0e0; border-radius: 5px; }}
                .bottleneck {{ color: red; font-weight: bold; }}
                .recommendation {{ background-color: #fffacd; padding: 10px; margin: 5px 0; border-radius: 3px; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>Load Test Report</h1>
                <p>Generated at: {time.strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
            
            <h2>Summary</h2>
            <div class="metric">Total Tests: {analysis['summary']['total_tests']}</div>
            <div class="metric">Success Rate: {analysis['summary']['success_rate']:.2%}</div>
            <div class="metric">Average RPS: {analysis['summary']['average_metrics']['rps']}</div>
            
            <h2>Performance Trends</h2>
            <p>RPS Trend: {analysis['performance_trends']['rps_trend']} ({analysis['performance_trends']['rps_change_percent']:+.2f}%)</p>
            <p>Error Rate Trend: {analysis['performance_trends']['error_rate_trend']}</p>
            
            <h2>Bottlenecks</h2>
            {"".join([f'<div class="bottleneck">{b["description"]}</div>' for b in analysis['bottlenecks']])}
            
            <h2>Recommendations</h2>
            {"".join([f'<div class="recommendation">{rec}</div>' for rec in analysis['recommendations']])}
            
            <h2>Detailed Results</h2>
            <table>
                <tr>
                    <th>Test Index</th>
                    <th>RPS</th>
                    <th>Error Rate</th>
                    <th>P95 Response Time</th>
                    <th>Status</th>
                </tr>
                {self._generate_result_table_rows(results)}
            </table>
        </body>
        </html>
        """
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
    
    def _generate_result_table_rows(self, results: List[Dict]) -> str:
        """生成结果表格行"""
        rows = []
        for i, result in enumerate(results):
            status = "PASS" if result.get('test_passed', False) else "FAIL"
            status_color = "green" if result.get('test_passed', False) else "red"
            
            rows.append(f"""
                <tr>
                    <td>{i}</td>
                    <td>{result['metrics']['rps']}</td>
                    <td>{result['metrics']['error_rate']:.4f}</td>
                    <td>{result['metrics']['p95_response_time']:.3f}s</td>
                    <td style="color: {status_color};">{status}</td>
                </tr>
            """)
        
        return "".join(rows)
```

## 4. 负载测试最佳实践

### 测试准备
1. **环境准备**: 确保测试环境与生产环境相似
2. **数据准备**: 准备真实的测试数据集
3. **监控准备**: 部署性能监控和日志收集
4. **基线建立**: 建立性能基线和阈值标准

### 测试执行
1. **渐进测试**: 从低负载开始，逐步增加负载
2. **多轮测试**: 执行多轮测试以确保结果一致性
3. **长期监控**: 对于耐久性测试，进行长期监控
4. **错误分析**: 详细记录和分析错误信息

### 结果分析
1. **多维度分析**: 从响应时间、吞吐量、错误率等多个维度分析
2. **趋势分析**: 分析性能随时间的变化趋势
3. **瓶颈识别**: 准确识别系统瓶颈点
4. **可重现性**: 确保测试结果可重现

通过以上负载测试框架和实践，可以系统性地评估系统在不同负载条件下的性能表现，为系统优化和扩容决策提供可靠的数据支持。