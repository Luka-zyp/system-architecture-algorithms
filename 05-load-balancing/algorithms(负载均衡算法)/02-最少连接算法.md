# Least Connections 负载均衡算法详解

## 目录
1. [算法概述](#算法概述)
2. [算法原理](#算法原理)
3. [Python实现](#python实现)
4. [Go语言实现](#go语言实现)
5. [算法变种](#算法变种)
6. [性能分析](#性能分析)
7. [适用场景](#适用场景)
8. [故障处理](#故障处理)
9. [监控指标](#监控指标)
10. [实战案例](#实战案例)

## 算法概述

### 什么是Least Connections

Least Connections（最少连接）是一种动态负载均衡算法，通过选择当前连接数最少的服务器来分发请求。该算法考虑了服务器的实时负载状态，能够更智能地处理不同类型的请求和服务器性能差异。

### 核心特性

```python
from typing import List, Dict, Optional, Any, Callable, Tuple
from dataclasses import dataclass, field
from enum import Enum
import time
import threading
import random
import statistics
import json
import logging
import heapq
from collections import defaultdict, deque
from concurrent.futures import ThreadPoolExecutor, as_completed
import copy
from abc import ABC, abstractmethod

@dataclass
class Server:
    """服务器节点"""
    id: str
    hostname: str
    port: int
    weight: float = 1.0
    max_connections: int = 1000
    
    # 连接管理
    active_connections: int = 0
    pending_connections: int = 0
    connection_queue: deque = field(default_factory=deque)
    
    # 性能指标
    avg_response_time: float = 0.0
    response_times: deque = field(default_factory=lambda: deque(maxlen=100))
    cpu_usage: float = 0.0
    memory_usage: float = 0.0
    
    # 健康状态
    is_healthy: bool = True
    last_health_check: float = field(default_factory=time.time)
    failure_count: int = 0
    success_count: int = 0
    
    # 统计信息
    total_requests: int = 0
    total_response_time: float = 0.0
    connection_timestamps: deque = field(default_factory=lambda: deque(maxlen=1000))
    
    def get_current_load(self) -> float:
        """获取当前负载分数"""
        load_factors = [
            self.active_connections / self.max_connections,  # 连接负载
            self.pending_connections / 10,  # 等待队列负载
            self.avg_response_time / 1000.0,  # 响应时间负载
            self.cpu_usage / 100.0,  # CPU负载
            self.memory_usage / 100.0  # 内存负载
        ]
        return sum(load_factors) / len(load_factors)
    
    def get_efficiency_score(self) -> float:
        """获取效率分数"""
        if self.total_requests == 0:
            return 1.0
        
        # 基于响应时间和成功率计算效率
        success_rate = self.success_count / (self.success_count + self.failure_count) if (self.success_count + self.failure_count) > 0 else 0
        response_factor = max(0.1, 1.0 - (self.avg_response_time / 2000.0))  # 响应时间越短越好
        
        return success_rate * response_factor
    
    def get_adjusted_load(self) -> float:
        """获取调整后的负载（考虑效率）"""
        base_load = self.get_current_load()
        efficiency = self.get_efficiency_score()
        return base_load / efficiency if efficiency > 0 else base_load

class LeastConnectionsStrategy(Enum):
    """最少连接策略类型"""
    SIMPLE_LEAST_CONNECTIONS = "simple"
    WEIGHTED_LEAST_CONNECTIONS = "weighted"
    LEAST_LOAD = "least_load"
    ADAPTIVE_LEAST_CONNECTIONS = "adaptive"

@dataclass
class Connection:
    """连接"""
    connection_id: str
    client_id: str
    server_id: str
    start_time: float
    estimated_duration: float = 30.0
    is_active: bool = True
    request_type: str = "normal"  # normal, streaming, file_upload
    
    def get_remaining_time(self) -> float:
        """获取剩余时间"""
        if not self.is_active:
            return 0.0
        
        elapsed = time.time() - self.start_time
        return max(0.0, self.estimated_duration - elapsed)

@dataclass
class LoadBalancingMetrics:
    """负载均衡指标"""
    total_requests: int = 0
    total_connections: int = 0
    average_response_time: float = 0.0
    requests_per_second: float = 0.0
    connection_utilization: float = 0.0
    algorithm_efficiency: float = 0.0
    load_distribution_variance: float = 0.0

class ConnectionTracker:
    """连接跟踪器"""
    
    def __init__(self):
        self.connections: Dict[str, Connection] = {}
        self.server_connections: Dict[str, List[str]] = defaultdict(list)
        self.client_connections: Dict[str, List[str]] = defaultdict(list)
        self.mutex = threading.RLock()
        
    def create_connection(self, connection: Connection):
        """创建连接"""
        with self.mutex:
            self.connections[connection.connection_id] = connection
            self.server_connections[connection.server_id].append(connection.connection_id)
            self.client_connections[connection.client_id].append(connection.connection_id)
    
    def close_connection(self, connection_id: str):
        """关闭连接"""
        with self.mutex:
            if connection_id in self.connections:
                connection = self.connections[connection_id]
                connection.is_active = False
                
                # 从服务器连接列表中移除
                server_connections = self.server_connections[connection.server_id]
                if connection_id in server_connections:
                    server_connections.remove(connection_id)
                
                # 从客户端连接列表中移除
                client_connections = self.client_connections[connection.client_id]
                if connection_id in client_connections:
                    client_connections.remove(connection_id)
                
                # 删除连接记录
                del self.connections[connection_id]
    
    def get_server_connections(self, server_id: str) -> List[Connection]:
        """获取服务器的连接列表"""
        with self.mutex:
            connection_ids = self.server_connections[server_id]
            return [self.connections[conn_id] for conn_id in connection_ids if conn_id in self.connections]
    
    def get_active_connections_count(self, server_id: str) -> int:
        """获取服务器的活跃连接数"""
        return len(self.get_server_connections(server_id))
    
    def get_pending_connections_count(self, server_id: str) -> int:
        """获取服务器的待处理连接数"""
        with self.mutex:
            connections = self.server_connections[server_id]
            pending_count = 0
            for conn_id in connections:
                if conn_id in self.connections:
                    connection = self.connections[conn_id]
                    if connection.is_active and connection.get_remaining_time() > 60:  # 长时间运行的任务
                        pending_count += 1
            return pending_count

class LeastConnectionsLoadBalancer:
    """Least Connections负载均衡器"""
    
    def __init__(self, strategy: LeastConnectionsStrategy = LeastConnectionsStrategy.SIMPLE_LEAST_CONNECTIONS):
        self.strategy = strategy
        self.servers: List[Server] = []
        self.connection_tracker = ConnectionTracker()
        self.metrics = LoadBalancingMetrics()
        self.mutex = threading.RLock()
        self.last_metric_update = time.time()
        
        # 设置日志
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger("LeastConnectionsLB")
    
    def add_server(self, server: Server):
        """添加服务器"""
        with self.mutex:
            self.servers.append(server)
        
        self.logger.info(f"Added server: {server.hostname}:{server.port} (Max connections: {server.max_connections})")
    
    def remove_server(self, server_id: str):
        """移除服务器"""
        with self.mutex:
            # 关闭该服务器的所有连接
            server = self.get_server_by_id(server_id)
            if server:
                connections = self.connection_tracker.get_server_connections(server_id)
                for connection in connections:
                    self.connection_tracker.close_connection(connection.connection_id)
            
            # 移除服务器
            self.servers = [s for s in self.servers if s.id != server_id]
        
        self.logger.info(f"Removed server: {server_id}")
    
    def get_server_by_id(self, server_id: str) -> Optional[Server]:
        """根据ID获取服务器"""
        for server in self.servers:
            if server.id == server_id:
                return server
        return None
    
    def get_next_server(self, request_type: str = "normal", expected_duration: float = 30.0) -> Optional[Server]:
        """获取下一个服务器"""
        with self.mutex:
            healthy_servers = [s for s in self.servers if s.is_healthy]
            
            if not healthy_servers:
                self.logger.warning("No healthy servers available")
                return None
            
            # 应用不同的策略
            if self.strategy == LeastConnectionsStrategy.SIMPLE_LEAST_CONNECTIONS:
                return self._simple_least_connections(healthy_servers, expected_duration)
            elif self.strategy == LeastConnectionsStrategy.WEIGHTED_LEAST_CONNECTIONS:
                return self._weighted_least_connections(healthy_servers, expected_duration)
            elif self.strategy == LeastConnectionsStrategy.LEAST_LOAD:
                return self._least_load(healthy_servers)
            elif self.strategy == LeastConnectionsStrategy.ADAPTIVE_LEAST_CONNECTIONS:
                return self._adaptive_least_connections(healthy_servers, request_type, expected_duration)
            else:
                return self._simple_least_connections(healthy_servers, expected_duration)
    
    def _simple_least_connections(self, healthy_servers: List[Server], expected_duration: float) -> Server:
        """简单最少连接"""
        server_loads = []
        
        for server in healthy_servers:
            active_connections = self.connection_tracker.get_active_connections_count(server.id)
            pending_connections = self.connection_tracker.get_pending_connections_count(server.id)
            
            # 计算预估负载（当前连接 + 新连接的预估影响）
            estimated_load = active_connections + (pending_connections * 0.5)
            
            # 如果新连接是长时间任务，增加权重
            if expected_duration > 60:  # 长时间任务
                estimated_load += 0.3
            
            server_loads.append((estimated_load, server))
        
        # 选择负载最小的服务器
        server_loads.sort(key=lambda x: x[0])
        return server_loads[0][1]
    
    def _weighted_least_connections(self, healthy_servers: List[Server], expected_duration: float) -> Server:
        """加权最少连接"""
        server_scores = []
        
        for server in healthy_servers:
            active_connections = self.connection_tracker.get_active_connections_count(server.id)
            pending_connections = self.connection_tracker.get_pending_connections_count(server.id)
            
            # 基础负载
            base_load = active_connections + (pending_connections * 0.5)
            
            # 根据权重调整
            weight_factor = server.weight if server.weight > 0 else 1.0
            weighted_load = base_load / weight_factor
            
            # 长时间任务权重
            if expected_duration > 60:
                weighted_load += 0.2
            
            # 考虑服务器容量限制
            capacity_utilization = active_connections / server.max_connections
            capacity_penalty = capacity_utilization * 0.3
            
            final_score = weighted_load + capacity_penalty
            server_scores.append((final_score, server))
        
        server_scores.sort(key=lambda x: x[0])
        return server_scores[0][1]
    
    def _least_load(self, healthy_servers: List[Server]) -> Server:
        """最少负载"""
        server_scores = []
        
        for server in healthy_servers:
            load_score = server.get_adjusted_load()
            server_scores.append((load_score, server))
        
        server_scores.sort(key=lambda x: x[0])
        return server_scores[0][1]
    
    def _adaptive_least_connections(self, healthy_servers: List[Server], request_type: str, expected_duration: float) -> Server:
        """自适应最少连接"""
        server_scores = []
        
        for server in healthy_servers:
            # 基础连接数
            active_connections = self.connection_tracker.get_active_connections_count(server.id)
            pending_connections = self.connection_tracker.get_pending_connections_count(server.id)
            
            # 根据请求类型调整权重
            type_multiplier = {
                "streaming": 2.0,  # 流媒体占用更多资源
                "file_upload": 1.5,  # 文件上传中等资源占用
                "normal": 1.0,  # 普通请求
                "api": 0.8  # API请求通常较短
            }.get(request_type, 1.0)
            
            # 计算加权负载
            base_load = (active_connections + pending_connections * 0.3) * type_multiplier
            
            # 服务器效率调整
            efficiency = server.get_efficiency_score()
            efficiency_adjusted_load = base_load / efficiency if efficiency > 0 else base_load
            
            # 长时间任务调整
            if expected_duration > 120:  # 2分钟以上的任务
                efficiency_adjusted_load *= 1.2
            elif expected_duration > 60:  # 1分钟以上的任务
                efficiency_adjusted_load *= 1.1
            
            # 容量限制检查
            if active_connections >= server.max_connections * 0.9:
                efficiency_adjusted_load *= 10  # 大幅降低优先级
            
            server_scores.append((efficiency_adjusted_load, server))
        
        server_scores.sort(key=lambda x: x[0])
        return server_scores[0][1]
    
    def establish_connection(self, client_id: str, server: Server, request_type: str = "normal", 
                           expected_duration: float = 30.0) -> Optional[Connection]:
        """建立连接"""
        if not server or not server.is_healthy:
            return None
        
        # 检查服务器容量
        active_connections = self.connection_tracker.get_active_connections_count(server.id)
        if active_connections >= server.max_connections:
            self.logger.warning(f"Server {server.hostname} at capacity: {active_connections}/{server.max_connections}")
            return None
        
        # 创建连接
        connection_id = f"conn_{int(time.time() * 1000)}_{random.randint(1000, 9999)}"
        connection = Connection(
            connection_id=connection_id,
            client_id=client_id,
            server_id=server.id,
            start_time=time.time(),
            estimated_duration=expected_duration,
            request_type=request_type
        )
        
        # 建立连接
        self.connection_tracker.create_connection(connection)
        
        # 更新服务器统计
        server.active_connections += 1
        server.total_requests += 1
        
        self.logger.info(f"Established connection {connection_id} to {server.hostname}")
        
        return connection
    
    def close_connection(self, connection_id: str):
        """关闭连接"""
        if connection_id in self.connection_tracker.connections:
            connection = self.connection_tracker.connections[connection_id]
            server = self.get_server_by_id(connection.server_id)
            
            if server:
                server.active_connections = max(0, server.active_connections - 1)
            
            self.connection_tracker.close_connection(connection_id)
            self.logger.info(f"Closed connection {connection_id}")
    
    def record_response_time(self, server: Server, response_time: float):
        """记录响应时间"""
        server.response_times.append(response_time)
        server.total_response_time += response_time
        server.avg_response_time = statistics.mean(server.response_times) if server.response_times else 0.0
        
        # 更新效率指标
        if response_time < server.avg_response_time * 1.2:  # 快速响应
            server.success_count += 1
        else:  # 慢响应作为失败处理
            server.failure_count += 1
    
    def health_check(self, server: Server) -> bool:
        """健康检查"""
        try:
            # 模拟健康检查
            time.sleep(0.1)  # 模拟检查时间
            
            # 基于负载和连接数判断健康状态
            load_score = server.get_current_load()
            connection_utilization = server.active_connections / server.max_connections
            
            # 负载过高时标记为不健康
            if load_score > 0.8 or connection_utilization > 0.95:
                server.is_healthy = False
                server.failure_count += 1
                self.logger.warning(f"Server {server.hostname} marked unhealthy due to high load")
                return False
            else:
                server.is_healthy = True
                if server.failure_count > 0:
                    server.failure_count = max(0, server.failure_count - 1)
                return True
                
        except Exception as e:
            self.logger.error(f"Health check failed for {server.hostname}: {str(e)}")
            server.is_healthy = False
            return False
    
    def simulate_request(self, client_id: str, request_type: str = "normal", 
                        expected_duration: float = 30.0) -> Dict[str, Any]:
        """模拟请求处理"""
        start_time = time.time()
        
        # 选择服务器
        server = self.get_next_server(request_type, expected_duration)
        
        if not server:
            return {
                "success": False,
                "error": "No available servers",
                "response_time": 0.0
            }
        
        # 建立连接
        connection = self.establish_connection(client_id, server, request_type, expected_duration)
        
        if not connection:
            return {
                "success": False,
                "error": "Failed to establish connection",
                "server": server.hostname,
                "response_time": time.time() - start_time
            }
        
        try:
            # 模拟请求处理时间
            processing_time = random.uniform(0.1, 2.0) * (expected_duration / 30.0)
            time.sleep(processing_time)
            
            # 模拟成功率（基于服务器效率）
            success_rate = server.get_efficiency_score()
            is_success = random.random() < success_rate
            
            response_time = time.time() - start_time
            
            # 记录响应时间
            self.record_response_time(server, response_time)
            
            return {
                "success": is_success,
                "server": server.hostname,
                "connection_id": connection.connection_id,
                "response_time": response_time,
                "processing_time": processing_time,
                "request_type": request_type
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "server": server.hostname,
                "connection_id": connection.connection_id,
                "response_time": time.time() - start_time
            }
        finally:
            # 关闭连接
            self.close_connection(connection.connection_id)
    
    def get_metrics(self) -> Dict[str, Any]:
        """获取指标"""
        with self.mutex:
            current_time = time.time()
            
            # 计算基本指标
            total_active_connections = sum(
                self.connection_tracker.get_active_connections_count(server.id)
                for server in self.servers
            )
            
            avg_response_time = statistics.mean([s.avg_response_time for s in self.servers if s.avg_response_time > 0]) if self.servers else 0.0
            
            # 计算负载分布方差
            if self.servers:
                connection_counts = [
                    self.connection_tracker.get_active_connections_count(server.id)
                    for server in self.servers
                ]
                avg_connections = statistics.mean(connection_counts)
                load_variance = statistics.variance(connection_counts) if len(connection_counts) > 1 else 0.0
            else:
                load_variance = 0.0
            
            return {
                "algorithm": self.strategy.value,
                "total_servers": len(self.servers),
                "healthy_servers": len([s for s in self.servers if s.is_healthy]),
                "total_active_connections": total_active_connections,
                "average_response_time": avg_response_time,
                "load_distribution_variance": load_variance,
                "servers": [
                    {
                        "id": server.id,
                        "hostname": server.hostname,
                        "active_connections": self.connection_tracker.get_active_connections_count(server.id),
                        "pending_connections": self.connection_tracker.get_pending_connections_count(server.id),
                        "max_connections": server.max_connections,
                        "utilization": server.active_connections / server.max_connections,
                        "avg_response_time": server.avg_response_time,
                        "efficiency_score": server.get_efficiency_score(),
                        "load_score": server.get_adjusted_load(),
                        "is_healthy": server.is_healthy
                    } for server in self.servers
                ]
            }

class GoStyleLeastConnections:
    """Go风格的Least Connections实现"""
    
    def __init__(self, servers: List[Dict[str, Any]]):
        self.servers = []
        for server_data in servers:
            self.servers.append({
                "id": server_data["id"],
                "host": server_data["host"],
                "port": server_data["port"],
                "weight": server_data.get("weight", 1.0),
                "max_connections": server_data.get("max_connections", 1000),
                "active_connections": 0,
                "connections": []  # 模拟连接池
            })
    
    func (lb *GoStyleLeastConnections) SelectServer() *ServerInfo {
        """选择服务器（Go语言风格）"""
        if len(lb.servers) == 0 {
            return nil
        }
        
        var selectedServer *ServerInfo
        minConnections := int(^uint(0) >> 1) // 最大整数
        
        for i := range lb.servers {
            server := &lb.servers[i]
            if server.active_connections < minConnections {
                minConnections = server.active_connections
                selectedServer = server
            }
        }
        
        return selectedServer
    }
    
    def SelectWeightedServer(self):
        """选择加权服务器"""
        if not self.servers:
            return None
        
        # 计算总的权重负载
        total_weighted_load = 0
        server_loads = []
        
        for server in self.servers:
            active_connections = server["active_connections"]
            weight = server["weight"]
            max_connections = server["max_connections"]
            
            # 计算加权负载
            weighted_load = (active_connections / max_connections) * weight
            server_loads.append((weighted_load, server))
            total_weighted_load += weighted_load
        
        # 基于加权负载选择
        target_load = random.uniform(0, total_weighted_load)
        current_load = 0
        
        for weighted_load, server in server_loads:
            current_load += weighted_load
            if current_load >= target_load:
                return server
        
        return server_loads[-1][1]  # 兜底
    
    def ChannelBasedLoadBalancing(self, requests: int):
        """基于通道的负载均衡"""
        # 模拟Go的channel模式
        server_channels = {}
        
        for server in self.servers:
            channel_capacity = min(server["max_connections"] // 10, 100)
            server_channels[server["id"]] = {
                "capacity": channel_capacity,
                "requests": [],
                "server": server
            }
        
        # 模拟将请求发送到通道
        results = []
        for i in range(requests):
            # 选择连接数最少的服务器
            selected_server = self.SelectWeightedServer()
            
            if selected_server:
                results.append({
                    "request_id": i,
                    "server_id": selected_server["id"],
                    "assigned_at": time.time()
                })
                
                # 模拟添加连接
                selected_server["active_connections"] += 1
        
        return results

class LoadBalancingSimulation:
    """负载均衡仿真"""
    
    def __init__(self, load_balancer: LeastConnectionsLoadBalancer):
        self.load_balancer = load_balancer
        self.simulation_results = {}
    
    def simulate_traffic_patterns(self, pattern: str = "uniform", duration: int = 60):
        """仿真不同流量模式"""
        print(f"Simulating {pattern} traffic pattern for {duration} seconds...")
        
        request_types = ["normal", "streaming", "file_upload", "api"]
        pattern_configs = {
            "uniform": {"weight": {t: 1.0 for t in request_types}},
            "burst": {"weight": {"normal": 0.3, "streaming": 0.4, "file_upload": 0.2, "api": 0.1}},
            "heavy_streaming": {"weight": {"normal": 0.2, "streaming": 0.7, "file_upload": 0.05, "api": 0.05}},
            "file_heavy": {"weight": {"normal": 0.3, "streaming": 0.1, "file_upload": 0.6, "api": 0.0}}
        }
        
        config = pattern_configs.get(pattern, pattern_configs["uniform"])
        
        start_time = time.time()
        request_count = 0
        connection_log = []
        
        while time.time() - start_time < duration:
            # 根据模式生成请求
            request_type = random.choices(
                request_types,
                weights=list(config["weight"].values())
            )[0]
            
            # 模拟客户端ID
            client_id = f"client_{random.randint(1, 100)}"
            
            # 设置预期的请求持续时间
            duration_mapping = {
                "normal": random.uniform(10, 60),
                "streaming": random.uniform(120, 600),  # 2-10分钟
                "file_upload": random.uniform(60, 300),  # 1-5分钟
                "api": random.uniform(5, 30)
            }
            expected_duration = duration_mapping.get(request_type, 30.0)
            
            # 执行请求
            result = self.load_balancer.simulate_request(client_id, request_type, expected_duration)
            
            if result["success"]:
                connection_log.append({
                    "request_id": request_count,
                    "server": result["server"],
                    "request_type": request_type,
                    "duration": expected_duration,
                    "timestamp": time.time()
                })
            
            request_count += 1
            
            # 控制请求频率
            time.sleep(0.1)  # 10请求/秒
        
        # 分析结果
        self.analyze_simulation_results(connection_log)
        
        return self.simulation_results
    
    def analyze_simulation_results(self, connection_log: List[Dict]):
        """分析仿真结果"""
        if not connection_log:
            return
        
        # 服务器使用统计
        server_usage = defaultdict(list)
        request_type_stats = defaultdict(list)
        
        for log_entry in connection_log:
            server_usage[log_entry["server"]].append(log_entry["request_id"])
            request_type_stats[log_entry["request_type"]].append(log_entry["server"])
        
        # 计算负载分布
        total_requests = len(connection_log)
        server_request_counts = {server: len(requests) for server, requests in server_usage.items()}
        
        # 计算负载均衡质量
        request_counts = list(server_request_counts.values())
        avg_requests = statistics.mean(request_counts)
        load_variance = statistics.variance(request_counts) if len(request_counts) > 1 else 0
        
        # 负载均衡质量分数 (0-100, 越高越好)
        ideal_variance = 0
        actual_variance = load_variance
        quality_score = max(0, 100 - (actual_variance / avg_requests * 100)) if avg_requests > 0 else 0
        
        self.simulation_results = {
            "total_requests": total_requests,
            "server_usage": dict(server_request_counts),
            "request_type_distribution": {rt: len(servers) for rt, servers in request_type_stats.items()},
            "load_variance": load_variance,
            "average_requests_per_server": avg_requests,
            "load_balancing_quality": quality_score,
            "connection_log": connection_log
        }

# 主演示函数
def demo_least_connections():
    """主演示函数"""
    
    print("=== Least Connections Load Balancer Demo ===\n")
    
    # 1. 创建负载均衡器
    print("1. Setting up Least Connections Load Balancer")
    print("="*50)
    
    # 创建测试服务器
    servers = [
        Server("server1", "webserver1.com", 8080, max_connections=100, weight=1.0),
        Server("server2", "webserver2.com", 8080, max_connections=150, weight=1.5),
        Server("server3", "webserver3.com", 8080, max_connections=200, weight=2.0),
        Server("server4", "webserver4.com", 8080, max_connections=80, weight=1.0)
    ]
    
    # 创建不同策略的负载均衡器
    strategies = [
        LeastConnectionsStrategy.SIMPLE_LEAST_CONNECTIONS,
        LeastConnectionsStrategy.WEIGHTED_LEAST_CONNECTIONS,
        LeastConnectionsStrategy.LEAST_LOAD,
        LeastConnectionsStrategy.ADAPTIVE_LEAST_CONNECTIONS
    ]
    
    results = {}
    
    for strategy in strategies:
        print(f"\n--- Testing {strategy.value} strategy ---")
        
        lb = LeastConnectionsLoadBalancer(strategy=strategy)
        
        # 添加服务器
        for server in servers:
            lb.add_server(copy.deepcopy(server))
        
        # 运行仿真
        simulation = LoadBalancingSimulation(lb)
        simulation_results = simulation.simulate_traffic_patterns("uniform", duration=30)
        
        results[strategy.value] = simulation_results
        
        print(f"Total requests: {simulation_results['total_requests']}")
        print(f"Server usage: {simulation_results['server_usage']}")
        print(f"Load balancing quality: {simulation_results['load_balancing_quality']:.2f}")
    
    # 2. 不同流量模式测试
    print("\n2. Traffic Pattern Analysis")
    print("="*50)
    
    lb = LeastConnectionsLoadBalancer(LeastConnectionsStrategy.ADAPTIVE_LEAST_CONNECTIONS)
    
    for server in servers:
        lb.add_server(copy.deepcopy(server))
    
    patterns = ["uniform", "burst", "heavy_streaming", "file_heavy"]
    
    for pattern in patterns:
        print(f"\n--- {pattern.replace('_', ' ').title()} Pattern ---")
        
        simulation = LoadBalancingSimulation(lb)
        pattern_results = simulation.simulate_traffic_patterns(pattern, duration=20)
        
        print(f"Requests: {pattern_results['total_requests']}")
        print(f"Load variance: {pattern_results['load_variance']:.2f}")
        print(f"Balance quality: {pattern_results['load_balancing_quality']:.2f}")
        print(f"Request types: {pattern_results['request_type_distribution']}")
    
    # 3. 性能对比分析
    print("\n3. Strategy Performance Comparison")
    print("="*50)
    
    print(f"{'Strategy':<25} {'Quality':<10} {'Variance':<12} {'Avg Requests':<15}")
    print("-" * 65)
    
    for strategy, result in results.items():
        quality = result['load_balancing_quality']
        variance = result['load_variance']
        avg_requests = result['average_requests_per_server']
        
        print(f"{strategy:<25} {quality:<10.2f} {variance:<12.2f} {avg_requests:<15.2f}")
    
    # 4. 服务器容量测试
    print("\n4. Server Capacity Testing")
    print("="*50)
    
    capacity_lb = LeastConnectionsLoadBalancer(LeastConnectionsStrategy.WEIGHTED_LEAST_CONNECTIONS)
    
    # 添加不同容量的服务器
    capacity_servers = [
        Server("small", "small.com", 8080, max_connections=50, weight=0.5),
        Server("medium", "medium.com", 8080, max_connections=100, weight=1.0),
        Server("large", "large.com", 8080, max_connections=300, weight=3.0)
    ]
    
    for server in capacity_servers:
        capacity_lb.add_server(server)
    
    # 发送大量请求测试容量
    print("Testing with high load...")
    
    heavy_requests = []
    for i in range(200):
        result = capacity_lb.simulate_request(f"client_{i}", "normal", random.uniform(30, 120))
        if result["success"]:
            heavy_requests.append(result)
    
    metrics = capacity_lb.get_metrics()
    
    print(f"\nCapacity test results:")
    print(f"Total successful requests: {len(heavy_requests)}")
    print(f"Server utilization:")
    
    for server_metric in metrics["servers"]:
        utilization = server_metric["utilization"] * 100
        print(f"  {server_metric['id']}: {utilization:.1f}% ({server_metric['active_connections']}/{server_metric['max_connections']})")
    
    # 5. 故障恢复测试
    print("\n5. Failure Recovery Testing")
    print("="*50)
    
    recovery_lb = LeastConnectionsLoadBalancer(LeastConnectionsStrategy.ADAPTIVE_LEAST_CONNECTIONS)
    
    for server in servers[:3]:  # 只添加3台服务器
        recovery_lb.add_server(copy.deepcopy(server))
    
    # 正常情况下的请求分布
    print("Normal operation:")
    normal_requests = []
    for i in range(50):
        result = recovery_lb.simulate_request(f"client_{i}", "normal", 30)
        if result["success"]:
            normal_requests.append(result)
    
    server_usage_normal = defaultdict(int)
    for req in normal_requests:
        server_usage_normal[req["server"]] += 1
    
    print(f"Server usage: {dict(server_usage_normal)}")
    
    # 模拟一台服务器故障
    failed_server = servers[1]
    failed_server.is_healthy = False
    print(f"\nSimulating failure of {failed_server.hostname}")
    
    # 故障后的请求分布
    print("After server failure:")
    failed_requests = []
    for i in range(50):
        result = recovery_lb.simulate_request(f"client_{i+100}", "normal", 30)
        if result["success"]:
            failed_requests.append(result)
    
    server_usage_failed = defaultdict(int)
    for req in failed_requests:
        server_usage_failed[req["server"]] += 1
    
    print(f"Server usage: {dict(server_usage_failed)}")
    
    # 6. Go风格实现演示
    print("\n6. Go-Style Implementation Demo")
    print("="*50)
    
    go_servers = [
        {"id": "go1", "host": "go-server1", "port": 8080, "weight": 1.0, "max_connections": 100},
        {"id": "go2", "host": "go-server2", "port": 8080, "weight": 2.0, "max_connections": 200},
        {"id": "go3", "host": "go-server3", "port": 8080, "weight": 1.5, "max_connections": 150}
    ]
    
    go_lb = GoStyleLeastConnections(go_servers)
    
    print("Go-style server selection:")
    for i in range(10):
        server = go_lb.SelectWeightedServer()
        if server:
            go_lb.servers[go_lb.servers.index(server)]["active_connections"] += 1
            print(f"  Request {i+1}: {server['host']}:{server['port']} (connections: {server['active_connections']})")
    
    print("\n=== Least Connections Load Balancer Summary ===")
    print("Least Connections Algorithm provides:")
    print("• Dynamic load-aware distribution")
    print("• Real-time connection tracking")
    print("• Adaptive to server capacity")
    print("• Multiple strategy variations")
    print("\nKey Advantages:")
    print("• Considers real server load")
    print("• Better for varying request durations")
    print("• Supports weighted distribution")
    print("• Handles server capacity differences")
    print("\nUse Cases:")
    print("• Long-lived connections")
    print("• Streaming applications")
    print("• File upload/download services")
    print("• Heterogeneous server environments")
    print("\nStrategy Variations:")
    print("• Simple: Basic connection counting")
    print("• Weighted: Considers server weights")
    print("• Least Load: Multi-metric load calculation")
    print("• Adaptive: Request-type aware selection")

if __name__ == "__main__":
    demo_least_connections()