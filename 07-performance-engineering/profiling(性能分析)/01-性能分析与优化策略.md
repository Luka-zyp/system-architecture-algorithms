# 性能分析与优化策略

## 1. 性能分析基础

### 性能分析概念
```python
from enum import Enum
from dataclasses import dataclass
from typing import Dict, Any
import time
import psutil
import cProfile
import pstats
import io
import tracemalloc

class ProfilingType(Enum):
    CPU = "cpu"
    MEMORY = "memory"

@dataclass
class ProfilingResult:
    profiling_type: ProfilingType
    start_time: float
    end_time: float
    duration: float
    data: Dict[str, Any]

class CPUProfiler:
    """CPU性能分析器"""
    
    def __init__(self):
        self.profiler = None
        self.start_timestamp = 0.0
    
    def start_profiling(self):
        """开始CPU分析"""
        self.start_timestamp = time.time()
        self.profiler = cProfile.Profile()
        self.profiler.enable()
    
    def stop_profiling(self) -> ProfilingResult:
        """停止CPU分析"""
        self.profiler.disable()
        end_timestamp = time.time()
        duration = end_timestamp - self.start_timestamp
        
        stats_stream = io.StringIO()
        stats = pstats.Stats(self.profiler, stream=stats_stream)
        stats.sort_stats('cumulative')
        stats.print_stats()
        
        return ProfilingResult(
            profiling_type=ProfilingType.CPU,
            start_time=self.start_timestamp,
            end_time=end_timestamp,
            duration=duration,
            data={'stats': stats_stream.getvalue()}
        )

class MemoryProfiler:
    """内存性能分析器"""
    
    def __init__(self):
        self.start_timestamp = 0.0
    
    def start_profiling(self):
        """开始内存分析"""
        self.start_timestamp = time.time()
        tracemalloc.start()
    
    def stop_profiling(self) -> ProfilingResult:
        """停止内存分析"""
        tracemalloc.stop()
        end_timestamp = time.time()
        duration = end_timestamp - self.start_timestamp
        
        current, peak = tracemalloc.get_traced_memory()
        
        return ProfilingResult(
            profiling_type=ProfilingType.MEMORY,
            start_time=self.start_timestamp,
            end_time=end_timestamp,
            duration=duration,
            data={'current': current, 'peak': peak}
        )




```

## 2. 性能分析框架

### 核心分析器

1. **CPU分析器** - 分析CPU使用情况和函数执行时间
2. **内存分析器** - 监控内存使用和内存泄漏
3. **I/O分析器** - 分析磁盘和网络I/O性能
4. **行级分析器** - 提供代码行级别的性能分析

## 3. 性能优化策略

### 核心优化技术

1. **缓存策略** - 减少重复计算和数据访问
2. **并行处理** - 利用多核处理提升性能
3. **懒加载** - 延迟加载减少启动时间
4. **批处理** - 合并操作提高效率

### 性能分析最佳实践

1. **选择合适的分析器** - 根据应用特点选择分析类型
2. **设置合理的阈值** - 避免过度的性能开销
3. **定期性能测试** - 建立性能回归测试
4. **监控性能趋势** - 持续跟踪性能指标

## 4. 实践示例
        """使用缓存优化"""
        cache = {}
        cache_timestamps = {}
        lock = threading.Lock()
        
        @functools.wraps(func)
        def cached_func(*args, **kwargs):
            # 创建缓存键
            cache_key = str(args) + str(sorted(kwargs.items()))
            
            with lock:
                # 检查缓存
                if cache_key in cache:
                    # 检查TTL
                    if time.time() - cache_timestamps[cache_key] < cache_ttl:
                        return cache[cache_key]
                    else:
                        # 缓存过期，删除
                        del cache[cache_key]
                        del cache_timestamps[cache_key]
                
                # 执行函数
                result = func(*args, **kwargs)
                
                # 缓存结果
                cache[cache_key] = result
                cache_timestamps[cache_key] = time.time()
                
                return result
        
        return cached_func
    
    def _optimize_with_parallelization(self, func: Callable, 
                                     max_workers: int = None,
                                     use_multiprocessing: bool = False) -> Callable:
        """使用并行化优化"""
        executor_class = ProcessPoolExecutor if use_multiprocessing else ThreadPoolExecutor
        executor = executor_class(max_workers=max_workers)
        
        @functools.wraps(func)
        def parallel_func(*args, **kwargs):
            # 对于可并行化的操作，这里只是一个示例
            # 实际使用时需要根据具体场景调整
            if len(args) > 0 and hasattr(args[0], '__iter__'):
                # 如果第一个参数是可迭代的，并行处理
                items = list(args[0])
                remaining_args = args[1:]
                
                futures = []
                for item in items:
                    future = executor.submit(func, item, *remaining_args, **kwargs)
                    futures.append(future)
                
                results = []
                for future in futures:
                    results.append(future.result())
                
                return results
            else:
                # 单个任务，直接执行
                return func(*args, **kwargs)
        
        return parallel_func
    
    def _optimize_with_lazy_loading(self, func: Callable) -> Callable:
        """使用懒加载优化"""
        class LazyWrapper:
            def __init__(self, func, *args, **kwargs):
                self.func = func
                self.args = args
                self.kwargs = kwargs
                self._result = None
                self._computed = False
            
            def __call__(self, *args, **kwargs):
                if not self._computed:
                    self._result = self.func(*self.args, **{**self.kwargs, **kwargs})
                    self._computed = True
                return self._result
            
            def __getattr__(self, name):
                if not self._computed:
                    self._result = self.func(*self.args, **self.kwargs)
                    self._computed = True
                return getattr(self._result, name)
        
        return LazyWrapper
    
    def _optimize_with_batch_processing(self, func: Callable, batch_size: int = 100) -> Callable:
        """使用批处理优化"""
        batch_buffer = []
        batch_lock = threading.Lock()
        batch_results = {}
        
        def flush_batch():
            nonlocal batch_buffer
            if not batch_buffer:
                return
            
            batch_items = batch_buffer[:]
            batch_buffer.clear()
            
            # 批量处理
            for i, (args, kwargs, result_future) in enumerate(batch_items):
                try:
                    result = func(*args, **kwargs)
                    batch_results[id(result_future)] = result
                except Exception as e:
                    batch_results[id(result_future)] = e
        
        @functools.wraps(func)
        def batch_func(*args, **kwargs):
            # 在实际实现中，需要一个更复杂的机制来管理future
            # 这里简化处理
            result = func(*args, **kwargs)
            
            # 定期刷新批处理缓冲区
            with batch_lock:
                batch_buffer.append((args, kwargs, None))
                
                if len(batch_buffer) >= batch_size:
                    flush_batch()
            
            return result
        
        # 添加刷新方法
        batch_func.flush = flush_batch
        return batch_func

class AsyncPerformanceOptimizer:
    """异步性能优化器"""
    
    def __init__(self):
        self.optimization_strategies = {
            'async_memoization': self._optimize_async_memoization,
            'async_caching': self._optimize_async_caching,
            'async_batch': self._optimize_async_batch
        }
    
    async def optimize_async_function(self, func: Callable, strategy: str, **kwargs) -> Callable:
        """优化异步函数"""
        if strategy not in self.optimization_strategies:
            raise ValueError(f"Unknown optimization strategy: {strategy}")
        
        return self.optimization_strategies[strategy](func, **kwargs)
    
    def _optimize_async_memoization(self, func: Callable, max_size: int = 128) -> Callable:
        """异步记忆化"""
性能分析应该成为开发流程的一部分，而不仅仅是问题出现后的补救措施。

### 基本性能分析

```python
# CPU性能分析示例
def cpu_intensive_task():
    """CPU密集型任务示例"""
    total = 0
    for i in range(1000000):
        total += i * i
    return total

# 启动性能分析
cpu_profiler = CPUProfiler()
cpu_profiler.start_profiling()

# 执行任务
result = cpu_intensive_task()

# 停止分析并获取结果
cpu_result = cpu_profiler.stop_profiling()
print(f"CPU分析结果: {cpu_result}")
```

### 内存分析示例

```python
def memory_consuming_task():
    """内存消耗任务示例"""
    data = [i * i for i in range(100000)]
    return sum(data)

# 启动内存分析
memory_profiler = MemoryProfiler()
memory_profiler.start_profiling()

# 执行任务
result = memory_consuming_task()

# 停止分析并获取结果
memory_result = memory_profiler.stop_profiling()
print(f"内存分析结果: {memory_result}")
```

## 5. 总结

性能分析是系统优化的重要工具。通过合理使用CPU、内存等分析器，可以识别性能瓶颈并采取针对性的优化措施。关键在于：

1. **选择合适的分析工具** - 根据场景选择最适合的分析器
2. **建立基线数据** - 记录性能指标作为基准
3. **持续监控** - 定期执行性能分析
4. **数据驱动优化** - 基于分析结果制定优化策略

性能分析应该成为开发流程的一部分，而不仅仅是问题出现后的补救措施。