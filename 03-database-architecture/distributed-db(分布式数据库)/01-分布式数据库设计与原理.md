# 分布式数据库设计与原理

## 概述

分布式数据库是现代大规模系统架构的核心组件，它通过将数据和计算分布在多个节点上，实现高可用性、可扩展性和容错能力。深入理解分布式数据库的原理、设计模式和技术选型，是构建企业级系统的关键技能。

## 分布式数据库基础原理

### 分布式数据库概述

**分布式数据库的定义**：
- 分布式数据库是在地理上分布的逻辑数据库，由多个物理数据库组成
- 数据存储在多个计算机节点上，对用户呈现为统一的逻辑数据库
- 具有数据分布性、逻辑统一性、站点自治性和分布透明性等特点

**分布式数据库的优势**：
- **可扩展性**：通过增加节点来扩展存储容量和处理能力
- **可用性**：单点故障不影响整体系统运行
- **性能**：数据就近访问，减少网络延迟
- **成本效益**：可以使用普通硬件构建高性能系统

**分布式数据库的挑战**：
- **一致性**：维护数据在不同节点间的一致性
- **可用性**：在网络分区或节点故障时的服务能力
- **分区容错**：在网络分区时系统仍能运行
- **复杂性**：系统设计和运维复杂度增加

### CAP定理

**CAP定理的核心概念**：

```mermaid
graph TD
    A[CAP定理] --> B[一致性 Consistency]
    A --> C[可用性 Availability]
    A --> D[分区容错性 Partition Tolerance]
    
    B --> E[所有节点同时看到相同数据]
    C --> F[每个请求都能收到响应]
    D --> G[网络分区时系统仍能运行]
    
    A --> H[只能同时满足两个特性]
    H --> I[CP系统]
    H --> J[AP系统]
    H --> K[CA系统（理论存在）]
```

**一致性分类**：

```python
from abc import ABC, abstractmethod
from typing import List, Dict, Optional
from dataclasses import dataclass
import time
from enum import Enum

# 一致性模型层次
class ConsistencyLevel(Enum):
    STRONG = "strong"
    WEAK = "weak"
    EVENTUAL = "eventual"
    CAUSAL = "causal"
    READ_YOUR_WRITES = "read_your_writes"

class ConsistencyModel(ABC):
    @abstractmethod
    def write(self, key: str, value: str, **kwargs) -> bool:
        """写入数据"""
        pass
    
    @abstractmethod
    def read(self, key: str, **kwargs) -> Optional[str]:
        """读取数据"""
        pass

class StrongConsistency(ConsistencyModel):
    """强一致性：所有节点同时看到最新数据"""
    
    def write(self, key: str, value: str, **kwargs) -> bool:
        """写入操作需要多数节点确认"""
        # 实现强一致性写入逻辑
        return True
    
    def read(self, key: str, **kwargs) -> Optional[str]:
        """总是返回最新写入的值"""
        # 实现强一致性读取逻辑
        return "latest_value"

class WeakConsistency(ConsistencyModel):
    """弱一致性：数据最终会一致，但不保证立即一致"""
    
    def __init__(self):
        self.inconsistency_window = 5  # 不一致窗口（秒）
    
    def write(self, key: str, value: str, **kwargs) -> bool:
        """写入操作可能只更新部分节点"""
        # 实现弱一致性写入逻辑
        return True
    
    def read(self, key: str, **kwargs) -> Optional[str]:
        """可能返回旧数据"""
        # 实现弱一致性读取逻辑
        return "possibly_old_value"
    
    def get_inconsistency_window(self) -> int:
        """获取不一致窗口（秒）"""
        return self.inconsistency_window

class EventualConsistency(ConsistencyModel):
    """最终一致性：在没有新写入时，数据最终会达到一致"""
    
    def write(self, key: str, value: str, **kwargs) -> bool:
        """异步复制到其他节点"""
        # 实现最终一致性写入逻辑
        return True
    
    def read(self, key: str, **kwargs) -> Optional[str]:
        """可能返回旧数据，但最终会一致"""
        # 实现最终一致性读取逻辑
        return "eventually_consistent_value"
    
    def is_converged(self, key: str) -> bool:
        """检查数据是否已收敛"""
        # 实现收敛检查逻辑
        return True

class CausalConsistency(ConsistencyModel):
    """因果一致性：保证因果相关的操作顺序一致"""
    
    def __init__(self):
        self.dependencies: Dict[str, List[str]] = {}
    
    def write(self, key: str, value: str, **kwargs) -> bool:
        """写入操作"""
        # 实现因果一致性写入逻辑
        return True
    
    def read(self, key: str, **kwargs) -> Optional[str]:
        """读取数据，保持因果顺序"""
        # 实现因果一致性读取逻辑
        return "causally_consistent_value"
    
    def mark_as_dependent(self, key1: str, key2: str):
        """定义key1依赖于key2的因果关系"""
        if key1 not in self.dependencies:
            self.dependencies[key1] = []
        self.dependencies[key1].append(key2)

class ReadYourWritesConsistency(ConsistencyModel):
    """读己之写一致性：用户总是看到自己的最新写入"""
    
    def __init__(self):
        self.session_data: Dict[str, Dict[str, str]] = {}
    
    def write(self, key: str, value: str, session_id: str, **kwargs) -> bool:
        """写入操作，记录session"""
        if session_id not in self.session_data:
            self.session_data[session_id] = {}
        self.session_data[session_id][key] = value
        # 实现写入逻辑
        return True
    
    def read(self, key: str, session_id: str, **kwargs) -> Optional[str]:
        """返回该session的最新写入"""
        if session_id in self.session_data and key in self.session_data[session_id]:
            return self.session_data[session_id][key]
        # 实现读取逻辑
        return "default_value"

# 一致性实现示例
class StrongConsistencyKVStore:
    """强一致性键值存储实现"""
    
    def __init__(self, nodes: List[str], replication_factor: int = 3):
        self.nodes = nodes
        self.replication_factor = replication_factor
        self.consistency = StrongConsistency()
    def write(self, key: str, value: str) -> bool:
        # 1. 选择主节点
        primary = self._select_primary_node(key)
        
        # 2. 写入主节点
        primary.write(key, value)
        
        # 3. 同步复制到所有副本
        replicas = self._select_replica_nodes(key, self.replication_factor - 1)
        for replica in replicas:
            replica.write_async(key, value)
        
        # 4. 等待所有副本确认
        return self._wait_for_all_replicas(key, value)
    
    def read(self, key: str) -> Optional[str]:
        # 读取所有副本并比较
        values = []
        for node in self.nodes:
            values.append(node.read(key))
        
        # 检查一致性
        first_value = values[0]
        for value in values:
            if value != first_value:
                raise ValueError("数据不一致")
        
        return first_value
    
    def _select_primary_node(self, key: str):
        # 实现主节点选择逻辑
        return self.nodes[0]  # 简化示例
    
    def _select_replica_nodes(self, key: str, count: int):
        # 实现副本节点选择逻辑
        return self.nodes[1:count+1]  # 简化示例
    
    def _wait_for_all_replicas(self, key: str, value: str) -> bool:
        # 实现等待逻辑
        time.sleep(0.1)  # 模拟等待
        return True


# 一致性异常类
class ConsistencyViolationException(Exception):
    pass
```

### 数据分片原理

**分片策略**：

```python
from abc import ABC, abstractmethod
from typing import List, Set

# 分片策略接口
class ShardingStrategy(ABC):
    @abstractmethod
    def shard_id(self, key: str, total_shards: int) -> int:
        """获取单个key的分片ID"""
        pass
    
    @abstractmethod
    def shard_ids(self, keys: List[str], total_shards: int) -> Set[int]:
        """获取多个key的所有分片ID集合"""
        pass

# 1. 哈希分片
class HashShardingStrategy(ShardingStrategy):
    def __init__(self, total_shards: int):
        self.total_shards = total_shards
    
    def shard_id(self, key: str, total_shards: int) -> int:
        """基于哈希计算分片ID"""
        hash_value = hash(key)
        return abs(hash_value) % total_shards
    
    def shard_ids(self, keys: List[str], total_shards: int) -> Set[int]:
        """获取多个key的所有分片ID"""
        shard_ids = set()
        for key in keys:
            shard_ids.add(self.shard_id(key, total_shards))
        return shard_ids


# 2. 范围分片
class RangeShardingStrategy(ShardingStrategy):
    def __init__(self, range_shards: List[dict]):
        """
        初始化范围分片策略
        
        Args:
            range_shards: 分片范围列表，每个元素包含'start', 'end', 'shard_id'
        """
        # 按起始值排序
        self.range_shards = sorted(range_shards, key=lambda x: x['start'])
    
    def shard_id(self, key: str, total_shards: int) -> int:
        """根据key获取分片ID"""
        numeric_key = int(key)
        for shard in self.range_shards:
            if shard['start'] <= numeric_key < shard['end']:
                return shard['shard_id']
        raise ValueError(f"Key out of range: {key}")

# 3. 目录分片
class DirectoryShardingStrategy(ShardingStrategy):
    def __init__(self, shard_directory):
        """
        初始化目录分片策略
        
        Args:
            shard_directory: 分片目录对象，需实现get_shard_for_key方法
        """
        self.shard_directory = shard_directory
    
    def shard_id(self, key: str, total_shards: int) -> int:
        """根据key获取分片ID"""
        return self.shard_directory.get_shard_for_key(key)
    
    def shard_ids(self, keys: List[str], total_shards: int) -> Set[int]:
        """获取多个key的所有分片ID"""
        unique_shard_ids = set()
        for key in keys:
            unique_shard_ids.add(self.shard_id(key, total_shards))
        return unique_shard_ids

# 分片目录接口
class ShardDirectory:
    """分片目录接口定义"""
    def get_shard_for_key(self, key: str) -> int:
        """获取指定key的分片ID"""
        raise NotImplementedError
    
    def update_shard_mapping(self, key: str, shard_id: int) -> None:
        """更新key的分片映射"""
        raise NotImplementedError
    
    def remove_shard_mapping(self, key: str) -> None:
        """移除key的分片映射"""
        raise NotImplementedError

# 分片管理器
class ShardManager:
    def __init__(self, sharding_strategy: ShardingStrategy, total_shards: int):
        """
        初始化分片管理器
        
        Args:
            sharding_strategy: 分片策略
            total_shards: 总分片数
        """
        self.sharding_strategy = sharding_strategy
        self.total_shards = total_shards
        self.shard_nodes: Dict[int, 'ShardNode'] = {}  # 使用字典模拟ConcurrentHashMap
    
    def add_shard_node(self, shard_id: int, node: 'ShardNode') -> None:
        """添加分片节点"""
        self.shard_nodes[shard_id] = node
    
    def remove_shard_node(self, shard_id: int) -> None:
        """移除分片节点"""
        if shard_id in self.shard_nodes:
            del self.shard_nodes[shard_id]
    
    def get_shard_node(self, key: str) -> 'ShardNode':
        """根据key获取分片节点"""
        shard_id = self.sharding_strategy.shard_id(key, self.total_shards)
        node = self.shard_nodes.get(shard_id)
        if node is None:
            raise ValueError(f"Shard {shard_id} not available")
        return node

# 分片节点类
class ShardNode:
    """分片节点类"""
    def __init__(self, host: str, port: int):
        self.host = host
        self.port = port
    
    def write(self, key: str, value: str) -> bool:
        """写入数据"""
        # 实现写入逻辑
        return True
    
    def read(self, key: str) -> Optional[str]:
        """读取数据"""
        # 实现读取逻辑
        return "data"
    
    def get_shard_nodes(self, keys: List[str], sharding_strategy: 'ShardingStrategy', 
                        shard_nodes: Dict[int, 'ShardNode'], total_shards: int) -> List['ShardNode']:
        """获取与给定键相关的所有分片节点"""
        shard_ids = set(sharding_strategy.shard_ids(keys, total_shards))
        
        return [shard_nodes[sid] for sid in shard_ids if sid in shard_nodes]
```

### 副本机制

**复制策略**：

```python
# 复制模式
from enum import Enum
from typing import List, Optional, Dict
import asyncio
import time

class ReplicationMode(Enum):
    SYNCHRONOUS = "同步复制"
    ASYNCHRONOUS = "异步复制"
    SEMI_SYNC = "半同步复制"

# 确认结果类
class AckResult:
    """复制确认结果"""
    def __init__(self, node_id: str, success: bool, timestamp: float = None):
        self.node_id = node_id
        self.success = success
        self.timestamp = timestamp or time.time()

# 写入结果类
class WriteResult:
    """写入操作结果"""
    def __init__(self, success: bool, total_nodes: int, ack_nodes: int, 
                 failed_nodes: List[str] = None, error: str = None):
        self.success = success
        self.total_nodes = total_nodes
        self.ack_nodes = ack_nodes
        self.failed_nodes = failed_nodes or []
        self.error = error
    
    @classmethod
    def success(cls, total_nodes: int, ack_nodes: int) -> 'WriteResult':
        return cls(True, total_nodes, ack_nodes)
    
    @classmethod
    def failure(cls, total_nodes: int, ack_nodes: int, failed_nodes: List[str], 
               error: str) -> 'WriteResult':
        return cls(False, total_nodes, ack_nodes, failed_nodes, error)

# 副本节点类
class ReplicaNode:
    """副本节点"""
    def __init__(self, node_id: str, host: str, port: int):
        self.node_id = node_id
        self.host = host
        self.port = port
        self.data_store = {}
    
    async def write_async(self, key: str, value: str) -> AckResult:
        """异步写入"""
        try:
            # 模拟写入延迟
            await asyncio.sleep(0.1)
            self.data_store[key] = value
            return AckResult(self.node_id, True)
        except Exception:
            return AckResult(self.node_id, False)

# 复制管理器
class ReplicationManager:
    """复制管理器"""
    def __init__(self, replicas: List[ReplicaNode], mode: ReplicationMode):
        self.replicas = replicas
        self.mode = mode
        self.min_ack_nodes = self._calculate_min_ack_nodes(mode)
    
    async def write(self, key: str, value: str) -> WriteResult:
        """执行写入操作"""
        if self.mode == ReplicationMode.SYNCHRONOUS:
            return await self._write_synchronous(key, value)
        elif self.mode == ReplicationMode.ASYNCHRONOUS:
            return await self._write_asynchronous(key, value)
        elif self.mode == ReplicationMode.SEMI_SYNC:
            return await self._write_semi_synchronous(key, value)
        else:
            raise ValueError(f"不支持的复制模式: {self.mode}")
    
    async def _write_synchronous(self, key: str, value: str) -> WriteResult:
        """同步复制写入"""
        tasks = [replica.write_async(key, value) for replica in self.replicas]
        
        try:
            # 等待所有节点确认（5秒超时）
            results = await asyncio.wait_for(
                asyncio.gather(*tasks, return_exceptions=True),
                timeout=5.0
            )
        except asyncio.TimeoutError:
            return WriteResult.failure(
                len(self.replicas), 0, 
                [r.node_id for r in self.replicas], "写入超时"
            )
        
        ack_results = [r for r in results if isinstance(r, AckResult) and r.success]
        failed_results = [r for r in results if isinstance(r, AckResult) and not r.success]
        
        return WriteResult.success(len(self.replicas), len(ack_results))
    
    async def _write_asynchronous(self, key: str, value: str) -> WriteResult:
        """异步复制写入"""
        # 异步写入所有副本，不等待确认
        asyncio.create_task(
            asyncio.gather(*[r.write_async(key, value) for r in self.replicas], return_exceptions=True)
        )
        
        return WriteResult.success(len(self.replicas), 1)  # 只需要主节点确认
    
    async def _write_semi_synchronous(self, key: str, value: str) -> WriteResult:
        """半同步复制写入"""
        # 主节点写入
        primary = self.replicas[0]
        primary_result = await primary.write_async(key, value)
        
        if not primary_result.success:
            return WriteResult.failure(
                len(self.replicas), 0, 
                [primary.node_id], "主节点写入失败"
            )
        
        # 异步写入其他副本，但等待至少min_ack_nodes-1个确认
        other_replicas = self.replicas[1:]
        if not other_replicas:
            return WriteResult.success(1, 1)
        
        tasks = [replica.write_async(key, value) for replica in other_replicas]
        
        # 需要等待的副本数
        required_acks = max(0, self.min_ack_nodes - 1)
        if required_acks == 0:
            return WriteResult.success(len(self.replicas), 1)
        
        try:
            # 等待至少required_acks个副本确认（3秒超时）
            results = await asyncio.wait_for(
                asyncio.gather(*tasks[:required_acks], return_exceptions=True),
                timeout=3.0
            )
        except asyncio.TimeoutError:
            return WriteResult.failure(
                len(self.replicas), 1, 
                ["timeout"], "复制超时"
            )
        
        # 统计成功的副本数
        successful_replicas = [r for r in results if isinstance(r, AckResult) and r.success]
        total_acks = 1 + len(successful_replicas)  # 1表示主节点
        
        return WriteResult.success(len(self.replicas), total_acks)
    
    async def read(self, key: str) -> str:
        """读取数据"""
        if not self.replicas:
            raise self.NoReplicaAvailableException("没有可用副本")
        
        # 读取所有副本并收集结果
        values = []
        for replica in self.replicas:
            try:
                # 简单的读取实现，实际应该有完整的读取方法
                value = replica.data_store.get(key)
                if value is not None:
                    values.append(value)
            except Exception:
                continue
        
        if not values:
            raise self.ReadFailureException("无法从所有副本读取数据")
        
        # 使用冲突解决策略
        return self._resolve_conflicts(values)
    }
    
    def _resolve_conflicts(self, values: List[str]) -> str:
        """解决数据冲突"""
        if len(values) == 1:
            return values[0]
        
        # 实现冲突解决策略（时间戳、版本号、优先级等）
        # 这里使用自然排序作为简化实现
        return max(values)
    
    def _calculate_min_ack_nodes(self, mode: ReplicationMode) -> int:
        """计算需要的最小确认节点数"""
        match mode:
            case ReplicationMode.SYNCHRONOUS:
                return len(self.replicas)
            case ReplicationMode.SEMI_SYNC:
                return max(2, (len(self.replicas) // 2) + 1)  # 多数
            case ReplicationMode.ASYNCHRONOUS:
                return 1
            case _:
                return 1
    
    async def get_replica_status(self) -> Dict[str, bool]:
        """获取所有副本的状态"""
        status = {}
        for replica in self.replicas:
            try:
                # 简单的健康检查
                result = await replica.write_async("__health_check__", "1")
                status[replica.node_id] = result.success
            except:
                status[replica.node_id] = False
        return status
    
    # 异常类
    class NoReplicaAvailableException(Exception):
        """没有可用副本异常"""
        pass
    
    class ReadFailureException(Exception):
        """读取失败异常"""
        pass
    
    class WriteFailureException(Exception):
        """写入失败异常"""
        pass
    
    class UnsupportedOperationException(Exception):
        """不支持的操作异常"""
        pass
}
```

## 分布式一致性算法

### Paxos算法

**Paxos原理**：

```java
// Paxos算法实现
public class PaxosNode {
    private final int nodeId;
    private final List<PaxosNode> allNodes;
    private final int quorum;
    
    // Proposer状态
    private int currentProposalNumber = 0;
    private int lastAcceptedProposal = -1;
    private String lastAcceptedValue = null;
    
    // Acceptor状态
    private final Map<Integer, Proposal> acceptedProposals = new ConcurrentHashMap<>();
    private final Map<Integer, Integer> promisedProposals = new ConcurrentHashMap<>();
    
    public PaxosNode(int nodeId, List<PaxosNode> allNodes) {
        this.nodeId = nodeId;
        this.allNodes = allNodes;
        this.quorum = (allNodes.size() / 2) + 1;
    }
    
    // 阶段1：Prepare
    public PrepareResponse prepare(int proposalNumber) {
        if (proposalNumber <= promisedProposals.getOrDefault(nodeId, -1)) {
            return new PrepareResponse(false, lastAcceptedProposal, lastAcceptedValue);
        }
        
        // 更新承诺
        promisedProposals.put(nodeId, proposalNumber);
        
        return new PrepareResponse(true, lastAcceptedProposal, lastAcceptedValue);
    }
    
    // 阶段2：Accept
    public AcceptResponse accept(int proposalNumber, String value) {
        if (proposalNumber < promisedProposals.getOrDefault(nodeId, -1)) {
            return new AcceptResponse(false, "Proposal number too low");
        }
        
        // 接受提议
        acceptedProposals.put(proposalNumber, new Proposal(proposalNumber, value, nodeId));
        lastAcceptedProposal = proposalNumber;
        lastAcceptedValue = value;
        
        return new AcceptResponse(true, "Accepted");
    }
    
    // Proposer发起提议
    public PaxosResult propose(String value) throws InterruptedException {
        int proposalNumber = ++currentProposalNumber;
        
        // 阶段1：Prepare请求
        List<PrepareResponse> prepares = sendPrepareRequests(proposalNumber);
        
        long acceptedCount = prepares.stream().filter(PrepareResponse::isPromise).count();
        if (acceptedCount < quorum) {
            return PaxosResult.failure("Insufficient promises: " + acceptedCount + "/" + quorum);
        }
        
        // 选择值（最高编号的accepted值或新值）
        String chosenValue = selectValue(prepares, value);
        
        // 阶段2：Accept请求
        List<AcceptResponse> accepts = sendAcceptRequests(proposalNumber, chosenValue);
        
        long acceptedCount2 = accepts.stream().filter(AcceptResponse::isAccepted).count();
        if (acceptedCount2 < quorum) {
            return PaxosResult.failure("Insufficient accepts: " + acceptedCount2 + "/" + quorum);
        }
        
        return PaxosResult.success(chosenValue);
    }
    
    private List<PrepareResponse> sendPrepareRequests(int proposalNumber) {
        return allNodes.parallelStream()
                .map(node -> {
                    try {
                        return node.prepare(proposalNumber);
                    } catch (Exception e) {
                        return new PrepareResponse(false, -1, null);
                    }
                })
                .collect(Collectors.toList());
    }
    
    private String selectValue(List<PrepareResponse> prepares, String newValue) {
        return prepares.stream()
                .filter(PrepareResponse::isPromise)
                .filter(response -> response.getLastAcceptedProposal() > -1)
                .max(Comparator.comparing(PrepareResponse::getLastAcceptedProposal))
                .map(PrepareResponse::getLastAcceptedValue)
                .orElse(newValue);
    }
    
    private List<AcceptResponse> sendAcceptRequests(int proposalNumber, String value) {
        return allNodes.parallelStream()
                .map(node -> {
                    try {
                        return node.accept(proposalNumber, value);
                    } catch (Exception e) {
                        return new AcceptResponse(false, e.getMessage());
                    }
                })
                .collect(Collectors.toList());
    }
}

// 结果类
public class PaxosResult {
    private final boolean success;
    private final String value;
    private final String error;
    
    private PaxosResult(boolean success, String value, String error) {
        this.success = success;
        this.value = value;
        this.error = error;
    }
    
    public static PaxosResult success(String value) {
        return new PaxosResult(true, value, null);
    }
    
    public static PaxosResult failure(String error) {
        return new PaxosResult(false, null, error);
    }
    
    public boolean isSuccess() { return success; }
    public String getValue() { return value; }
    public String getError() { return error; }
}
```

### Raft算法

**Raft算法实现**：

```java
// Raft算法实现
public class RaftNode {
    private final int nodeId;
    private final List<RaftNode> allNodes;
    private final int quorum;
    
    // 状态
    private RaftState state = RaftState.FOLLOWER;
    private int currentTerm = 0;
    private int votedFor = -1;
    private int commitIndex = -1;
    private int lastApplied = -1;
    
    // Leader状态
    private int leaderId = -1;
    private final Map<Integer, Integer> nextIndex = new ConcurrentHashMap<>();
    private final Map<Integer, Integer> matchIndex = new ConcurrentHashMap<>();
    
    // 日志
    private final List<LogEntry> log = new ArrayList<>();
    
    // 选举相关
    private long lastHeartbeatTime = 0;
    private final Duration electionTimeout = Duration.ofMillis(150 + new Random().nextInt(150));
    
    // 通信接口
    public interface RaftNode {
        RequestVoteResponse requestVote(RequestVoteRequest request);
        AppendEntriesResponse appendEntries(AppendEntriesRequest request);
        InstallSnapshotResponse installSnapshot(InstallSnapshotRequest request);
    }
    
    // 选举定时器
    public void checkElectionTimeout() {
        if (System.currentTimeMillis() - lastHeartbeatTime > electionTimeout.toMillis()) {
            startElection();
        }
    }
    
    private void startElection() {
        state = RaftState.CANDIDATE;
        currentTerm++;
        votedFor = nodeId;
        lastHeartbeatTime = System.currentTimeMillis();
        
        // 给自己投票
        int voteCount = 1;
        
        // 向其他节点请求投票
        List<RequestVoteResponse> responses = allNodes.parallelStream()
                .filter(node -> node != this)
                .map(node -> node.requestVote(new RequestVoteRequest(currentTerm, nodeId, log.size(), log.isEmpty() ? -1 : log.get(log.size() - 1).getTerm())))
                .collect(Collectors.toList());
        
        for (RequestVoteResponse response : responses) {
            if (response.isVoteGranted()) {
                voteCount++;
            }
        }
        
        if (voteCount >= quorum) {
            becomeLeader();
        } else {
            // 选举失败，回到Follower状态
            state = RaftState.FOLLOWER;
            votedFor = -1;
        }
    }
    
    private void becomeLeader() {
        state = RaftState.LEADER;
        leaderId = nodeId;
        
        // 初始化Leader状态
        for (RaftNode node : allNodes) {
            if (node != this) {
                nextIndex.put(node.nodeId, log.size() + 1);
                matchIndex.put(node.nodeId, 0);
            }
        }
        
        // 立即发送心跳
        sendHeartbeat();
    }
    
    // 日志复制
    public void replicateLog(String command) {
        if (state != RaftState.LEADER) {
            throw new IllegalStateException("Only leader can replicate logs");
        }
        
        // 添加日志条目
        LogEntry entry = new LogEntry(currentTerm, command, System.currentTimeMillis());
        log.add(entry);
        
        // 尝试复制到Followers
        replicateToFollowers();
    }
    
    private void replicateToFollowers() {
        for (RaftNode follower : allNodes) {
            if (follower == this) continue;
            
            try {
                int nextIdx = nextIndex.get(follower.nodeId);
                
                // 准备日志条目
                List<LogEntry> entriesToSend = new ArrayList<>();
                if (nextIdx <= log.size()) {
                    entriesToSend.addAll(log.subList(nextIdx - 1, log.size()));
                }
                
                // 发送AppendEntries
                AppendEntriesRequest request = new AppendEntriesRequest(
                    currentTerm, nodeId, nextIdx - 1, 
                    nextIdx > 1 ? log.get(nextIdx - 2).getTerm() : -1,
                    entriesToSend, commitIndex
                );
                
                AppendEntriesResponse response = follower.appendEntries(request);
                
                if (response.isSuccess()) {
                    // 更新匹配索引
                    if (!entriesToSend.isEmpty()) {
                        matchIndex.put(follower.nodeId, nextIdx + entriesToSend.size() - 1);
                        nextIndex.put(follower.nodeId, matchIndex.get(follower.nodeId) + 1);
                    }
                } else {
                    // 减少nextIndex重试
                    nextIndex.put(follower.nodeId, Math.max(1, nextIdx - 1));
                }
            } catch (Exception e) {
                // 处理失败情况
                nextIndex.put(follower.nodeId, Math.max(1, nextIndex.get(follower.nodeId) - 1));
            }
        }
        
        // 检查是否可以提交
        checkCommitIndex();
    }
    
    private void checkCommitIndex() {
        // 找到大多数节点都有的最高日志索引
        List<Integer> matchIndices = new ArrayList<>(matchIndex.values());
        matchIndices.add(log.size()); // Leader自己的日志
        Collections.sort(matchIndices, Collections.reverseOrder());
        
        int newCommitIndex = matchIndices.get(quorum - 1);
        
        if (newCommitIndex > commitIndex && log.get(newCommitIndex - 1).getTerm() == currentTerm) {
            commitIndex = newCommitIndex;
            applyCommittedEntries();
        }
    }
    
    private void applyCommittedEntries() {
        while (lastApplied < commitIndex) {
            lastApplied++;
            LogEntry entry = log.get(lastApplied);
            applyLogEntry(entry);
        }
    }
    
    private void applyLogEntry(LogEntry entry) {
        // 应用日志条目到状态机
        // 具体实现取决于应用场景
        System.out.println("Applying log entry: " + entry.getCommand());
    }
    
    private void sendHeartbeat() {
        AppendEntriesRequest heartbeat = new AppendEntriesRequest(
            currentTerm, nodeId, log.size(), 
            log.isEmpty() ? -1 : log.get(log.size() - 1).getTerm(),
            Collections.emptyList(), commitIndex
        );
        
        allNodes.parallelStream()
                .filter(node -> node != this)
                .forEach(node -> node.appendEntries(heartbeat));
    }
    
    // 状态机
    public enum RaftState {
        FOLLOWER, CANDIDATE, LEADER
    }
    
    // 日志条目
    public static class LogEntry {
        private final int term;
        private final String command;
        private final long timestamp;
        
        public LogEntry(int term, String command, long timestamp) {
            this.term = term;
            this.command = command;
            this.timestamp = timestamp;
        }
        
        public int getTerm() { return term; }
        public String getCommand() { return command; }
        public long getTimestamp() { return timestamp; }
    }
}
```

## 分布式事务

### 两阶段提交（2PC）

**2PC原理实现**：

```java
// 两阶段提交协议实现
public class TwoPhaseCommitCoordinator {
    private final List<Participant> participants;
    private final String transactionId;
    private CommitState state = CommitState.INITIATED;
    
    public TwoPhaseCommitCoordinator(List<Participant> participants, String transactionId) {
        this.participants = participants;
        this.transactionId = transactionId;
    }
    
    public CommitResult executeTransaction(TransactionAction action) {
        try {
            // 阶段1：准备阶段
            List<PrepareResult> prepareResults = preparePhase(action);
            
            // 检查所有参与者是否准备好
            if (prepareResults.stream().allMatch(PrepareResult::isReady)) {
                // 阶段2：提交阶段
                return commitPhase();
            } else {
                // 中止事务
                return abortPhase();
            }
        } catch (Exception e) {
            // 发生异常，中止事务
            return abortPhase();
        }
    }
    
    private List<PrepareResult> preparePhase(TransactionAction action) {
        List<CompletableFuture<PrepareResult>> futures = participants.stream()
                .map(participant -> CompletableFuture.supplyAsync(() -> {
                    try {
                        return participant.prepare(transactionId, action);
                    } catch (Exception e) {
                        return PrepareResult.notReady(e.getMessage());
                    }
                }))
                .collect(Collectors.toList());
        
        import concurrent.futures
        
        # 使用线程池执行并行请求
        results = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=len(self.participants)) as executor:
            # 提交所有准备请求
            future_to_participant = {
                executor.submit(participant.prepare, self.transaction_id, self.action): participant
                for participant in self.participants
            }
            
            # 收集结果
            for future in concurrent.futures.as_completed(future_to_participant):
                try:
                    result = future.result(timeout=30)
                    results.append(result)
                except Exception as e:
                    results.append(PrepareResult.not_ready(f"Timeout: {str(e)}"))
        
        return results
    
    def _commit_phase(self):
        """执行提交阶段"""
        import concurrent.futures
        
        # 使用线程池执行并行提交请求
        results = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=len(self.participants)) as executor:
            # 提交所有提交请求
            future_to_participant = {
                executor.submit(participant.commit, self.transaction_id): participant
                for participant in self.participants
            }
            
            # 收集结果
            for future in concurrent.futures.as_completed(future_to_participant):
                try:
                    result = future.result(timeout=30)
                    results.append(result)
                except Exception as e:
                    results.append(CommitResult.failure(f"Commit timeout: {str(e)}"))
        
        self.state = CommitState.COMMITTED
        
        all_committed = all(result.is_success() for result in results)
        if all_committed:
            return CommitResult.success("Transaction committed successfully")
        else:
            # 部分提交失败，需要补偿操作
            self._compensate_phase(results)
            return CommitResult.failure("Transaction commit failed")
    
    def _abort_phase(self):
        """执行中止阶段"""
        import concurrent.futures
        
        # 使用线程池执行并行中止请求
        with concurrent.futures.ThreadPoolExecutor(max_workers=len(self.participants)) as executor:
            # 提交所有中止请求
            future_to_participant = {
                executor.submit(participant.abort, self.transaction_id): participant
                for participant in self.participants
            }
            
            # 收集结果（忽略超时，只记录失败）
            for future in concurrent.futures.as_completed(future_to_participant):
                try:
                    future.result(timeout=30)
                except Exception as e:
                    # 记录失败日志
                    print(f"Abort failed: {str(e)}")
        
        self.state = CommitState.ABORTED
        return CommitResult.failure("Transaction aborted")
    
    def _compensate_phase(self, results):
        """执行补偿阶段"""
        # 补偿已成功提交的操作
        for i, participant in enumerate(self.participants):
            if results[i].is_success():
                try:
                    participant.compensate(self.transaction_id)
                except Exception as e:
                    # 记录补偿失败，需要人工干预
                    print(f"Compensation failed for participant {i}: {str(e)}")
    
    class CommitState(Enum):
        """提交状态"""
        INITIATED = "INITIATED"
        PREPARED = "PREPARED"
        COMMITTED = "COMMITTED"
        ABORTED = "ABORTED"
}

# 参与者接口
class Participant(ABC):
    @abstractmethod
    def prepare(self, transaction_id: str, action: TransactionAction) -> PrepareResult:
        """准备阶段"""
        pass
    
    @abstractmethod
    def commit(self, transaction_id: str) -> CommitResult:
        """提交阶段"""
        pass
    
    @abstractmethod
    def abort(self, transaction_id: str) -> CommitResult:
        """中止阶段"""
        pass
    
    @abstractmethod
    def compensate(self, transaction_id: str):
        """补偿操作"""
        pass

# 参与者实现
class DatabaseParticipant(Participant):
    private final DatabaseConnection connection;
    private final List<TransactionLog> transactionLogs = new ArrayList<>();
    
    @Override
    public PrepareResult prepare(String transactionId, TransactionAction action) {
        try {
            connection.beginTransaction();
            
            // 执行操作前的验证
            if (!action.canExecute(connection)) {
                return PrepareResult.notReady("Validation failed");
            }
            
            // 记录预写日志
            TransactionLog log = new TransactionLog(transactionId, action, TransactionLog.Status.PREPARED);
            transactionLogs.add(log);
            
            // 持有资源锁
            action.acquireLocks(connection);
            
            return PrepareResult.ready();
        } catch (Exception e) {
            return PrepareResult.notReady(e.getMessage());
        }
    }
    
    @Override
    public CommitResult commit(String transactionId) {
        try {
            // 查找对应的预写日志
            TransactionLog log = transactionLogs.stream()
                    .filter(t -> t.getTransactionId().equals(transactionId))
                    .findFirst()
                    .orElseThrow(() -> new IllegalStateException("No prepared transaction found"));
            
            // 提交事务
            action.execute(connection);
            connection.commit();
            
            // 更新日志状态
            log.setStatus(TransactionLog.Status.COMMITTED);
            
            // 释放锁
            action.releaseLocks(connection);
            
            return CommitResult.success("Committed");
        } catch (Exception e) {
            return CommitResult.failure(e.getMessage());
        }
    }
    
    @Override
    public CommitResult abort(String transactionId) {
        try {
            connection.rollback();
            
            // 更新日志状态
            transactionLogs.stream()
                    .filter(t -> t.getTransactionId().equals(transactionId))
                    .forEach(t -> t.setStatus(TransactionLog.Status.ABORTED));
            
            // 释放锁
            action.releaseLocks(connection);
            
            return CommitResult.success("Aborted");
        } catch (Exception e) {
            return CommitResult.failure(e.getMessage());
        }
    }
    
    @Override
    public void compensate(String transactionId) {
        try {
            // 执行补偿操作
            action.compensate(connection);
        } catch (Exception e) {
            throw new CompensationException("Compensation failed", e);
        }
    }
}
```

### 三阶段提交（3PC）

**3PC算法实现**：

```java
// 三阶段提交协议实现
public class ThreePhaseCommitCoordinator {
    private final List<Participant> participants;
    private final String transactionId;
    private CommitState state = CommitState.INITIATED;
    
    public ThreePhaseCommitCoordinator(List<Participant> participants, String transactionId) {
        this.participants = participants;
        this.transactionId = transactionId;
    }
    
    public CommitResult executeTransaction(TransactionAction action) {
        try {
            // 阶段1：Can-Commit阶段
            List<CanCommitResult> canCommitResults = canCommitPhase(action);
            
            if (canCommitResults.stream().allMatch(CanCommitResult::canProceed)) {
                // 阶段2：Pre-Commit阶段
                List<PreCommitResult> preCommitResults = preCommitPhase(action);
                
                if (preCommitResults.stream().allMatch(PreCommitResult::isPrepared)) {
                    // 阶段3：Do-Commit阶段
                    return doCommitPhase();
                } else {
                    // 中止事务
                    return abortPhase();
                }
            } else {
                return abortPhase();
            }
        } catch (Exception e) {
            // 处理超时或网络分区
            return handleFailure(e);
        }
    }
    
    private List<CanCommitResult> canCommitPhase(TransactionAction action) {
        return participants.parallelStream()
                .map(participant -> {
                    try {
                        return participant.canCommit(transactionId, action);
                    } catch (Exception e) {
                        return CanCommitResult.cannotProceed(e.getMessage());
                    }
                })
                .collect(Collectors.toList());
    }
    
    private List<PreCommitResult> preCommitPhase(TransactionAction action) {
        return participants.parallelStream()
                .map(participant -> {
                    try {
                        return participant.preCommit(transactionId, action);
                    } catch (Exception e) {
                        return PreCommitResult.preparationFailed(e.getMessage());
                    }
                })
                .collect(Collectors.toList());
    }
    
    private CommitResult doCommitPhase() {
        List<CompletableFuture<CommitResult>> futures = participants.stream()
                .map(participant -> CompletableFuture.supplyAsync(() -> {
                    try {
                        return participant.doCommit(transactionId);
                    } catch (Exception e) {
                        return CommitResult.failure(e.getMessage());
                    }
                }))
                .collect(Collectors.toList());
        
        state = CommitState.COMMITTED;
        return CommitResult.success("Transaction committed");
    }
    
    private CommitResult abortPhase() {
        participants.parallelStream()
                .forEach(participant -> {
                    try {
                        participant.doAbort(transactionId);
                    } catch (Exception e) {
                        System.err.println("Abort failed: " + e.getMessage());
                    }
                });
        
        state = CommitState.ABORTED;
        return CommitResult.failure("Transaction aborted");
    }
    
    private CommitResult handleFailure(Exception e) {
        // 网络分区或超时情况下的处理
        if (state == CommitState.PRE_COMMITTED) {
            // 如果已经Pre-Commit，尝试Do-Commit
            return doCommitPhase();
        } else {
            // 否则中止事务
            return abortPhase();
        }
    }
    
    public enum CommitState {
        INITIATED, CAN_COMMIT, PRE_COMMITTED, COMMITTED, ABORTED
    }
}
```

### Saga模式

**Saga事务实现**：

```java
// Saga模式实现
public class SagaOrchestrator {
    private final List<SagaStep> steps;
    private final String sagaId;
    private SagaState state = SagaState.INITIATED;
    private final List<SagaStep> completedSteps = new ArrayList<>();
    
    public SagaOrchestrator(List<SagaStep> steps, String sagaId) {
        this.steps = steps;
        this.sagaId = sagaId;
    }
    
    public SagaResult executeSaga() {
        try {
            // 按顺序执行步骤
            for (int i = 0; i < steps.size(); i++) {
                SagaStep step = steps.get(i);
                
                try {
                    // 执行正向操作
                    StepResult result = step.execute(sagaId, i);
                    
                    if (result.isSuccess()) {
                        completedSteps.add(step);
                    } else {
                        // 执行失败，开始补偿
                        return compensateAndFail(step, result);
                    }
                } catch (Exception e) {
                    return compensateAndFail(step, StepResult.failure(e.getMessage()));
                }
            }
            
            state = SagaState.COMPLETED;
            return SagaResult.success("Saga completed successfully");
            
        } catch (Exception e) {
            state = SagaState.FAILED;
            return SagaResult.failure("Saga failed: " + e.getMessage());
        }
    }
    
    private SagaResult compensateAndFail(SagaStep failedStep, StepResult failure) {
        // 从失败的步骤开始，逆向补偿
        List<SagaStep> stepsToCompensate = new ArrayList<>(completedSteps);
        Collections.reverse(stepsToCompensate);
        
        List<CompensationResult> compensationResults = new ArrayList<>();
        
        for (Step step : stepsToCompensate) {
            try {
                CompensationResult result = step.compensate(sagaId);
                compensationResults.add(result);
                
                if (!result.isSuccess()) {
                    // 补偿失败，需要人工干预
                    break;
                }
            } catch (Exception e) {
                compensationResults.add(CompensationResult.failure(e.getMessage()));
                break;
            }
        }
        
        state = SagaState.COMPENSATED;
        return SagaResult.failure("Saga compensated due to: " + failure.getError());
    }
    
    public enum SagaState {
        INITIATED, IN_PROGRESS, COMPLETED, FAILED, COMPENSATED
    }
}

// Saga步骤接口
public interface SagaStep {
    StepResult execute(String sagaId, int stepIndex);
    CompensationResult compensate(String sagaId);
}

// 具体Saga步骤示例
public class OrderProcessingSaga implements SagaStep {
    private final OrderService orderService;
    private final InventoryService inventoryService;
    private final PaymentService paymentService;
    private final NotificationService notificationService;
    
    @Override
    public StepResult execute(String sagaId, int stepIndex) {
        switch (stepIndex) {
            case 0:
                return createOrder(sagaId);
            case 1:
                return reserveInventory(sagaId);
            case 2:
                return processPayment(sagaId);
            case 3:
                return sendConfirmation(sagaId);
            default:
                throw new IllegalArgumentException("Invalid step index: " + stepIndex);
        }
    }
    
    private StepResult createOrder(String sagaId) {
        try {
            Order order = orderService.createOrder(sagaId);
            if (order != null) {
                return StepResult.success(order.getOrderId());
            } else {
                return StepResult.failure("Failed to create order");
            }
        } catch (Exception e) {
            return StepResult.failure("Order creation error: " + e.getMessage());
        }
    }
    
    private StepResult reserveInventory(String sagaId) {
        try {
            boolean reserved = inventoryService.reserveInventory(sagaId);
            if (reserved) {
                return StepResult.success("Inventory reserved");
            } else {
                return StepResult.failure("Inventory reservation failed");
            }
        } catch (Exception e) {
            return StepResult.failure("Inventory error: " + e.getMessage());
        }
    }
    
    private StepResult processPayment(String sagaId) {
        try {
            Payment payment = paymentService.processPayment(sagaId);
            if (payment.isSuccessful()) {
                return StepResult.success(payment.getTransactionId());
            } else {
                return StepResult.failure("Payment processing failed");
            }
        } catch (Exception e) {
            return StepResult.failure("Payment error: " + e.getMessage());
        }
    }
    
    private StepResult sendConfirmation(String sagaId) {
        try {
            notificationService.sendOrderConfirmation(sagaId);
            return StepResult.success("Confirmation sent");
        } catch (Exception e) {
            return StepResult.failure("Notification error: " + e.getMessage());
        }
    }
    
    @Override
    public CompensationResult compensate(String sagaId) {
        // 逆向补偿过程
        List<CompensationResult> results = new ArrayList<>();
        
        try {
            // 3. 取消订单确认
            results.add(cancelConfirmation(sagaId));
            
            // 2. 撤销支付
            results.add(reversePayment(sagaId));
            
            // 1. 释放库存
            results.add(releaseInventory(sagaId));
            
            // 0. 取消订单
            results.add(cancelOrder(sagaId));
            
            return results.stream().anyMatch(CompensationResult::isSuccess) 
                ? CompensationResult.success("Compensation completed")
                : CompensationResult.failure("Compensation failed");
                
        } catch (Exception e) {
            return CompensationResult.failure("Compensation error: " + e.getMessage());
        }
    }
    
    private CompensationResult cancelOrder(String sagaId) {
        try {
            orderService.cancelOrder(sagaId);
            return CompensationResult.success("Order cancelled");
        } catch (Exception e) {
            return CompensationResult.failure("Order cancellation failed: " + e.getMessage());
        }
    }
    
    private CompensationResult releaseInventory(String sagaId) {
        try {
            inventoryService.releaseInventory(sagaId);
            return CompensationResult.success("Inventory released");
        } catch (Exception e) {
            return CompensationResult.failure("Inventory release failed: " + e.getMessage());
        }
    }
    
    private CompensationResult reversePayment(String sagaId) {
        try {
            paymentService.reversePayment(sagaId);
            return CompensationResult.success("Payment reversed");
        } catch (Exception e) {
            return CompensationResult.failure("Payment reversal failed: " + e.getMessage());
        }
    }
    
    private CompensationResult cancelConfirmation(String sagaId) {
        try {
            notificationService.cancelConfirmation(sagaId);
            return CompensationResult.success("Confirmation cancelled");
        } catch (Exception e) {
            return CompensationResult.failure("Confirmation cancellation failed: " + e.getMessage());
        }
    }
}
```

## 分布式查询优化

### 查询路由

**查询路由策略**：

```java
// 查询路由器
public class QueryRouter {
    private final ShardManager shardManager;
    private final ReplicaManager replicaManager;
    private final QueryAnalyzer queryAnalyzer;
    
    public QueryRouter(ShardManager shardManager, ReplicaManager replicaManager, QueryAnalyzer queryAnalyzer) {
        this.shardManager = shardManager;
        this.replicaManager = replicaManager;
        this.queryAnalyzer = queryAnalyzer;
    }
    
    public QueryPlan routeQuery(String query) {
        QueryAnalysis analysis = queryAnalyzer.analyze(query);
        
        return QueryPlan.builder()
                .withQuery(query)
                .withAnalysis(analysis)
                .withTargetShards(determineTargetShards(analysis))
                .withTargetReplicas(selectReplicas(analysis))
                .withExecutionStrategy(determineExecutionStrategy(analysis))
                .build();
    }
    
    private List<ShardInfo> determineTargetShards(QueryAnalysis analysis) {
        if (analysis.isSingleShardQuery()) {
            // 单分片查询
            return Collections.singletonList(shardManager.getShardNode(analysis.getShardKey()));
        } else if (analysis.isFanOutQuery()) {
            // 需要查询所有分片
            return shardManager.getAllShardNodes();
        } else {
            // 部分分片查询
            return analysis.getTargetShards().stream()
                    .map(shardManager::getShardNode)
                    .collect(Collectors.toList());
        }
    }
    
    private List<ReplicaInfo> selectReplicas(QueryAnalysis analysis) {
        if (analysis.isReadOnlyQuery()) {
            // 只读查询可以选择副本
            return replicaManager.getReadableReplicas(analysis.getPreferredConsistency());
        } else {
            // 写查询必须路由到主节点
            return replicaManager.getPrimaryReplicas();
        }
    }
    
    private ExecutionStrategy determineExecutionStrategy(QueryAnalysis analysis) {
        if (analysis.requiresAggregation()) {
            return ExecutionStrategy.FAN_OUT_AGGREGATE;
        } else if (analysis.requiresSorting()) {
            return ExecutionStrategy.FAN_OUT_SORT;
        } else if (analysis.isSimpleQuery()) {
            return ExecutionStrategy.DIRECT_ROUTE;
        } else {
            return ExecutionStrategy.FAN_OUT;
        }
    }
}

// 查询分析器
public class QueryAnalyzer {
    
    public QueryAnalysis analyze(String query) {
        // 解析SQL或查询语言
        QueryParser parser = new QueryParser(query);
        ParsedQuery parsed = parser.parse();
        
        return QueryAnalysis.builder()
                .withQueryType(determineQueryType(parsed))
                .withShardKey(extractShardKey(parsed))
                .withTablesInvolved(extractTables(parsed))
                .withFilters(extractFilters(parsed))
                .withAggregations(extractAggregations(parsed))
                .withSorting(extractSorting(parsed))
                .withRequiresAggregation(determineAggregationNeed(parsed))
                .withReadOnly(isReadOnly(parsed))
                .build();
    }
    
    private QueryType determineQueryType(ParsedQuery parsed) {
        if (parsed.isSelect()) {
            if (parsed.hasJoin()) {
                return QueryType.JOIN_QUERY;
            } else if (parsed.hasAggregation()) {
                return QueryType.AGGREGATION_QUERY;
            } else {
                return QueryType.SIMPLE_SELECT;
            }
        } else if (parsed.isInsert() || parsed.isUpdate() || parsed.isDelete()) {
            return QueryType.WRITE_QUERY;
        }
        return QueryType.UNKNOWN;
    }
    
    private String extractShardKey(ParsedQuery parsed) {
        // 从WHERE子句或查询条件中提取分片键
        List<FilterCondition> filters = parsed.getWhereConditions();
        
        return filters.stream()
                .filter(condition -> condition.isShardKeyCondition())
                .map(FilterCondition::getValue)
                .findFirst()
                .orElse(null);
    }
    
    private boolean isReadOnly(ParsedQuery parsed) {
        return parsed.isSelect() && !parsed.hasForUpdate();
    }
    
    private boolean determineAggregationNeed(ParsedQuery parsed) {
        return parsed.hasGroupBy() || parsed.hasAggregateFunctions();
    }
}

// 查询执行器
public class DistributedQueryExecutor {
    private final QueryRouter queryRouter;
    private final ExecutorService executorService = Executors.newFixedThreadPool(32);
    
    public QueryResult executeQuery(String query) {
        QueryPlan plan = queryRouter.routeQuery(query);
        
        switch (plan.getExecutionStrategy()) {
            case DIRECT_ROUTE:
                return executeDirectRoute(plan);
            case FAN_OUT:
                return executeFanOut(plan);
            case FAN_OUT_AGGREGATE:
                return executeFanOutAggregate(plan);
            case FAN_OUT_SORT:
                return executeFanOutSort(plan);
            default:
                throw new UnsupportedOperationException("Unsupported execution strategy: " + plan.getExecutionStrategy());
        }
    }
    
    private QueryResult executeFanOutAggregate(QueryPlan plan) {
        List<CompletableFuture<PartialResult>> futures = plan.getTargetShards().stream()
                .map(shard -> CompletableFuture.supplyAsync(() -> {
                    try {
                        return executePartialQueryOnShard(plan.getQuery(), shard);
                    } catch (Exception e) {
                        return PartialResult.failure(e.getMessage());
                    }
                }, executorService))
                .collect(Collectors.toList());
        
        List<PartialResult> partialResults = futures.stream()
                .map(future -> {
                    try {
                        return future.get(30, TimeUnit.SECONDS);
                    } catch (Exception e) {
                        return PartialResult.failure("Query timeout: " + e.getMessage());
                    }
                })
                .collect(Collectors.toList());
        
        // 合并和聚合结果
        return mergePartialResults(partialResults, plan.getAnalysis());
    }
    
    private QueryResult executeFanOutSort(QueryPlan plan) {
        List<CompletableFuture<PartialResult>> futures = plan.getTargetShards().stream()
                .map(shard -> CompletableFuture.supplyAsync(() -> {
                    try {
                        PartialResult result = executePartialQueryOnShard(plan.getQuery(), shard);
                        // 在分片上排序部分结果
                        result.sort();
                        return result;
                    } catch (Exception e) {
                        return PartialResult.failure(e.getMessage());
                    }
                }, executorService))
                .collect(Collectors.toList());
        
        List<PartialResult> partialResults = futures.stream()
                .map(future -> {
                    try {
                        return future.get(30, TimeUnit.SECONDS);
                    } catch (Exception e) {
                        return PartialResult.failure("Query timeout: " + e.getMessage());
                    }
                })
                .collect(Collectors.toList());
        
        // 合并排序结果
        return mergeSortedResults(partialResults);
    }
    
    private PartialResult executePartialQueryOnShard(String query, ShardInfo shard) {
        try {
            // 在指定分片上执行查询
            return shard.getConnection().executeQuery(query);
        } catch (Exception e) {
            throw new QueryExecutionException("Failed to execute query on shard " + shard.getShardId(), e);
        }
    }
}
```

## 监控与运维

### 分布式监控

**监控指标收集**：

```java
// 分布式监控服务
@Component
public class DistributedMonitoringService {
    
    @Autowired
    private MetricRegistry metricRegistry;
    
    @Autowired
    private HealthIndicator healthIndicator;
    
    // 监控分布式数据库关键指标
    public void collectMetrics() {
        collectConsistencyMetrics();
        collectLatencyMetrics();
        collectThroughputMetrics();
        collectAvailabilityMetrics();
        collectPartitionMetrics();
    }
    
    private void collectConsistencyMetrics() {
        // 一致性延迟指标
        Timer consistencyTimer = metricRegistry.timer("db.consistency.delay");
        consistencyTimer.record(getConsistencyDelay(), TimeUnit.MILLISECONDS);
        
        // 副本同步状态
        Gauge<Integer> replicaSyncGauge = () -> getReplicaSyncStatus();
        metricRegistry.gauge("db.replica.sync.status", replicaSyncGauge);
        
        // 数据冲突数量
        Counter conflictsCounter = metricRegistry.counter("db.conflicts.total");
        conflictsCounter.inc(getConflictCount());
    }
    
    private void collectLatencyMetrics() {
        // 查询延迟分布
        Timer queryTimer = metricRegistry.timer("db.query.latency");
        
        // 分片查询延迟
        Timer shardQueryTimer = metricRegistry.timer("db.shard.query.latency");
        
        // 网络延迟
        Timer networkTimer = metricRegistry.timer("db.network.latency");
    }
    
    private void collectThroughputMetrics() {
        // 每秒查询数
        Meter queriesPerSecond = metricRegistry.meter("db.queries.per.second");
        
        // 每秒写入数
        Meter writesPerSecond = metricRegistry.meter("db.writes.per.second");
        
        // 数据传输量
        Meter dataTransferRate = metricRegistry.meter("db.data.transfer.rate");
    }
    
    private void collectAvailabilityMetrics() {
        // 节点可用性
        Gauge<Double> availabilityGauge = () -> calculateAvailability();
        metricRegistry.gauge("db.availability", availabilityGauge);
        
        // 故障转移时间
        Timer failoverTimer = metricRegistry.timer("db.failover.time");
        
        // 服务健康状态
        healthIndicator.checkHealth();
    }
    
    private void collectPartitionMetrics() {
        // 分片分布情况
        Map<Integer, Integer> shardSizes = getShardSizes();
        shardSizes.forEach((shardId, size) -> {
            Gauge<Integer> shardSizeGauge = () -> size;
            metricRegistry.gauge("db.shard." + shardId + ".size", shardSizeGauge);
        });
        
        // 数据倾斜程度
        Gauge<Double> dataSkewGauge = () -> calculateDataSkew();
        metricRegistry.gauge("db.data.skew", dataSkewGauge);
    }
    
    public HealthStatus checkSystemHealth() {
        HealthStatus.Builder status = HealthStatus.builder();
        
        // 检查节点健康状态
        List<NodeHealth> nodeHealths = checkAllNodes();
        long healthyNodes = nodeHealths.stream().filter(NodeHealth::isHealthy).count();
        
        if (healthyNodes == nodeHealths.size()) {
            status.up();
        } else if (healthyNodes > nodeHealths.size() / 2) {
            status.degraded();
        } else {
            status.down();
        }
        
        // 添加详细健康信息
        status.withDetail("total_nodes", nodeHealths.size());
        status.withDetail("healthy_nodes", healthyNodes);
        status.withDetail("unhealthy_nodes", nodeHealths.size() - healthyNodes);
        
        // 检查一致性状态
        boolean isConsistent = checkDataConsistency();
        status.withDetail("data_consistent", isConsistent);
        
        // 检查性能状态
        PerformanceStatus perfStatus = checkPerformanceStatus();
        status.withDetail("performance_status", perfStatus.name());
        
        return status.build();
    }
    
    private List<NodeHealth> checkAllNodes() {
        List<NodeInfo> allNodes = getAllNodes();
        
        return allNodes.parallelStream()
                .map(this::checkNodeHealth)
                .collect(Collectors.toList());
    }
    
    private NodeHealth checkNodeHealth(NodeInfo node) {
        try {
            // 检查节点响应时间
            long responseTime = measureNodeResponseTime(node);
            
            // 检查节点连接状态
            boolean isConnected = testNodeConnection(node);
            
            // 检查节点资源使用情况
            ResourceUsage resourceUsage = getNodeResourceUsage(node);
            
            // 检查节点同步状态
            SyncStatus syncStatus = getNodeSyncStatus(node);
            
            return NodeHealth.builder()
                    .withNodeId(node.getNodeId())
                    .withHealthy(isConnected && responseTime < 5000 && syncStatus.isInSync())
                    .withResponseTime(responseTime)
                    .withResourceUsage(resourceUsage)
                    .withSyncStatus(syncStatus)
                    .build();
                    
        } catch (Exception e) {
            return NodeHealth.unhealthy(node.getNodeId(), e.getMessage());
        }
    }
    
    private PerformanceStatus checkPerformanceStatus() {
        // 检查查询延迟
        double avgQueryLatency = getAverageQueryLatency();
        
        // 检查吞吐量
        double throughput = getCurrentThroughput();
        
        // 检查错误率
        double errorRate = getErrorRate();
        
        if (avgQueryLatency < 100 && throughput > 1000 && errorRate < 0.01) {
            return PerformanceStatus.HEALTHY;
        } else if (avgQueryLatency < 500 && throughput > 500 && errorRate < 0.05) {
            return PerformanceStatus.DEGRADED;
        } else {
            return PerformanceStatus.UNHEALTHY;
        }
    }
}
```

### 故障检测与恢复

**故障检测机制**：

```java
// 故障检测器
public class FailureDetector {
    private final List<NodeInfo> nodes;
    private final ScheduledExecutorService scheduler = Executors.newScheduledThreadPool(4);
    private final Map<String, FailureStats> failureStats = new ConcurrentHashMap<>();
    
    public void startDetection() {
        // 定期发送心跳包
        scheduler.scheduleAtFixedRate(this::sendHeartbeats, 0, 1, TimeUnit.SECONDS);
        
        // 定期检查节点状态
        scheduler.scheduleAtFixedRate(this::checkNodeStatus, 0, 5, TimeUnit.SECONDS);
        
        // 定期清理过期的故障记录
        scheduler.scheduleAtFixedRate(this::cleanupFailureStats, 0, 60, TimeUnit.SECONDS);
    }
    
    private void sendHeartbeats() {
        nodes.parallelStream().forEach(node -> {
            try {
                long startTime = System.currentTimeMillis();
                HeartbeatResponse response = sendHeartbeat(node);
                long latency = System.currentTimeMillis() - startTime;
                
                updateNodeHealth(node, true, latency);
                
            } catch (Exception e) {
                updateNodeHealth(node, false, -1);
                recordFailure(node);
            }
        });
    }
    
    private void updateNodeHealth(NodeInfo node, boolean isAlive, long latency) {
        FailureStats stats = failureStats.computeIfAbsent(node.getNodeId(), k -> new FailureStats());
        
        if (isAlive) {
            stats.recordSuccess(latency);
        } else {
            stats.recordFailure();
        }
    }
    
    private void checkNodeStatus() {
        nodes.forEach(node -> {
            FailureStats stats = failureStats.get(node.getNodeId());
            if (stats != null) {
                FailureStatus status = determineNodeStatus(stats);
                if (status != FailureStatus.HEALTHY) {
                    handleNodeFailure(node, status);
                }
            }
        });
    }
    
    private FailureStatus determineNodeStatus(FailureStats stats) {
        if (stats.getConsecutiveFailures() >= 3) {
            return FailureStatus.SUSPECTED_DOWN;
        }
        
        if (stats.getFailureRate() > 0.5) {
            return FailureStatus.UNSTABLE;
        }
        
        if (stats.getAverageLatency() > 5000) {
            return FailureStatus.SLOW;
        }
        
        return FailureStatus.HEALTHY;
    }
    
    private void handleNodeFailure(NodeInfo node, FailureStatus status) {
        switch (status) {
            case SUSPECTED_DOWN:
                markNodeAsDown(node);
                triggerFailover(node);
                break;
            case UNSTABLE:
                logUnstableNode(node, status);
                break;
            case SLOW:
                markNodeAsDegraded(node);
                break;
            default:
                break;
        }
    }
    
    private void triggerFailover(NodeInfo failedNode) {
        // 启动故障转移流程
        FailoverCoordinator coordinator = new FailoverCoordinator();
        FailoverPlan plan = coordinator.createFailoverPlan(failedNode);
        
        coordinator.executeFailover(plan);
    }
}
```

## 总结

分布式数据库是现代企业级系统的核心基础设施，涉及多个复杂的技术领域：

### 核心原理总结

1. **CAP定理**：理解一致性、可用性、分区容错性的权衡
2. **分片策略**：基于哈希、范围或目录的数据分片方法
3. **复制机制**：同步、异步、半同步复制的选择
4. **一致性算法**：Paxos、Raft等分布式一致性协议
5. **事务管理**：2PC、3PC、Saga等分布式事务处理

### 设计要点

1. **数据分布**：合理设计分片键，避免数据倾斜
2. **副本策略**：平衡一致性和可用性
3. **查询优化**：高效的查询路由和执行策略
4. **故障处理**：完善的故障检测和恢复机制
5. **监控运维**：全面的监控指标和健康检查

### 技术选型考虑

1. **业务需求**：强一致性 vs 高可用性的选择
2. **数据规模**：分片策略和副本数量的确定
3. **访问模式**：读写比例和查询类型的影响
4. **成本控制**：硬件成本和运营成本的平衡
5. **团队能力**：技术栈和学习成本

构建分布式数据库系统需要在理论理解的基础上，结合具体业务场景做出合理的设计和实现决策。