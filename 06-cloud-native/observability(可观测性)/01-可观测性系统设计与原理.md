# 可观测性系统设计与原理

## 概述

可观测性（Observability）是现代云原生系统的核心能力，它通过收集、分析和可视化系统运行时的数据，帮助运维团队和开发团队理解系统的内部状态，快速定位问题，优化性能，并做出明智的决策。可观测性不仅仅是被动地监控，而是主动地探索和理解复杂系统的行为模式。

## 可观测性三大支柱

### 1. 指标（Metrics）- 量化系统健康度

**指标收集与存储**：

```java
// 指标收集器
public class MetricsCollector {
    private final MeterRegistry meterRegistry;
    private final MetricsPublisher metricsPublisher;
    private final AggregationWindow aggregationWindow;
    
    public MetricsCollector(MeterRegistry registry) {
        this.meterRegistry = registry;
        this.metricsPublisher = new PrometheusMetricsPublisher(registry);
        this.aggregationWindow = new TimeWindow(Duration.ofMinutes(5));
    }
    
    // 收集业务指标
    public void recordBusinessMetric(String metricName, double value, Tags tags) {
        Counter counter = Counter.builder(metricName)
            .description("Business metric counter")
            .tags(tags)
            .register(meterRegistry);
        
        counter.increment(value);
        
        // 实时发布
        publishMetric(metricName, value, tags);
    }
    
    // 收集性能指标
    public void recordPerformanceMetric(String operationName, long durationMs, Status status) {
        Timer.Sample sample = Timer.start(meterRegistry);
        
        // 记录操作持续时间
        Timer timer = Timer.builder("operation.duration")
            .description("Operation execution time")
            .tags(Tags.of(
                "operation", operationName,
                "status", status.name().toLowerCase()
            ))
            .register(meterRegistry);
        
        sample.stop(timer);
        
        // 记录延迟分布
        recordLatencyHistogram(operationName, durationMs);
        
        // 记录错误率
        if (status == Status.ERROR) {
            counter("operation.errors", operationName).increment();
        }
    }
    
    // 记录延迟分布直方图
    private void recordLatencyHistogram(String operationName, long durationMs) {
        DistributionSummary summary = DistributionSummary.builder("operation.latency.p95")
            .description("Operation latency 95th percentile")
            .tags(Tags.of("operation", operationName))
            .register(meterRegistry);
        
        summary.record(durationMs);
    }
    
    // 收集资源指标
    public void recordResourceMetrics() {
        // CPU使用率
        double cpuUsage = getCpuUsage();
        Gauge.builder("system.cpu.usage")
            .description("CPU usage percentage")
            .register(meterRegistry, this, MetricsCollector::getCpuUsage);
        
        // 内存使用量
        MemoryUsage memoryUsage = getMemoryUsage();
        Gauge.builder("system.memory.used")
            .description("Memory usage in bytes")
            .register(meterRegistry, memoryUsage, MemoryUsage::getUsed);
        
        // 磁盘I/O
        DiskIOStats diskIO = getDiskIOStats();
        Gauge.builder("system.disk.io.read")
            .description("Disk read operations per second")
            .register(meterRegistry, diskIO, DiskIOStats::getReadOps);
        
        Gauge.builder("system.disk.io.write")
            .description("Disk write operations per second")
            .register(meterRegistry, diskIO, DiskIOStats::getWriteOps);
    }
    
    private void publishMetric(String name, double value, Tags tags) {
        Metric metric = new Metric(name, value, tags, System.currentTimeMillis());
        metricsPublisher.publish(metric);
    }
    
    public double getCpuUsage() {
        try {
            OperatingSystemMXBean os = ManagementFactory.getOperatingSystemMXBean();
            return os.getProcessCpuLoad() * 100; // 转换为百分比
        } catch (Exception e) {
            return 0.0;
        }
    }
}

// 指标聚合器
public class MetricsAggregator {
    private final TimeWindowAggregation aggregationWindow;
    private final Map<String, AggregatedMetric> aggregatedMetrics;
    private final ScheduledExecutorService scheduler;
    
    public MetricsAggregator() {
        this.aggregationWindow = new TimeWindowAggregation(Duration.ofMinutes(1));
        this.aggregatedMetrics = new ConcurrentHashMap<>();
        this.scheduler = Executors.newScheduledThreadPool(2);
        
        // 定期聚合指标
        scheduler.scheduleAtFixedRate(this::aggregateMetrics, 30, 30, TimeUnit.SECONDS);
    }
    
    private void aggregateMetrics() {
        Instant windowStart = Instant.now().minus(aggregationWindow.getWindowSize());
        List<RawMetric> rawMetrics = queryRawMetrics(windowStart);
        
        // 按指标名称分组
        Map<String, List<RawMetric>> groupedMetrics = rawMetrics.stream()
            .collect(Collectors.groupingBy(RawMetric::getName));
        
        // 计算聚合值
        for (Map.Entry<String, List<RawMetric>> entry : groupedMetrics.entrySet()) {
            String metricName = entry.getKey();
            List<RawMetric> metrics = entry.getValue();
            
            AggregatedMetric aggregated = calculateAggregations(metrics);
            aggregatedMetrics.put(metricName, aggregated);
            
            // 触发告警检查
            checkAlerts(metricName, aggregated);
        }
    }
    
    private AggregatedMetric calculateAggregations(List<RawMetric> metrics) {
        if (metrics.isEmpty()) {
            return new AggregatedMetric();
        }
        
        List<Double> values = metrics.stream()
            .map(RawMetric::getValue)
            .collect(Collectors.toList());
        
        AggregatedMetric aggregated = new AggregatedMetric();
        aggregated.setCount(metrics.size());
        aggregated.setMin(Collections.min(values));
        aggregated.setMax(Collections.max(values));
        aggregated.setMean(values.stream().mapToDouble(Double::doubleValue).average().orElse(0.0));
        aggregated.setSum(values.stream().mapToDouble(Double::doubleValue).sum());
        
        // 计算分位数
        Collections.sort(values);
        aggregated.setP50(calculatePercentile(values, 50));
        aggregated.setP95(calculatePercentile(values, 95));
        aggregated.setP99(calculatePercentile(values, 99));
        
        return aggregated;
    }
    
    private double calculatePercentile(List<Double> sortedValues, double percentile) {
        int index = (int) Math.ceil((percentile / 100.0) * sortedValues.size()) - 1;
        return sortedValues.get(Math.max(0, Math.min(index, sortedValues.size() - 1)));
    }
    
    public AggregatedMetric getAggregatedMetric(String metricName) {
        return aggregatedMetrics.get(metricName);
    }
}
```

### 2. 日志（Logs）- 记录事件细节

**结构化日志系统**：

```java
// 结构化日志记录器
public class StructuredLogger {
    private final Logger logger;
    private final LogFormatter logFormatter;
    private final LogEnricher logEnricher;
    
    public StructuredLogger(String serviceName) {
        this.logger = LoggerFactory.getLogger(serviceName);
        this.logFormatter = new JsonLogFormatter();
        this.logEnricher = new LogEnricher();
    }
    
    // 记录业务事件
    public void logBusinessEvent(String eventType, Map<String, Object> eventData) {
        LogEntry logEntry = new LogEntry();
        logEntry.setTimestamp(Instant.now());
        logEntry.setLevel("INFO");
        logEntry.setEventType(eventType);
        logEntry.setServiceName(getCurrentServiceName());
        logEntry.setTraceId(getCurrentTraceId());
        logEntry.setSpanId(getCurrentSpanId());
        
        // 丰富日志上下文
        LogContext context = logEnricher.getCurrentContext();
        logEntry.setUserId(context.getUserId());
        logEntry.setRequestId(context.getRequestId());
        logEntry.setSessionId(context.getSessionId());
        logEntry.setCorrelationId(context.getCorrelationId());
        
        // 添加事件数据
        Map<String, Object> enrichedData = new HashMap<>(eventData);
        enrichedData.putAll(context.getAdditionalData());
        logEntry.setData(enrichedData);
        
        String formattedLog = logFormatter.format(logEntry);
        logger.info(formattedLog);
    }
    
    // 记录错误事件
    public void logError(String errorCode, String errorMessage, Throwable throwable, 
                        Map<String, Object> context) {
        LogEntry logEntry = new LogEntry();
        logEntry.setTimestamp(Instant.now());
        logEntry.setLevel("ERROR");
        logEntry.setEventType("ERROR");
        logEntry.setServiceName(getCurrentServiceName());
        logEntry.setTraceId(getCurrentTraceId());
        logEntry.setSpanId(getCurrentSpanId());
        
        // 错误详情
        Map<String, Object> errorData = new HashMap<>();
        errorData.put("errorCode", errorCode);
        errorData.put("errorMessage", errorMessage);
        errorData.put("errorClass", throwable.getClass().getName());
        errorData.put("stackTrace", getStackTraceString(throwable));
        errorData.putAll(context != null ? context : Collections.emptyMap());
        
        logEntry.setData(errorData);
        
        String formattedLog = logFormatter.format(logEntry);
        logger.error(formattedLog, throwable);
    }
    
    // 记录性能指标
    public void logPerformanceMetric(String operation, long durationMs, 
                                   Map<String, Object> metadata) {
        LogEntry logEntry = new LogEntry();
        logEntry.setTimestamp(Instant.now());
        logEntry.setLevel("INFO");
        logEntry.setEventType("PERFORMANCE");
        logEntry.setServiceName(getCurrentServiceName());
        logEntry.setTraceId(getCurrentTraceId());
        
        // 性能数据
        Map<String, Object> performanceData = new HashMap<>();
        performanceData.put("operation", operation);
        performanceData.put("duration_ms", durationMs);
        performanceData.put("duration_s", durationMs / 1000.0);
        performanceData.putAll(metadata != null ? metadata : Collections.emptyMap());
        
        logEntry.setData(performanceData);
        
        String formattedLog = logFormatter.format(logEntry);
        logger.info(formattedLog);
    }
    
    private String getStackTraceString(Throwable throwable) {
        StringWriter sw = new StringWriter();
        PrintWriter pw = new PrintWriter(sw);
        throwable.printStackTrace(pw);
        return sw.toString();
    }
}

// 日志聚合器
public class LogAggregator {
    private final BlockingQueue<LogEntry> logQueue;
    private final LogProcessor logProcessor;
    private final ScheduledExecutorService batchProcessor;
    
    public LogAggregator() {
        this.logQueue = new LinkedBlockingQueue<>(10000);
        this.logProcessor = new LogProcessor();
        this.batchProcessor = Executors.newScheduledThreadPool(1);
        
        // 批量处理日志
        batchProcessor.scheduleAtFixedRate(this::processBatch, 1, 1, TimeUnit.SECONDS);
    }
    
    public void ingestLog(LogEntry logEntry) {
        try {
            logQueue.offer(logEntry, 1, TimeUnit.SECONDS);
        } catch (InterruptedException e) {
            Thread.currentThread().interrupt();
        }
    }
    
    private void processBatch() {
        List<LogEntry> batch = new ArrayList<>();
        logQueue.drainTo(batch, 1000);
        
        if (!batch.isEmpty()) {
            try {
                // 1. 解析和分类日志
                List<ProcessedLog> processedLogs = logProcessor.processBatch(batch);
                
                // 2. 提取关键信息
                Map<String, Object> extractedData = extractKeyInformation(processedLogs);
                
                // 3. 更新实时指标
                updateRealTimeMetrics(extractedData);
                
                // 4. 检查告警条件
                checkLogAlerts(processedLogs);
                
                // 5. 存储到索引系统
                indexLogs(processedLogs);
                
            } catch (Exception e) {
                logger.error("Failed to process log batch", e);
            }
        }
    }
    
    private Map<String, Object> extractKeyInformation(List<ProcessedLog> logs) {
        Map<String, Object> summary = new HashMap<>();
        
        // 错误统计
        long errorCount = logs.stream()
            .filter(log -> "ERROR".equals(log.getLevel()))
            .count();
        summary.put("errorCount", errorCount);
        
        // 事件类型统计
        Map<String, Long> eventTypeCounts = logs.stream()
            .collect(Collectors.groupingBy(
                ProcessedLog::getEventType,
                Collectors.counting()
            ));
        summary.put("eventTypeCounts", eventTypeCounts);
        
        // 服务统计
        Map<String, Long> serviceCounts = logs.stream()
            .collect(Collectors.groupingBy(
                ProcessedLog::getServiceName,
                Collectors.counting()
            ));
        summary.put("serviceCounts", serviceCounts);
        
        // 延迟统计
        List<Long> latencies = logs.stream()
            .filter(log -> log.getData().containsKey("duration_ms"))
            .map(log -> (Long) log.getData().get("duration_ms"))
            .collect(Collectors.toList());
        
        if (!latencies.isEmpty()) {
            summary.put("avgLatency", latencies.stream().mapToLong(Long::longValue).average().orElse(0.0));
            summary.put("p95Latency", calculatePercentile(latencies, 95));
        }
        
        return summary;
    }
}

// 日志查询引擎
public class LogQueryEngine {
    private final ElasticsearchClient elasticsearchClient;
    private final LogIndexManager indexManager;
    private final QueryOptimizer queryOptimizer;
    
    public List<LogResult> searchLogs(LogQuery query) {
        try {
            // 1. 优化查询
            OptimizedQuery optimizedQuery = queryOptimizer.optimize(query);
            
            // 2. 构建ES查询
            SearchRequest searchRequest = SearchRequest.of(s -> s
                .index(getLogIndices(query.getTimeRange()))
                .query(buildElasticsearchQuery(optimizedQuery))
                .sort(buildSortClause(query.getSortBy(), query.getSortOrder()))
                .size(query.getLimit())
            );
            
            // 3. 执行搜索
            SearchResponse<LogDocument> response = elasticsearchClient.search(searchRequest, LogDocument.class);
            
            // 4. 处理结果
            return processSearchResults(response);
            
        } catch (Exception e) {
            throw new LogSearchException("Failed to search logs", e);
        }
    }
    
    private Query buildElasticsearchQuery(OptimizedQuery query) {
        BoolQuery.Builder boolQuery = new BoolQuery.Builder();
        
        // 时间范围查询
        if (query.getStartTime() != null && query.getEndTime() != null) {
            boolQuery.must(m -> m
                .range(r -> r
                    .field("timestamp")
                    .gte(JsonData.of(query.getStartTime()))
                    .lte(JsonData.of(query.getEndTime()))
                )
            );
        }
        
        // 服务名称过滤
        if (!query.getServiceNames().isEmpty()) {
            boolQuery.must(m -> m
                .terms(t -> t
                    .field("serviceName")
                    .terms(TermsQueryField.of(t -> t
                        .value(query.getServiceNames().stream()
                            .map(JsonData::of)
                            .collect(Collectors.toList())
                    ))
                )
            );
        }
        
        // 错误级别过滤
        if (query.getLevels().contains("ERROR")) {
            boolQuery.must(m -> m
                .term(t -> t.field("level").value("ERROR"))
            );
        }
        
        // 事件类型过滤
        if (!query.getEventTypes().isEmpty()) {
            boolQuery.must(m -> m
                .terms(t -> t
                    .field("eventType")
                    .terms(TermsQueryField.of(t -> t
                        .value(query.getEventTypes().stream()
                            .map(JsonData::of)
                            .collect(Collectors.toList())
                    ))
                )
            );
        }
        
        // 文本搜索
        if (query.getSearchText() != null && !query.getSearchText().trim().isEmpty()) {
            boolQuery.must(m -> m
                .multiMatch(mm -> mm
                    .fields("message", "data.*")
                    .query(query.getSearchText())
                    .fuzziness(Fuzziness.AUTO)
                )
            );
        }
        
        // 字段过滤
        for (Map.Entry<String, Object> filter : query.getFieldFilters().entrySet()) {
            boolQuery.must(m -> m
                .term(t -> t
                    .field("data." + filter.getKey())
                    .value(JsonData.of(filter.getValue()))
                )
            );
        }
        
        return Query.of(q -> q.bool(boolQuery.build()));
    }
    
    private List<String> getLogIndices(TimeRange timeRange) {
        return indexManager.getIndicesForTimeRange(timeRange);
    }
}
```

### 3. 链路追踪（Traces）- 请求路径可视化

**分布式追踪系统**：

```java
// 分布式追踪器
public class DistributedTracer {
    private final SpanProcessor spanProcessor;
    private final TraceSampler traceSampler;
    private final ContextPropagator contextPropagator;
    private final TraceIdGenerator traceIdGenerator;
    
    public DistributedTracer() {
        this.spanProcessor = new BatchSpanProcessor();
        this.traceSampler = new ProbabilisticSampler(0.1); // 10%采样率
        this.contextPropagator = new HttpContextPropagator();
        this.traceIdGenerator = new UUIDTraceIdGenerator();
    }
    
    // 开始新的追踪
    public Span startTrace(String operationName, Map<String, String> tags) {
        String traceId = traceIdGenerator.generateTraceId();
        String spanId = traceIdGenerator.generateSpanId();
        
        SpanContext spanContext = new SpanContext(traceId, spanId, TraceFlags.builder().build());
        
        Span span = new Span(spanContext, operationName, SpanKind.SERVER);
        
        // 添加标签
        for (Map.Entry<String, String> tag : tags.entrySet()) {
            span.addTag(tag.getKey(), tag.getValue());
        }
        
        // 设置开始时间
        span.setStartTime(Instant.now());
        
        return span;
    }
    
    // 开始子追踪
    public Span startChildSpan(String operationName, Span parentSpan) {
        if (!shouldSample(parentSpan)) {
            return NoopSpan.INSTANCE;
        }
        
        String spanId = traceIdGenerator.generateSpanId();
        
        SpanContext parentContext = parentSpan.getContext();
        SpanContext childContext = new SpanContext(
            parentContext.getTraceId(), 
            spanId, 
            TraceFlags.builder().setFlags(TraceFlags.SAMPLED).build()
        );
        
        Span childSpan = new Span(childContext, operationName, SpanKind.CLIENT);
        
        // 继承父追踪的标签
        childSpan.addTags(parentSpan.getTags());
        
        // 设置父子关系
        childSpan.setParentSpanId(parentContext.getSpanId());
        
        return childSpan;
    }
    
    // 记录追踪事件
    public void recordEvent(Span span, String eventName, Map<String, Object> attributes) {
        if (span == NoopSpan.INSTANCE) {
            return;
        }
        
        Event event = new Event();
        event.setTimestamp(Instant.now());
        event.setName(eventName);
        event.setAttributes(attributes);
        
        span.addEvent(event);
    }
    
    // 记录错误
    public void recordError(Span span, Throwable throwable, Map<String, Object> context) {
        if (span == NoopSpan.INSTANCE) {
            return;
        }
        
        span.addTag("error", true);
        span.addTag("error.message", throwable.getMessage());
        span.addTag("error.class", throwable.getClass().getName());
        span.addTag("error.stack", getStackTraceString(throwable));
        
        for (Map.Entry<String, Object> entry : context.entrySet()) {
            span.addTag("error.context." + entry.getKey(), entry.getValue());
        }
        
        span.setStatus(StatusCode.ERROR);
    }
    
    // 完成追踪
    public void endTrace(Span span) {
        if (span == NoopSpan.INSTANCE) {
            return;
        }
        
        span.setEndTime(Instant.now());
        
        // 发送给追踪后端
        spanProcessor.processSpan(span);
    }
    
    private boolean shouldSample(Span span) {
        return traceSampler.shouldSample(span.getContext());
    }
    
    private String getStackTraceString(Throwable throwable) {
        StringWriter sw = new StringWriter();
        PrintWriter pw = new PrintWriter(sw);
        throwable.printStackTrace(pw);
        return sw.toString();
    }
}

// 追踪数据收集器
public class TraceCollector {
    private final TracingStorage tracingStorage;
    private final TraceAggregator traceAggregator;
    private final AnomalyDetector anomalyDetector;
    
    public void collectTrace(Trace trace) {
        try {
            // 1. 验证追踪数据
            validateTrace(trace);
            
            // 2. 存储追踪数据
            tracingStorage.storeTrace(trace);
            
            // 3. 聚合统计
            TraceStatistics stats = traceAggregator.aggregateTrace(trace);
            updateTraceMetrics(stats);
            
            // 4. 检测异常
            List<Anomaly> anomalies = anomalyDetector.detectAnomalies(trace);
            if (!anomalies.isEmpty()) {
                handleAnomalies(anomalies);
            }
            
            // 5. 性能分析
            PerformanceAnalysis analysis = analyzePerformance(trace);
            if (analysis.hasPerformanceIssues()) {
                handlePerformanceIssues(analysis);
            }
            
        } catch (Exception e) {
            logger.error("Failed to collect trace", e);
        }
    }
    
    private void validateTrace(Trace trace) {
        if (trace == null) {
            throw new IllegalArgumentException("Trace cannot be null");
        }
        
        if (trace.getSpans().isEmpty()) {
            throw new IllegalArgumentException("Trace must contain at least one span");
        }
        
        // 验证追踪ID
        if (trace.getTraceId() == null || trace.getTraceId().trim().isEmpty()) {
            throw new IllegalArgumentException("Trace ID is required");
        }
        
        // 验证跨度ID
        for (Span span : trace.getSpans()) {
            if (span.getSpanId() == null || span.getSpanId().trim().isEmpty()) {
                throw new IllegalArgumentException("Span ID is required");
            }
            
            if (span.getOperationName() == null || span.getOperationName().trim().isEmpty()) {
                throw new IllegalArgumentException("Span operation name is required");
            }
            
            if (span.getStartTime() == null) {
                throw new IllegalArgumentException("Span start time is required");
            }
        }
    }
    
    private PerformanceAnalysis analyzePerformance(Trace trace) {
        PerformanceAnalysis analysis = new PerformanceAnalysis(trace);
        
        // 分析总延迟
        long totalDuration = trace.getTotalDuration().toMillis();
        if (totalDuration > 5000) { // 5秒
            analysis.addIssue(new PerformanceIssue("HIGH_LATENCY", 
                "Total trace duration " + totalDuration + "ms exceeds threshold"));
        }
        
        // 分析单个跨度延迟
        for (Span span : trace.getSpans()) {
            long spanDuration = Duration.between(span.getStartTime(), span.getEndTime()).toMillis();
            
            if (spanDuration > 1000) { // 1秒
                analysis.addIssue(new PerformanceIssue("SPAN_HIGH_LATENCY",
                    "Span " + span.getOperationName() + " took " + spanDuration + "ms"));
            }
            
            // 分析长尾延迟
            if (spanDuration > 2000) {
                analysis.addLongTailLatency(span.getOperationName(), spanDuration);
            }
        }
        
        // 分析服务间延迟
        Map<String, List<Long>> serviceLatencies = calculateServiceLatencies(trace);
        for (Map.Entry<String, List<Long>> entry : serviceLatencies.entrySet()) {
            String service = entry.getKey();
            List<Long> latencies = entry.getValue();
            
            double avgLatency = latencies.stream().mapToLong(Long::longValue).average().orElse(0.0);
            if (avgLatency > 500) { // 500ms
                analysis.addIssue(new PerformanceIssue("SERVICE_HIGH_LATENCY",
                    "Service " + service + " average latency " + avgLatency + "ms"));
            }
        }
        
        return analysis;
    }
    
    private Map<String, List<Long>> calculateServiceLatencies(Trace trace) {
        Map<String, List<Long>> serviceLatencies = new HashMap<>();
        
        for (Span span : trace.getSpans()) {
            String serviceName = span.getTags().get("service.name");
            if (serviceName != null) {
                long duration = Duration.between(span.getStartTime(), span.getEndTime()).toMillis();
                
                serviceLatencies.computeIfAbsent(serviceName, k -> new ArrayList<>())
                    .add(duration);
            }
        }
        
        return serviceLatencies;
    }
}

// 链路追踪可视化
public class TraceVisualizer {
    private final TraceDataExtractor traceDataExtractor;
    private final TimelineBuilder timelineBuilder;
    private final DependencyGraphBuilder dependencyGraphBuilder;
    
    public TraceVisualization createVisualization(String traceId) {
        try {
            // 1. 获取追踪数据
            Trace trace = traceDataExtractor.getTrace(traceId);
            
            if (trace == null) {
                throw new IllegalArgumentException("Trace not found: " + traceId);
            }
            
            // 2. 构建时间线
            Timeline timeline = timelineBuilder.buildTimeline(trace);
            
            // 3. 构建依赖图
            DependencyGraph dependencyGraph = dependencyGraphBuilder.buildDependencyGraph(trace);
            
            // 4. 计算性能指标
            PerformanceMetrics metrics = calculatePerformanceMetrics(trace);
            
            // 5. 生成可视化数据
            TraceVisualization visualization = new TraceVisualization();
            visualization.setTraceId(traceId);
            visualization.setTimeline(timeline);
            visualization.setDependencyGraph(dependencyGraph);
            visualization.setPerformanceMetrics(metrics);
            
            // 6. 添加交互式元素
            addInteractiveElements(visualization, trace);
            
            return visualization;
            
        } catch (Exception e) {
            throw new VisualizationException("Failed to create trace visualization", e);
        }
    }
    
    private Timeline buildTimeline(Trace trace) {
        Timeline timeline = new Timeline();
        
        // 按时间排序跨度
        List<Span> sortedSpans = trace.getSpans().stream()
            .sorted(Comparator.comparing(Span::getStartTime))
            .collect(Collectors.toList());
        
        // 创建时间线事件
        for (Span span : sortedSpans) {
            TimelineEvent event = new TimelineEvent();
            event.setSpanId(span.getSpanId());
            event.setOperationName(span.getOperationName());
            event.setStartTime(span.getStartTime());
            event.setEndTime(span.getEndTime());
            event.setServiceName(span.getTags().get("service.name"));
            event.setStatus(span.getStatus());
            event.setTags(span.getTags());
            event.setEvents(span.getEvents());
            
            timeline.addEvent(event);
        }
        
        return timeline;
    }
    
    private DependencyGraph buildDependencyGraph(Trace trace) {
        DependencyGraph graph = new DependencyGraph();
        
        // 添加节点
        Set<String> services = trace.getSpans().stream()
            .map(span -> span.getTags().get("service.name"))
            .filter(Objects::nonNull)
            .collect(Collectors.toSet());
        
        for (String service : services) {
            ServiceNode node = new ServiceNode(service);
            graph.addNode(node);
        }
        
        // 添加边（服务间调用）
        for (Span span : trace.getSpans()) {
            String sourceService = span.getTags().get("service.name");
            String targetService = span.getTags().get("peer.service");
            
            if (sourceService != null && targetService != null) {
                ServiceNode source = new ServiceNode(sourceService);
                ServiceNode target = new ServiceNode(targetService);
                
                ServiceEdge edge = new ServiceEdge(source, target);
                edge.setCallCount(edge.getCallCount() + 1);
                
                // 设置延迟信息
                long duration = Duration.between(span.getStartTime(), span.getEndTime()).toMillis();
                edge.setAverageLatency(duration);
                
                graph.addEdge(edge);
            }
        }
        
        return graph;
    }
}
```

## 可观测性架构设计

### 整体架构

**数据采集层**：

```yaml
# Prometheus配置示例
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "recording_rules.yml"
  - "alerting_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'kubernetes-apiservers'
    kubernetes_sd_configs:
    - role: endpoints
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
    - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
      action: keep
      regex: default;kubernetes;https

  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
    - role: pod
    relabel_configs:
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
      action: keep
      regex: true
    - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
      action: replace
      target_label: __metrics_path__
      regex: (.+)
```

```java
// 可观测性数据收集器
public class ObservabilityCollector {
    private final MetricsEndpoint metricsEndpoint;
    private final LogsEndpoint logsEndpoint;
    private final TracesEndpoint tracesEndpoint;
    private final CollectorRegistry registry;
    private final ScheduledExecutorService scheduledExecutor;
    
    public ObservabilityCollector() {
        this.registry = new CollectorRegistry();
        this.metricsEndpoint = new MetricsEndpoint(registry);
        this.logsEndpoint = new LogsEndpoint();
        this.tracesEndpoint = new TracesEndpoint();
        this.scheduledExecutor = Executors.newScheduledThreadPool(4);
        
        initializeCollectors();
    }
    
    private void initializeCollectors() {
        // 1. JVM指标收集
        registerJVMCollectors();
        
        // 2. 应用业务指标收集
        registerApplicationCollectors();
        
        // 3. 系统资源指标收集
        registerSystemCollectors();
        
        // 4. 网络指标收集
        registerNetworkCollectors();
    }
    
    private void registerJVMCollectors() {
        // GC指标
        Gauge.builder("jvm_gc_duration_seconds")
            .description("Time spent in garbage collection")
            .register(registry, this, this::getGCDuration);
        
        // 内存使用
        Gauge.builder("jvm_memory_used_bytes")
            .description("JVM memory usage")
            .register(registry, this, this::getMemoryUsage);
        
        // 线程数
        Gauge.builder("jvm_threads_live")
            .description("Number of live threads")
            .register(registry, this, this::getThreadCount);
        
        // 类加载数
        Gauge.builder("jvm_classes_loaded")
            .description("Number of loaded classes")
            .register(registry, this, this::getClassCount);
    }
    
    private void registerApplicationCollectors() {
        // HTTP请求指标
        Counter.builder("http_requests_total")
            .description("Total number of HTTP requests")
            .labelNames("method", "uri", "status")
            .register(registry);
        
        // 数据库连接池指标
        Gauge.builder("db_connections_active")
            .description("Active database connections")
            .labelNames("database")
            .register(registry);
        
        // 队列长度
        Gauge.builder("queue_length")
            .description("Queue length")
            .labelNames("queue_name")
            .register(registry);
        
        // 缓存命中率
        Gauge.builder("cache_hit_ratio")
            .description("Cache hit ratio")
            .labelNames("cache_name")
            .register(registry);
    }
    
    private void registerSystemCollectors() {
        // CPU使用率
        Gauge.builder("system_cpu_usage")
            .description("CPU usage percentage")
            .register(registry, this, this::getSystemCpuUsage);
        
        // 磁盘使用率
        Gauge.builder("disk_usage_bytes")
            .description("Disk usage in bytes")
            .labelNames("mountpoint")
            .register(registry, this, this::getDiskUsage);
        
        // 网络流量
        Gauge.builder("network_bytes_total")
            .description("Network traffic")
            .labelNames("direction", "interface")
            .register(registry, this, this::getNetworkBytes);
    }
    
    // 收集自定义业务指标
    public void recordBusinessMetric(String metricName, double value, Map<String, String> labels) {
        Counter counter = Counter.builder(metricName)
            .description("Business metric counter")
            .labelNames(labels.keySet().toArray(new String[0]))
            .register(registry);
        
        counter.labels(labels.values().toArray(new String[0])).inc(value);
    }
    
    // 收集性能指标
    public void recordLatencyMetric(String operation, long latencyMs, Status status) {
        // 记录延迟直方图
        Histogram latencyHistogram = Histogram.builder("operation_duration_seconds")
            .description("Operation duration histogram")
            .labelNames("operation", "status")
            .buckets(0.001, 0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1.0, 2.5, 5.0, 7.5, 10.0)
            .register(registry);
        
        latencyHistogram.labels(operation, status.name().toLowerCase())
            .observe(latencyMs / 1000.0);
    }
}

// OpenTelemetry集成
public class OpenTelemetryIntegration {
    private final OpenTelemetry openTelemetry;
    private final Meter meter;
    private final Tracer tracer;
    
    public OpenTelemetryIntegration() {
        // 初始化OpenTelemetry SDK
        Resource serviceName = Resource.create(Attributes.of(
            ResourceAttributes.SERVICE_NAME, "my-service",
            ResourceAttributes.SERVICE_VERSION, "1.0.0"
        ));
        
        this.openTelemetry = OpenTelemetrySdk.builder()
            .setTracerProvider(SdkTracerProvider.builder()
                .setResource(serviceName)
                .addSpanProcessor(BatchSpanProcessor.builder(
                    OtlpGrpcSpanExporter.builder()
                        .setEndpoint("http://jaeger-collector:14250")
                        .build()
                ).build())
                .build())
            .setMeterProvider(SdkMeterProvider.builder()
                .setResource(serviceName)
                .addMeterProviderCustomizer((builder, config) -> 
                    builder.registerPrometheusExporter(config -> {}))
                .build())
            .build();
        
        this.meter = openTelemetry.meterBuilder("my-service").build();
        this.tracer = openTelemetry.tracerBuilder("my-service").build();
    }
    
    // 创建指标
    public Counter<Long> createCounter(String name, String description) {
        return meter.counterBuilder(name)
            .setDescription(description)
            .build();
    }
    
    public Histogram<Double> createHistogram(String name, String description) {
        return meter.histogramBuilder(name)
            .setDescription(description)
            .build();
    }
    
    // 创建追踪
    public Span createSpan(String operationName) {
        return tracer.spanBuilder(operationName).startSpan();
    }
    
    // 添加分布式上下文传播
    public void injectContext(HttpHeaders headers) {
        openTelemetry.getPropagators().getTextMapPropagator()
            .inject(Context.current(), headers, Map::put);
    }
    
    public Context extractContext(HttpHeaders headers) {
        return openTelemetry.getPropagators().getTextMapPropagator()
            .extract(Context.current(), headers, Map::get);
    }
}
```

### 数据存储架构

**时序数据库设计**：

```java
// 时序数据存储管理器
public class TimeSeriesStorageManager {
    private final InfluxDBClient influxDBClient;
    private final ClickHouseClient clickHouseClient;
    private final DataRetentionPolicy retentionPolicy;
    private final CompressionStrategy compressionStrategy;
    
    public void storeMetrics(List<MetricData> metrics) {
        // 1. 数据预处理
        List<PreprocessedMetric> preprocessedMetrics = preprocessMetrics(metrics);
        
        // 2. 数据压缩
        List<CompressedMetric> compressedMetrics = compressMetrics(preprocessedMetrics);
        
        // 3. 分片存储
        Map<String, List<CompressedMetric>> shardedMetrics = shardMetrics(compressedMetrics);
        
        // 4. 批量写入
        for (Map.Entry<String, List<CompressedMetric>> entry : shardedMetrics.entrySet()) {
            String shard = entry.getKey();
            List<CompressedMetric> shardMetrics = entry.getValue();
            
            writeMetricsToShard(shard, shardMetrics);
        }
    }
    
    private List<PreprocessedMetric> preprocessMetrics(List<MetricData> metrics) {
        return metrics.stream().map(metric -> {
            PreprocessedMetric preprocessed = new PreprocessedMetric();
            preprocessed.setMetricName(metric.getName());
            preprocessed.setTimestamp(metric.getTimestamp());
            preprocessed.setValue(metric.getValue());
            
            // 标准化标签
            Map<String, String> normalizedTags = normalizeTags(metric.getTags());
            preprocessed.setTags(normalizedTags);
            
            // 添加计算字段
            preprocessed.setHash(calculateMetricHash(metric));
            preprocessed.setCompressionRatio(0.0);
            
            return preprocessed;
        }).collect(Collectors.toList());
    }
    
    private List<CompressedMetric> compressMetrics(List<PreprocessedMetric> metrics) {
        return metrics.stream().map(metric -> {
            // 时间戳压缩
            byte[] compressedTimestamp = compressionStrategy.compressTimestamp(metric.getTimestamp());
            
            // 数值压缩
            byte[] compressedValue = compressionStrategy.compressValue(metric.getValue());
            
            // 标签压缩
            byte[] compressedTags = compressionStrategy.compressTags(metric.getTags());
            
            CompressedMetric compressed = new CompressedMetric();
            compressed.setMetricId(metric.getHash());
            compressed.setCompressedTimestamp(compressedTimestamp);
            compressed.setCompressedValue(compressedValue);
            compressed.setCompressedTags(compressedTags);
            compressed.setOriginalSize(calculateOriginalSize(metric));
            compressed.setCompressedSize(calculateCompressedSize(compressed));
            
            double compressionRatio = (double) compressed.getCompressedSize() / compressed.getOriginalSize();
            compressed.setCompressionRatio(compressionRatio);
            
            return compressed;
        }).collect(Collectors.toList());
    }
    
    private Map<String, List<CompressedMetric>> shardMetrics(List<CompressedMetric> metrics) {
        return metrics.stream()
            .collect(Collectors.groupingBy(this::calculateShardKey));
    }
    
    private String calculateShardKey(CompressedMetric metric) {
        // 基于时间范围分片
        Instant timestamp = extractTimestamp(metric);
        long shardId = timestamp.toEpochMilli() / (24 * 60 * 60 * 1000); // 按天分片
        
        // 基于指标名称分片
        String metricPrefix = metric.getMetricId().substring(0, 2);
        
        return metricPrefix + "_" + shardId;
    }
    
    private void writeMetricsToShard(String shard, List<CompressedMetric> metrics) {
        // 写入InfluxDB（用于实时查询）
        writeToInfluxDB(shard, metrics);
        
        // 写入ClickHouse（用于历史分析）
        writeToClickHouse(shard, metrics);
    }
    
    private void writeToInfluxDB(String shard, List<CompressedMetric> metrics) {
        WriteApi writeApi = influxDBClient.makeWriteApi(WritePrecision.NS);
        
        List<Point> points = metrics.stream().map(this::convertToInfluxPoint).collect(Collectors.toList());
        
        writeApi.writePoints("observability", "prometheus", points);
    }
    
    private void writeToClickHouse(String shard, List<CompressedMetric> metrics) {
        String sql = """
            INSERT INTO compressed_metrics 
            (shard, metric_id, timestamp, value, tags, compression_ratio)
            VALUES (?, ?, ?, ?, ?, ?)
            """;
        
        try (PreparedStatement stmt = clickHouseClient.prepareStatement(sql)) {
            for (CompressedMetric metric : metrics) {
                stmt.setString(1, shard);
                stmt.setString(2, metric.getMetricId());
                stmt.setTimestamp(3, extractTimestamp(metric));
                stmt.setDouble(4, extractValue(metric));
                stmt.setString(5, extractTags(metric));
                stmt.setDouble(6, metric.getCompressionRatio());
                
                stmt.addBatch();
            }
            
            stmt.executeBatch();
        }
    }
}

// 数据查询优化器
public class TimeSeriesQueryOptimizer {
    private final QueryCache queryCache;
    private final ExecutionPlanBuilder planBuilder;
    
    public QueryResult executeOptimizedQuery(TimeSeriesQuery query) {
        try {
            // 1. 查询分析
            QueryAnalysis analysis = analyzeQuery(query);
            
            // 2. 执行计划生成
            ExecutionPlan executionPlan = planBuilder.buildExecutionPlan(query, analysis);
            
            // 3. 查询缓存检查
            QueryResult cachedResult = queryCache.get(executionPlan);
            if (cachedResult != null) {
                return cachedResult;
            }
            
            // 4. 执行查询
            QueryResult result = executeQuery(executionPlan);
            
            // 5. 结果缓存
            queryCache.put(executionPlan, result);
            
            return result;
            
        } catch (Exception e) {
            throw new QueryExecutionException("Failed to execute query", e);
        }
    }
    
    private QueryAnalysis analyzeQuery(TimeSeriesQuery query) {
        QueryAnalysis analysis = new QueryAnalysis();
        
        // 1. 时间范围分析
        Duration queryDuration = Duration.between(query.getStartTime(), query.getEndTime());
        analysis.setQueryDuration(queryDuration);
        
        // 2. 数据量估算
        long estimatedDataPoints = estimateDataPoints(query, queryDuration);
        analysis.setEstimatedDataPoints(estimatedDataPoints);
        
        // 3. 复杂度评估
        QueryComplexity complexity = assessQueryComplexity(query);
        analysis.setComplexity(complexity);
        
        // 4. 缓存策略确定
        CacheStrategy cacheStrategy = determineCacheStrategy(queryDuration, complexity);
        analysis.setCacheStrategy(cacheStrategy);
        
        // 5. 分片策略确定
        ShardStrategy shardStrategy = determineShardStrategy(query);
        analysis.setShardStrategy(shardStrategy);
        
        return analysis;
    }
    
    private QueryComplexity assessQueryComplexity(TimeSeriesQuery query) {
        int complexityScore = 0;
        
        // 时间范围复杂度
        Duration duration = Duration.between(query.getStartTime(), query.getEndTime());
        if (duration.toDays() > 30) {
            complexityScore += 3;
        } else if (duration.toDays() > 7) {
            complexityScore += 2;
        } else if (duration.toDays() > 1) {
            complexityScore += 1;
        }
        
        // 聚合函数复杂度
        for (AggregationType aggregation : query.getAggregations()) {
            switch (aggregation) {
                case COUNT:
                case SUM:
                    complexityScore += 1;
                    break;
                case AVG:
                    complexityScore += 2;
                    break;
                case PERCENTILE:
                case DERIVATIVE:
                    complexityScore += 3;
                    break;
            }
        }
        
        // 标签过滤复杂度
        complexityScore += query.getTagFilters().size() * 0.5;
        
        // 函数复杂度
        complexityScore += query.getFunctions().size() * 2;
        
        if (complexityScore <= 5) {
            return QueryComplexity.LOW;
        } else if (complexityScore <= 15) {
            return QueryComplexity.MEDIUM;
        } else {
            return QueryComplexity.HIGH;
        }
    }
}
```

## 告警系统设计

### 智能告警引擎

**告警规则引擎**：

```java
// 告警规则引擎
public class AlertingEngine {
    private final RuleEngine ruleEngine;
    private final AlertManager alertManager;
    private final NotificationService notificationService;
    private final EscalationPolicy escalationPolicy;
    private final AlertDeduplication deduplication;
    
    public AlertingEngine() {
        this.ruleEngine = new DroolsRuleEngine();
        this.alertManager = new AlertManager();
        this.notificationService = new MultiChannelNotificationService();
        this.escalationPolicy = new EscalationPolicy();
        this.deduplication = new AlertDeduplication();
        
        initializeRules();
    }
    
    private void initializeRules() {
        // 加载告警规则
        ruleEngine.loadRules("alert-rules.drl");
        
        // 初始化规则
        ruleEngine.insertFacts(new AlertingRules());
    }
    
    public void processMetrics(List<MetricData> metrics) {
        for (MetricData metric : metrics) {
            try {
                // 1. 评估告警规则
                List<Alert> alerts = evaluateRules(metric);
                
                // 2. 去重告警
                alerts = deduplication.deduplicate(alerts);
                
                // 3. 告警处理
                for (Alert alert : alerts) {
                    processAlert(alert);
                }
                
            } catch (Exception e) {
                logger.error("Failed to process metric", e);
            }
        }
    }
    
    private List<Alert> evaluateRules(MetricData metric) {
        List<Alert> alerts = new ArrayList<>();
        
        try {
            // 构建规则上下文
            RuleContext context = new RuleContext();
            context.setMetric(metric);
            context.setTimestamp(Instant.now());
            
            // 插入事实
            ruleEngine.insertFacts(context);
            
            // 触发规则评估
            ruleEngine.fireAllRules();
            
            // 获取告警结果
            alerts = context.getGeneratedAlerts();
            
        } catch (Exception e) {
            logger.error("Failed to evaluate rules for metric", e);
        }
        
        return alerts;
    }
    
    private void processAlert(Alert alert) {
        try {
            // 1. 告警验证
            if (!validateAlert(alert)) {
                logger.warn("Invalid alert: {}", alert);
                return;
            }
            
            // 2. 告警去重
            if (deduplication.isDuplicate(alert)) {
                logger.debug("Duplicate alert ignored: {}", alert.getId());
                return;
            }
            
            // 3. 存储告警
            alertManager.storeAlert(alert);
            
            // 4. 发送通知
            sendNotification(alert);
            
            // 5. 处理升级策略
            scheduleEscalation(alert);
            
            // 6. 记录告警事件
            recordAlertEvent(alert);
            
        } catch (Exception e) {
            logger.error("Failed to process alert", e);
        }
    }
    
    private void sendNotification(Alert alert) {
        NotificationRequest request = new NotificationRequest();
        request.setAlert(alert);
        request.setChannels(determineNotificationChannels(alert));
        request.setPriority(determinePriority(alert));
        request.setTemplate(getNotificationTemplate(alert.getType()));
        
        notificationService.sendNotification(request);
    }
    
    private void scheduleEscalation(Alert alert) {
        EscalationLevel level = escalationPolicy.getInitialLevel(alert);
        
        for (int i = 0; i < escalationPolicy.getMaxLevels(); i++) {
            EscalationAction action = escalationPolicy.getAction(level, i);
            
            ScheduledFuture<?> future = CompletableFuture.runAsync(() -> {
                try {
                    executeEscalation(alert, action);
                } catch (Exception e) {
                    logger.error("Failed to execute escalation", e);
                }
            });
            
            alert.addEscalationFuture(level, future);
            
            level = escalationPolicy.getNextLevel(level);
        }
    }
}

// 告警规则定义
public class AlertingRules {
    
    // CPU使用率告警
    public void checkCpuUsage(RuleContext context) {
        MetricData metric = context.getMetric();
        
        if ("system.cpu.usage".equals(metric.getName())) {
            double cpuUsage = metric.getValue();
            
            if (cpuUsage > 90.0) {
                Alert alert = new Alert();
                alert.setId(generateAlertId());
                alert.setSeverity(Severity.CRITICAL);
                alert.setType("CPU_HIGH_USAGE");
                alert.setMetric(metric);
                alert.setMessage("CPU usage is critically high: " + cpuUsage + "%");
                alert.setThreshold(90.0);
                alert.setCurrentValue(cpuUsage);
                alert.setTimestamp(Instant.now());
                
                context.addAlert(alert);
            } else if (cpuUsage > 80.0) {
                Alert alert = new Alert();
                alert.setId(generateAlertId());
                alert.setSeverity(Severity.WARNING);
                alert.setType("CPU_HIGH_USAGE");
                alert.setMetric(metric);
                alert.setMessage("CPU usage is high: " + cpuUsage + "%");
                alert.setThreshold(80.0);
                alert.setCurrentValue(cpuUsage);
                alert.setTimestamp(Instant.now());
                
                context.addAlert(alert);
            }
        }
    }
    
    // 内存使用率告警
    public void checkMemoryUsage(RuleContext context) {
        MetricData metric = context.getMetric();
        
        if ("system.memory.usage".equals(metric.getName())) {
            double memoryUsage = metric.getValue();
            
            if (memoryUsage > 95.0) {
                Alert alert = new Alert();
                alert.setId(generateAlertId());
                alert.setSeverity(Severity.CRITICAL);
                alert.setType("MEMORY_HIGH_USAGE");
                alert.setMetric(metric);
                alert.setMessage("Memory usage is critically high: " + memoryUsage + "%");
                alert.setThreshold(95.0);
                alert.setCurrentValue(memoryUsage);
                alert.setTimestamp(Instant.now());
                
                context.addAlert(alert);
            }
        }
    }
    
    // 错误率告警
    public void checkErrorRate(RuleContext context) {
        MetricData metric = context.getMetric();
        
        if ("http_requests_total".equals(metric.getName())) {
            Map<String, String> tags = metric.getTags();
            String status = tags.get("status");
            
            if ("5xx".equals(status)) {
                // 计算错误率（这里需要聚合计算）
                double errorRate = context.calculateErrorRate();
                
                if (errorRate > 0.05) { // 5%
                    Alert alert = new Alert();
                    alert.setId(generateAlertId());
                    alert.setSeverity(Severity.CRITICAL);
                    alert.setType("HIGH_ERROR_RATE");
                    alert.setMetric(metric);
                    alert.setMessage("Error rate is critically high: " + (errorRate * 100) + "%");
                    alert.setThreshold(0.05);
                    alert.setCurrentValue(errorRate);
                    alert.setTimestamp(Instant.now());
                    
                    context.addAlert(alert);
                }
            }
        }
    }
    
    // 延迟告警
    public void checkLatency(RuleContext context) {
        MetricData metric = context.getMetric();
        
        if ("http_request_duration_seconds".equals(metric.getName())) {
            double latency = metric.getValue();
            Map<String, String> tags = metric.getTags();
            String endpoint = tags.get("endpoint");
            
            if (latency > 5.0) { // 5秒
                Alert alert = new Alert();
                alert.setId(generateAlertId());
                alert.setSeverity(Severity.CRITICAL);
                alert.setType("HIGH_LATENCY");
                alert.setMetric(metric);
                alert.setMessage("HTTP latency is critically high for " + endpoint + ": " + latency + "s");
                alert.setThreshold(5.0);
                alert.setCurrentValue(latency);
                alert.setTimestamp(Instant.now());
                
                context.addAlert(alert);
            }
        }
    }
}

// 告警降噪和抑制
public class AlertNoiseReducer {
    private final AlertSuppression suppression;
    private final AlertGrouping grouping;
    private final AlertCorrelation correlation;
    
    public List<Alert> reduceNoise(List<Alert> alerts) {
        // 1. 告警抑制
        alerts = suppression.suppressAlerts(alerts);
        
        // 2. 告警分组
        List<AlertGroup> groups = grouping.groupAlerts(alerts);
        
        // 3. 告警关联
        List<Alert> correlatedAlerts = correlation.correlateAlerts(groups);
        
        // 4. 抑制重复告警
        correlatedAlerts = suppressDuplicateAlerts(correlatedAlerts);
        
        return correlatedAlerts;
    }
    
    private List<Alert> suppressDuplicateAlerts(List<Alert> alerts) {
        Map<String, Alert> uniqueAlerts = new HashMap<>();
        
        for (Alert alert : alerts) {
            String suppressionKey = generateSuppressionKey(alert);
            
            if (!uniqueAlerts.containsKey(suppressionKey)) {
                uniqueAlerts.put(suppressionKey, alert);
            } else {
                Alert existingAlert = uniqueAlerts.get(suppressionKey);
                if (isHigherSeverity(alert.getSeverity(), existingAlert.getSeverity())) {
                    uniqueAlerts.put(suppressionKey, alert);
                }
            }
        }
        
        return new ArrayList<>(uniqueAlerts.values());
    }
    
    private String generateSuppressionKey(Alert alert) {
        return String.format("%s:%s:%s",
            alert.getType(),
            alert.getMetric().getTags().get("service"),
            alert.getMetric().getTags().get("instance")
        );
    }
}
```

## 可观测性最佳实践

### 数据收集策略

```java
// 可观测性最佳实践实现
public class ObservabilityBestPractices {
    
    // 1. 统一的可观测性标签
    public static class UnifiedTags {
        public static Map<String, String> getStandardTags() {
            Map<String, String> tags = new HashMap<>();
            tags.put("service", getServiceName());
            tags.put("version", getServiceVersion());
            tags.put("environment", getEnvironment());
            tags.put("region", getRegion());
            tags.put("cluster", getClusterName());
            tags.put("namespace", getNamespace());
            return tags;
        }
    }
    
    // 2. 采样策略
    public class SamplingStrategy {
        private final Sampler traceSampler = new ProbabilisticSampler(0.1); // 10%采样率
        private final RateLimiter logRateLimiter = RateLimiter.create(1000); // 每秒1000条日志
        private final Sampler metricsSampler = new ProbabilisticSampler(0.01); // 1%采样率
        
        public boolean shouldSampleTrace() {
            return traceSampler.isSampled();
        }
        
        public boolean shouldSampleMetrics() {
            return metricsSampler.isSampled();
        }
        
        public boolean allowLog() {
            return logRateLimiter.tryAcquire();
        }
    }
    
    // 3. 性能影响最小化
    public class LowImpactCollector {
        private final BlockingQueue<MetricData> metricsQueue = new LinkedBlockingQueue<>(10000);
        private final ScheduledExecutorService asyncExecutor = Executors.newScheduledThreadPool(2);
        
        public void init() {
            // 异步批量发送指标
            asyncExecutor.scheduleAtFixedRate(this::flushMetrics, 5, 5, TimeUnit.SECONDS);
            
            // 异步发送日志
            asyncExecutor.scheduleAtFixedRate(this::flushLogs, 1, 1, TimeUnit.SECONDS);
        }
        
        public void recordMetric(String name, double value, Map<String, String> tags) {
            if (samplingStrategy.shouldSampleMetrics()) {
                MetricData metric = new MetricData(name, value, tags, Instant.now());
                metricsQueue.offer(metric);
            }
        }
        
        private void flushMetrics() {
            List<MetricData> batch = new ArrayList<>();
            metricsQueue.drainTo(batch, 1000);
            
            if (!batch.isEmpty()) {
                try {
                    metricsPublisher.publishBatch(batch);
                } catch (Exception e) {
                    logger.warn("Failed to publish metrics batch", e);
                }
            }
        }
    }
    
    // 4. 数据质量保证
    public class DataQualityAssurance {
        
        public void validateMetric(MetricData metric) {
            if (metric.getName() == null || metric.getName().trim().isEmpty()) {
                throw new IllegalArgumentException("Metric name is required");
            }
            
            if (Double.isNaN(metric.getValue()) || Double.isInfinite(metric.getValue())) {
                throw new IllegalArgumentException("Invalid metric value: " + metric.getValue());
            }
            
            if (metric.getTimestamp() == null) {
                metric.setTimestamp(Instant.now());
            }
            
            if (metric.getTimestamp().isAfter(Instant.now().plusSeconds(60))) {
                throw new IllegalArgumentException("Future timestamp not allowed");
            }
            
            // 验证标签
            if (metric.getTags() != null) {
                for (Map.Entry<String, String> tag : metric.getTags().entrySet()) {
                    if (tag.getKey() == null || tag.getKey().trim().isEmpty()) {
                        throw new IllegalArgumentException("Empty tag key not allowed");
                    }
                    
                    if (tag.getValue() == null || tag.getValue().trim().isEmpty()) {
                        logger.warn("Empty tag value for key: {}", tag.getKey());
                    }
                }
            }
        }
    }
}
```

## 总结

可观测性系统是现代云原生应用的核心基础设施，通过系统性地收集、分析和可视化系统的运行数据，为运维和开发团队提供深入的系统理解能力。

### 核心价值

1. **问题快速定位**：通过指标、日志和追踪的关联分析，快速定位问题根因
2. **性能优化指导**：基于实际数据性能指标，持续优化系统性能
3. **容量规划支持**：通过历史数据分析，科学制定容量规划
4. **用户体验保障**：实时监控用户体验指标，及时发现和解决问题
5. **业务洞察发现**：通过业务指标分析，发现业务价值和优化机会

### 技术要点

- **三大支柱**：指标(Metrics)、日志(Logs)、追踪(Traces)缺一不可
- **数据采集**：低侵入、高性能的数据收集机制
- **存储优化**：时序数据库的高效存储和查询
- **告警智能化**：智能告警减少噪音，提高告警质量
- **可视化分析**：直观的数据可视化帮助理解和决策

通过构建完善的可观测性系统，可以实现从被动监控到主动预测的转变，大幅提升系统的可靠性和运维效率。