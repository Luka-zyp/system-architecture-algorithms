# 性能分析与优化策略

## 1. 性能分析基础

### 性能分析概念
```python
from enum import Enum
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
import time
import threading
import psutil
import cProfile
import pstats
import io
import sys
import tracemalloc
from contextlib import contextmanager
import json
import pickle
from collections import defaultdict, deque
import statistics

class ProfilingType(Enum):
    CPU_PROFILING = "cpu_profiling"       # CPU分析
    MEMORY_PROFILING = "memory_profiling" # 内存分析
    IO_PROFILING = "io_profiling"         # I/O分析
    WALL_TIME_PROFILING = "wall_time_profiling"  # 壁钟时间分析
    LINE_PROFILING = "line_profiling"     # 行级分析

@dataclass
class ProfilingResult:
    profiling_type: ProfilingType
    start_time: float
    end_time: float
    duration: float
    data: Dict[str, Any]
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class FunctionProfile:
    function_name: str
    file_path: str
    line_number: int
    call_count: int = 0
    total_time: float = 0.0
    cumulative_time: float = 0.0
    per_call_time: float = 0.0
    sub_function_calls: List[str] = field(default_factory=list)

@dataclass
class MemorySnapshot:
    timestamp: float
    total_memory: int
    memory_by_type: Dict[str, int]
    top_memory_consumers: List[Dict[str, Any]]

@dataclass
class IOCounter:
    read_count: int = 0
    write_count: int = 0
    read_bytes: int = 0
    write_bytes: int = 0
    read_time: float = 0.0
    write_time: float = 0.0

class BaseProfiler(ABC):
    """基础性能分析器"""
    
    def __init__(self, name: str):
        self.name = name
        self.is_running = False
        self.results = []
    
    @abstractmethod
    def start_profiling(self):
        """开始分析"""
        pass
    
    @abstractmethod
    def stop_profiling(self) -> ProfilingResult:
        """停止分析"""
        pass
    
    @abstractmethod
    def get_current_stats(self) -> Dict[str, Any]:
        """获取当前统计信息"""
        pass

class CPUProfiler(BaseProfiler):
    """CPU性能分析器"""
    
    def __init__(self):
        super().__init__("cpu_profiler")
        self.profiler = None
        self.start_timestamp = 0.0
    
    def start_profiling(self):
        """开始CPU分析"""
        if self.is_running:
            return
        
        self.is_running = True
        self.start_timestamp = time.time()
        self.profiler = cProfile.Profile()
        self.profiler.enable()
    
    def stop_profiling(self) -> ProfilingResult:
        """停止CPU分析"""
        if not self.is_running or not self.profiler:
            raise RuntimeError("Profiler is not running")
        
        self.profiler.disable()
        self.is_running = False
        
        end_timestamp = time.time()
        duration = end_timestamp - self.start_timestamp
        
        # 分析结果
        stats_stream = io.StringIO()
        stats = pstats.Stats(self.profiler, stream=stats_stream)
        stats.sort_stats('cumulative')
        stats.print_stats()
        
        cpu_data = {
            'stats_text': stats_stream.getvalue(),
            'functions': self._extract_function_stats(stats),
            'top_functions': self._get_top_functions(stats, 10)
        }
        
        result = ProfilingResult(
            profiling_type=ProfilingType.CPU_PROFILING,
            start_time=self.start_timestamp,
            end_time=end_timestamp,
            duration=duration,
            data=cpu_data,
            metadata={'profiler': 'cProfile'}
        )
        
        self.results.append(result)
        return result
    
    def get_current_stats(self) -> Dict[str, Any]:
        """获取当前CPU使用率"""
        return {
            'cpu_percent': psutil.cpu_percent(),
            'cpu_count': psutil.cpu_count(),
            'load_average': psutil.getloadavg() if hasattr(psutil, 'getloadavg') else [0, 0, 0]
        }
    
    def _extract_function_stats(self, stats: pstats.Stats) -> List[FunctionProfile]:
        """提取函数统计信息"""
        functions = []
        
        for func_info in stats.stats.values():
            file_path, line_number, function_name, call_count, cumulative_time, total_time = func_info
            
            per_call_time = cumulative_time / call_count if call_count > 0 else 0
            
            functions.append(FunctionProfile(
                function_name=function_name,
                file_path=file_path,
                line_number=line_number,
                call_count=call_count,
                total_time=total_time,
                cumulative_time=cumulative_time,
                per_call_time=per_call_time
            ))
        
        return sorted(functions, key=lambda x: x.cumulative_time, reverse=True)
    
    def _get_top_functions(self, stats: pstats.Stats, count: int = 10) -> List[Dict[str, Any]]:
        """获取顶部函数"""
        top_functions = []
        
        # 按累计时间排序
        for func_info in stats.stats.values()[:count]:
            file_path, line_number, function_name, call_count, cumulative_time, total_time = func_info
            
            top_functions.append({
                'function': function_name,
                'file': file_path,
                'line': line_number,
                'call_count': call_count,
                'cumulative_time': cumulative_time,
                'total_time': total_time,
                'per_call_time': cumulative_time / call_count if call_count > 0 else 0
            })
        
        return top_functions

class MemoryProfiler(BaseProfiler):
    """内存性能分析器"""
    
    def __init__(self):
        super().__init__("memory_profiler")
        self.snapshots = []
        self.start_timestamp = 0.0
        self.peak_memory = 0
    
    def start_profiling(self):
        """开始内存分析"""
        if self.is_running:
            return
        
        self.is_running = True
        self.start_timestamp = time.time()
        tracemalloc.start()
        
        # 初始快照
        self._take_snapshot()
    
    def stop_profiling(self) -> ProfilingResult:
        """停止内存分析"""
        if not self.is_running:
            raise RuntimeError("Memory profiler is not running")
        
        self.is_running = False
        
        # 最终快照
        self._take_snapshot()
        
        end_timestamp = time.time()
        duration = end_timestamp - self.start_timestamp
        
        # 计算内存统计
        memory_data = self._calculate_memory_stats()
        
        result = ProfilingResult(
            profiling_type=ProfilingType.MEMORY_PROFILING,
            start_time=self.start_timestamp,
            end_time=end_timestamp,
            duration=duration,
            data=memory_data,
            metadata={
                'peak_memory': self.peak_memory,
                'snapshot_count': len(self.snapshots)
            }
        )
        
        self.results.append(result)
        tracemalloc.stop()
        return result
    
    def get_current_stats(self) -> Dict[str, Any]:
        """获取当前内存使用情况"""
        process = psutil.Process()
        memory_info = process.memory_info()
        
        return {
            'rss': memory_info.rss,  # 物理内存
            'vms': memory_info.vms,  # 虚拟内存
            'percent': process.memory_percent(),
            'available': psutil.virtual_memory().available,
            'used': psutil.virtual_memory().used
        }
    
    def _take_snapshot(self):
        """拍摄内存快照"""
        if not self.is_running:
            return
        
        snapshot = tracemalloc.take_snapshot()
        
        # 更新峰值内存
        current, peak = tracemalloc.get_traced_memory()
        self.peak_memory = max(self.peak_memory, peak)
        
        # 统计快照信息
        memory_by_type = {}
        top_stats = snapshot.statistics('lineno')
        
        for index, stat in enumerate(top_stats[:10]):  # 前10个内存使用最高的条目
            frame = stat.traceback.format()[-1] if stat.traceback else "unknown"
            memory_by_type[frame] = stat.size
        
        snapshot_data = MemorySnapshot(
            timestamp=time.time(),
            total_memory=current,
            memory_by_type=memory_by_type,
            top_memory_consumers=[
                {
                    'traceback': stat.traceback.format(),
                    'size': stat.size,
                    'count': stat.count
                }
                for stat in top_stats[:10]
            ]
        )
        
        self.snapshots.append(snapshot_data)
    
    def _calculate_memory_stats(self) -> Dict[str, Any]:
        """计算内存统计信息"""
        if not self.snapshots:
            return {}
        
        total_memories = [snap.total_memory for snap in self.snapshots]
        memory_growth = total_memories[-1] - total_memories[0]
        
        # 分析内存增长趋势
        memory_changes = [total_memories[i] - total_memories[i-1] 
                         for i in range(1, len(total_memories))]
        
        return {
            'initial_memory': total_memories[0],
            'final_memory': total_memories[-1],
            'peak_memory': self.peak_memory,
            'memory_growth': memory_growth,
            'memory_growth_rate': memory_growth / len(self.snapshots),
            'average_memory': statistics.mean(total_memories),
            'memory_volatility': statistics.stdev(total_memories) if len(total_memories) > 1 else 0,
            'top_consumers': self._get_top_memory_consumers(),
            'memory_trend': self._analyze_memory_trend(total_memories)
        }
    
    def _get_top_memory_consumers(self) -> List[Dict[str, Any]]:
        """获取内存消耗最大的对象"""
        if not self.snapshots:
            return []
        
        latest_snapshot = self.snapshots[-1]
        return latest_snapshot.top_memory_consumers[:5]
    
    def _analyze_memory_trend(self, memories: List[int]) -> str:
        """分析内存趋势"""
        if len(memories) < 3:
            return "insufficient_data"
        
        # 计算线性回归斜率
        n = len(memories)
        sum_x = sum(range(n))
        sum_y = sum(memories)
        sum_xy = sum(i * memories[i] for i in range(n))
        sum_x2 = sum(i * i for i in range(n))
        
        slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x * sum_x)
        
        if slope > 1000:  # 假设每秒增长超过1000字节
            return "increasing_rapidly"
        elif slope > 100:
            return "increasing_slowly"
        elif slope < -1000:
            return "decreasing_rapidly"
        elif slope < -100:
            return "decreasing_slowly"
        else:
            return "stable"

class IOProfiler(BaseProfiler):
    """I/O性能分析器"""
    
    def __init__(self):
        super().__init__("io_profiler")
        self.initial_counters = None
        self.final_counters = None
        self.start_timestamp = 0.0
        self.monitor_thread = None
        self.io_samples = deque(maxlen=1000)
    
    def start_profiling(self):
        """开始I/O分析"""
        if self.is_running:
            return
        
        self.is_running = True
        self.start_timestamp = time.time()
        self.initial_counters = self._get_io_counters()
        
        # 启动I/O监控线程
        self.monitor_thread = threading.Thread(target=self._monitor_io, daemon=True)
        self.monitor_thread.start()
    
    def stop_profiling(self) -> ProfilingResult:
        """停止I/O分析"""
        if not self.is_running:
            raise RuntimeError("IO profiler is not running")
        
        self.is_running = False
        self.final_counters = self._get_io_counters()
        
        if self.monitor_thread:
            self.monitor_thread.join(timeout=1.0)
        
        end_timestamp = time.time()
        duration = end_timestamp - self.start_timestamp
        
        # 计算I/O统计
        io_data = self._calculate_io_stats()
        
        result = ProfilingResult(
            profiling_type=ProfilingType.IO_PROFILING,
            start_time=self.start_timestamp,
            end_time=end_timestamp,
            duration=duration,
            data=io_data,
            metadata={
                'sample_count': len(self.io_samples)
            }
        )
        
        self.results.append(result)
        return result
    
    def get_current_stats(self) -> Dict[str, Any]:
        """获取当前I/O统计"""
        counters = self._get_io_counters()
        
        if self.initial_counters:
            delta_read = counters.read_count - self.initial_counters.read_count
            delta_write = counters.write_count - self.initial_counters.write_count
            delta_read_bytes = counters.read_bytes - self.initial_counters.read_bytes
            delta_write_bytes = counters.write_bytes - self.initial_counters.write_bytes
        else:
            delta_read = delta_write = delta_read_bytes = delta_write_bytes = 0
        
        return {
            'read_count': counters.read_count,
            'write_count': counters.write_count,
            'read_bytes': counters.read_bytes,
            'write_bytes': counters.write_bytes,
            'delta_reads': delta_read,
            'delta_writes': delta_write,
            'delta_read_bytes': delta_read_bytes,
            'delta_write_bytes': delta_write_bytes
        }
    
    def _get_io_counters(self) -> IOCounter:
        """获取I/O计数器"""
        try:
            io_counters = psutil.disk_io_counters()
            if io_counters:
                return IOCounter(
                    read_count=io_counters.read_count,
                    write_count=io_counters.write_count,
                    read_bytes=io_counters.read_bytes,
                    write_bytes=io_counters.write_bytes
                )
        except Exception:
            pass
        
        return IOCounter()
    
    def _monitor_io(self):
        """监控I/O使用"""
        while self.is_running:
            try:
                sample = self.get_current_stats()
                sample['timestamp'] = time.time()
                self.io_samples.append(sample)
                
                time.sleep(0.5)  # 每0.5秒采样一次
                
            except Exception as e:
                print(f"IO monitoring error: {e}")
                break
    
    def _calculate_io_stats(self) -> Dict[str, Any]:
        """计算I/O统计信息"""
        if not self.initial_counters or not self.final_counters:
            return {}
        
        # 计算增量
        delta_read = self.final_counters.read_count - self.initial_counters.read_count
        delta_write = self.final_counters.write_count - self.initial_counters.write_count
        delta_read_bytes = self.final_counters.read_bytes - self.initial_counters.read_bytes
        delta_write_bytes = self.final_counters.write_bytes - self.initial_counters.write_bytes
        
        duration = self.final_counters.write_time - self.initial_counters.write_time if hasattr(self.final_counters, 'write_time') else 0
        
        # 计算平均I/O大小
        avg_read_size = delta_read_bytes / delta_read if delta_read > 0 else 0
        avg_write_size = delta_write_bytes / delta_write if delta_write > 0 else 0
        
        # 计算吞吐量
        total_duration = (self.final_counters.write_time - self.initial_counters.write_time) if hasattr(self.final_counters, 'write_time') else 1
        read_throughput = delta_read_bytes / total_duration if total_duration > 0 else 0
        write_throughput = delta_write_bytes / total_duration if total_duration > 0 else 0
        
        return {
            'total_operations': {
                'reads': delta_read,
                'writes': delta_write,
                'total': delta_read + delta_write
            },
            'total_bytes': {
                'read': delta_read_bytes,
                'written': delta_write_bytes,
                'total': delta_read_bytes + delta_write_bytes
            },
            'average_operation_size': {
                'read': avg_read_size,
                'write': avg_write_size
            },
            'throughput': {
                'read_bps': read_throughput,
                'write_bps': write_throughput,
                'total_bps': read_throughput + write_throughput
            },
            'io_patterns': self._analyze_io_patterns()
        }
    
    def _analyze_io_patterns(self) -> Dict[str, Any]:
        """分析I/O模式"""
        if len(self.io_samples) < 2:
            return {'pattern': 'insufficient_data'}
        
        # 计算I/O活动的时间分布
        active_samples = [s for s in self.io_samples 
                         if s.get('delta_reads', 0) > 0 or s.get('delta_writes', 0) > 0]
        
        activity_rate = len(active_samples) / len(self.io_samples)
        
        # 分析突发性
        if len(active_samples) > 1:
            intervals = [active_samples[i]['timestamp'] - active_samples[i-1]['timestamp'] 
                        for i in range(1, len(active_samples))]
            avg_interval = statistics.mean(intervals)
            interval_std = statistics.stdev(intervals) if len(intervals) > 1 else 0
            burst_ratio = interval_std / avg_interval if avg_interval > 0 else 0
        else:
            burst_ratio = 0
        
        return {
            'activity_rate': activity_rate,
            'burst_ratio': burst_ratio,
            'pattern': 'bursty' if burst_ratio > 2.0 else 'steady' if burst_ratio < 0.5 else 'mixed'
        }

class WallTimeProfiler(BaseProfiler):
    """壁钟时间分析器"""
    
    def __init__(self):
        super().__init__("wall_time_profiler")
        self.function_times = defaultdict(list)
        self.start_timestamp = 0.0
        self.call_stack = []
    
    def start_profiling(self):
        """开始壁钟时间分析"""
        if self.is_running:
            return
        
        self.is_running = True
        self.start_timestamp = time.time()
    
    def stop_profiling(self) -> ProfilingResult:
        """停止壁钟时间分析"""
        if not self.is_running:
            raise RuntimeError("Wall time profiler is not running")
        
        self.is_running = False
        
        end_timestamp = time.time()
        duration = end_timestamp - self.start_timestamp
        
        # 分析函数执行时间
        wall_time_data = self._analyze_function_times()
        
        result = ProfilingResult(
            profiling_type=ProfilingType.WALL_TIME_PROFILING,
            start_time=self.start_timestamp,
            end_time=end_timestamp,
            duration=duration,
            data=wall_time_data,
            metadata={
                'function_count': len(self.function_times)
            }
        )
        
        self.results.append(result)
        return result
    
    def get_current_stats(self) -> Dict[str, Any]:
        """获取当前统计"""
        return {
            'active_functions': len(self.call_stack),
            'profiling_duration': time.time() - self.start_timestamp,
            'functions_tracked': len(self.function_times)
        }
    
    def _analyze_function_times(self) -> Dict[str, Any]:
        """分析函数执行时间"""
        function_stats = []
        
        for func_name, times in self.function_times.items():
            total_time = sum(times)
            avg_time = total_time / len(times)
            min_time = min(times)
            max_time = max(times)
            
            function_stats.append({
                'function': func_name,
                'call_count': len(times),
                'total_time': total_time,
                'avg_time': avg_time,
                'min_time': min_time,
                'max_time': max_time,
                'time_percentage': 0  # 将在后续计算中填入
            })
        
        # 计算时间百分比
        total_tracked_time = sum(stat['total_time'] for stat in function_stats)
        for stat in function_stats:
            stat['time_percentage'] = (stat['total_time'] / total_tracked_time * 100) if total_tracked_time > 0 else 0
        
        # 按总时间排序
        function_stats.sort(key=lambda x: x['total_time'], reverse=True)
        
        return {
            'function_stats': function_stats,
            'total_tracked_time': total_tracked_time,
            'tracked_percentage': total_tracked_time / (time.time() - self.start_timestamp) * 100 if self.start_timestamp > 0 else 0
        }

class LineProfiler:
    """行级性能分析器"""
    
    def __init__(self):
        self.line_stats = defaultdict(list)
        self.is_running = False
        self.start_time = 0.0
    
    def start_profiling(self):
        """开始行级分析"""
        self.is_running = True
        self.start_time = time.time()
        sys.settrace(self._trace_function)
    
    def stop_profiling(self):
        """停止行级分析"""
        self.is_running = False
        sys.settrace(None)
    
    def _trace_function(self, frame, event, arg):
        """跟踪函数调用"""
        if not self.is_running:
            return
        
        if event == 'line':
            filename = frame.f_code.co_filename
            function_name = frame.f_code.co_name
            line_number = frame.f_lineno
            
            # 记录行执行信息
            line_key = f"{filename}:{function_name}:{line_number}"
            self.line_stats[line_key].append(time.time())
        
        return self._trace_function
    
    def get_line_stats(self) -> Dict[str, Any]:
        """获取行级统计"""
        line_stats_data = {}
        
        for line_key, timestamps in self.line_stats.items():
            if len(timestamps) > 1:
                intervals = [timestamps[i] - timestamps[i-1] for i in range(1, len(timestamps))]
                line_stats_data[line_key] = {
                    'execution_count': len(timestamps),
                    'total_time': timestamps[-1] - timestamps[0],
                    'avg_interval': statistics.mean(intervals),
                    'min_interval': min(intervals),
                    'max_interval': max(intervals)
                }
        
        return line_stats_data
```

## 2. 性能分析框架

### 性能监控系统
```python
import asyncio
from typing import Dict, List, Callable, Any
from collections import defaultdict, deque
import json
import threading
from datetime import datetime, timedelta
import logging

class PerformanceMonitor:
    """性能监控器"""
    
    def __init__(self, name: str, buffer_size: int = 1000):
        self.name = name
        self.buffer_size = buffer_size
        self.metrics_buffer = deque(maxlen=buffer_size)
        self.alert_thresholds = {}
        self.alert_callbacks = {}
        self.is_monitoring = False
        self.monitor_thread = None
        self.lock = threading.Lock()
    
    def add_metric(self, metric_name: str, value: float, tags: Dict[str, str] = None):
        """添加性能指标"""
        with self.lock:
            metric = {
                'name': metric_name,
                'value': value,
                'tags': tags or {},
                'timestamp': time.time(),
                'datetime': datetime.now().isoformat()
            }
            self.metrics_buffer.append(metric)
    
    def set_alert_threshold(self, metric_name: str, threshold_type: str, 
                          threshold_value: float, callback: Callable = None):
        """设置告警阈值"""
        self.alert_thresholds[metric_name] = {
            'type': threshold_type,  # 'greater_than', 'less_than', 'equals'
            'value': threshold_value
        }
        
        if callback:
            self.alert_callbacks[metric_name] = callback
    
    def start_monitoring(self, interval: float = 1.0):
        """开始监控"""
        if self.is_monitoring:
            return
        
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(
            target=self._monitor_loop, 
            args=(interval,), 
            daemon=True
        )
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """停止监控"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5.0)
    
    def _monitor_loop(self, interval: float):
        """监控循环"""
        while self.is_monitoring:
            try:
                self._check_alerts()
                time.sleep(interval)
            except Exception as e:
                print(f"Monitoring error: {e}")
    
    def _check_alerts(self):
        """检查告警"""
        with self.lock:
            if not self.metrics_buffer:
                return
            
            latest_metrics = self._get_latest_metrics()
        
        for metric_name, value in latest_metrics.items():
            if metric_name in self.alert_thresholds:
                threshold = self.alert_thresholds[metric_name]
                triggered = False
                
                if threshold['type'] == 'greater_than' and value > threshold['value']:
                    triggered = True
                elif threshold['type'] == 'less_than' and value < threshold['value']:
                    triggered = True
                elif threshold['type'] == 'equals' and abs(value - threshold['value']) < 0.001:
                    triggered = True
                
                if triggered:
                    self._trigger_alert(metric_name, value, threshold)
    
    def _trigger_alert(self, metric_name: str, value: float, threshold: Dict):
        """触发告警"""
        alert_info = {
            'metric': metric_name,
            'value': value,
            'threshold': threshold,
            'timestamp': time.time(),
            'datetime': datetime.now().isoformat()
        }
        
        if metric_name in self.alert_callbacks:
            try:
                self.alert_callbacks[metric_name](alert_info)
            except Exception as e:
                print(f"Alert callback error: {e}")
        
        logging.warning(f"Performance alert: {metric_name} = {value} (threshold: {threshold})")
    
    def _get_latest_metrics(self) -> Dict[str, float]:
        """获取最新的指标值"""
        latest_metrics = {}
        
        # 按指标名称分组，获取每个指标的最新值
        metric_groups = defaultdict(list)
        
        for metric in reversed(self.metrics_buffer):
            name = metric['name']
            if name not in latest_metrics:
                latest_metrics[name] = metric['value']
                metric_groups[name].append(metric)
        
        return latest_metrics
    
    def get_metrics_summary(self, duration_minutes: int = 60) -> Dict[str, Any]:
        """获取指标摘要"""
        cutoff_time = time.time() - (duration_minutes * 60)
        
        with self.lock:
            recent_metrics = [m for m in self.metrics_buffer if m['timestamp'] > cutoff_time]
        
        summary = defaultdict(lambda: {
            'count': 0,
            'sum': 0,
            'min': float('inf'),
            'max': float('-inf'),
            'values': []
        })
        
        for metric in recent_metrics:
            name = metric['name']
            value = metric['value']
            
            summary[name]['count'] += 1
            summary[name]['sum'] += value
            summary[name]['min'] = min(summary[name]['min'], value)
            summary[name]['max'] = max(summary[name]['max'], value)
            summary[name]['values'].append(value)
        
        # 计算统计数据
        for name, stats in summary.items():
            if stats['count'] > 0:
                stats['avg'] = stats['sum'] / stats['count']
                stats['count'] = len([v for v in stats['values']])
                
                if stats['count'] > 1:
                    sorted_values = sorted(stats['values'])
                    n = len(sorted_values)
                    stats['p50'] = sorted_values[int(n * 0.5)]
                    stats['p95'] = sorted_values[int(n * 0.95)]
                    stats['p99'] = sorted_values[int(n * 0.99)]
                
                del stats['values']  # 删除原始值列表
        
        return dict(summary)
    
    def export_metrics(self, output_file: str, duration_minutes: int = 60):
        """导出指标数据"""
        cutoff_time = time.time() - (duration_minutes * 60)
        
        with self.lock:
            export_data = {
                'monitor_name': self.name,
                'export_time': datetime.now().isoformat(),
                'duration_minutes': duration_minutes,
                'metrics': [
                    {
                        'name': m['name'],
                        'value': m['value'],
                        'tags': m['tags'],
                        'timestamp': m['timestamp'],
                        'datetime': m['datetime']
                    }
                    for m in self.metrics_buffer
                    if m['timestamp'] > cutoff_time
                ],
                'summary': self.get_metrics_summary(duration_minutes)
            }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, indent=2, ensure_ascii=False)

class ComprehensiveProfiler:
    """综合性能分析器"""
    
    def __init__(self, name: str = "comprehensive_profiler"):
        self.name = name
        self.cpu_profiler = CPUProfiler()
        self.memory_profiler = MemoryProfiler()
        self.io_profiler = IOProfiler()
        self.wall_time_profiler = WallTimeProfiler()
        self.line_profiler = LineProfiler()
        self.monitor = PerformanceMonitor(f"{name}_monitor")
        self.results = []
        self.is_running = False
    
    def start_profiling(self, profiling_types: List[ProfilingType] = None):
        """开始性能分析"""
        if self.is_running:
            return
        
        if profiling_types is None:
            profiling_types = list(ProfilingType)
        
        self.is_running = True
        
        # 启动各种分析器
        if ProfilingType.CPU_PROFILING in profiling_types:
            self.cpu_profiler.start_profiling()
        
        if ProfilingType.MEMORY_PROFILING in profiling_types:
            self.memory_profiler.start_profiling()
        
        if ProfilingType.IO_PROFILING in profiling_types:
            self.io_profiler.start_profiling()
        
        if ProfilingType.WALL_TIME_PROFILING in profiling_types:
            self.wall_time_profiler.start_profiling()
        
        if ProfilingType.LINE_PROFILING in profiling_types:
            self.line_profiler.start_profiling()
        
        # 启动监控
        self.monitor.start_monitoring(interval=1.0)
    
    def stop_profiling(self) -> Dict[str, ProfilingResult]:
        """停止性能分析"""
        if not self.is_running:
            raise RuntimeError("Profiler is not running")
        
        self.is_running = False
        
        results = {}
        
        # 停止各种分析器
        if ProfilingType.CPU_PROFILING in [p.profiling_type for p in self.cpu_profiler.results] or \
           any(p.profiling_type == ProfilingType.CPU_PROFILING for p in self.results):
            try:
                results['cpu'] = self.cpu_profiler.stop_profiling()
            except:
                pass
        
        if ProfilingType.MEMORY_PROFILING in [p.profiling_type for p in self.memory_profiler.results] or \
           any(p.profiling_type == ProfilingType.MEMORY_PROFILING for p in self.results):
            try:
                results['memory'] = self.memory_profiler.stop_profiling()
            except:
                pass
        
        if ProfilingType.IO_PROFILING in [p.profiling_type for p in self.io_profiler.results] or \
           any(p.profiling_type == ProfilingType.IO_PROFILING for p in self.results):
            try:
                results['io'] = self.io_profiler.stop_profiling()
            except:
                pass
        
        if ProfilingType.WALL_TIME_PROFILING in [p.profiling_type for p in self.wall_time_profiler.results] or \
           any(p.profiling_type == ProfilingType.WALL_TIME_PROFILING for p in self.results):
            try:
                results['wall_time'] = self.wall_time_profiler.stop_profiling()
            except:
                pass
        
        if ProfilingType.LINE_PROFILING in []:  # LineProfiler doesn't follow the same pattern
            self.line_profiler.stop_profiling()
            results['line_profiling'] = ProfilingResult(
                profiling_type=ProfilingType.LINE_PROFILING,
                start_time=0,
                end_time=time.time(),
                duration=0,
                data=self.line_profiler.get_line_stats()
            )
        
        # 停止监控
        self.monitor.stop_monitoring()
        
        self.results.extend(results.values())
        return results
    
    @contextmanager
    def profile_context(self, profiling_types: List[ProfilingType] = None):
        """性能分析上下文管理器"""
        self.start_profiling(profiling_types)
        try:
            yield self
        finally:
            self.stop_profiling()
    
    def add_custom_metric(self, name: str, value: float, tags: Dict[str, str] = None):
        """添加自定义指标"""
        self.monitor.add_metric(name, value, tags)
    
    def get_comprehensive_report(self) -> Dict[str, Any]:
        """生成综合报告"""
        report = {
            'profiler_name': self.name,
            'timestamp': datetime.now().isoformat(),
            'total_results': len(self.results),
            'profiling_types': [result.profiling_type.value for result in self.results],
            'monitor_summary': self.monitor.get_metrics_summary(),
            'detailed_results': {}
        }
        
        for result in self.results:
            report['detailed_results'][result.profiling_type.value] = {
                'duration': result.duration,
                'start_time': result.start_time,
                'end_time': result.end_time,
                'data': result.data,
                'metadata': result.metadata
            }
        
        return report

class PerformanceAnalyzer:
    """性能分析器"""
    
    def __init__(self):
        self.analyzers = {
            'cpu': self._analyze_cpu_performance,
            'memory': self._analyze_memory_performance,
            'io': self._analyze_io_performance,
            'wall_time': self._analyze_wall_time_performance
        }
    
    def analyze_profiling_results(self, results: Dict[str, ProfilingResult]) -> Dict[str, Any]:
        """分析性能分析结果"""
        analysis = {
            'performance_summary': {},
            'bottlenecks': [],
            'recommendations': [],
            'detailed_analysis': {}
        }
        
        for profiler_name, result in results.items():
            if profiler_name in self.analyzers:
                profiler_analysis = self.analyzers[profiler_name](result)
                analysis['detailed_analysis'][profiler_name] = profiler_analysis
                
                # 更新总体摘要
                for key, value in profiler_analysis.get('summary', {}).items():
                    analysis['performance_summary'][f"{profiler_name}_{key}"] = value
                
                # 添加瓶颈
                analysis['bottlenecks'].extend(profiler_analysis.get('bottlenecks', []))
                
                # 添加建议
                analysis['recommendations'].extend(profiler_analysis.get('recommendations', []))
        
        return analysis
    
    def _analyze_cpu_performance(self, result: ProfilingResult) -> Dict[str, Any]:
        """分析CPU性能"""
        functions = result.data.get('top_functions', [])
        
        # 识别CPU密集型函数
        cpu_intensive_functions = [
            func for func in functions 
            if func.get('cumulative_time', 0) > 0.1  # 超过100ms的函数
        ]
        
        return {
            'summary': {
                'total_cpu_time': sum(func.get('cumulative_time', 0) for func in functions),
                'cpu_intensive_functions': len(cpu_intensive_functions),
                'top_function': functions[0] if functions else None
            },
            'bottlenecks': [
                {
                    'type': 'cpu_intensive_function',
                    'function': func.get('function'),
                    'cumulative_time': func.get('cumulative_time'),
                    'severity': 'high' if func.get('cumulative_time', 0) > 1.0 else 'medium'
                }
                for func in cpu_intensive_functions
            ],
            'recommendations': [
                f"Optimize CPU-intensive function: {func.get('function')}" 
                for func in cpu_intensive_functions[:5]  # 前5个
            ]
        }
    
    def _analyze_memory_performance(self, result: ProfilingResult) -> Dict[str, Any]:
        """分析内存性能"""
        memory_data = result.data
        
        # 识别内存问题
        memory_issues = []
        
        if memory_data.get('memory_growth', 0) > 1000000:  # 增长超过1MB
            memory_issues.append({
                'type': 'memory_growth',
                'severity': 'high' if memory_data['memory_growth'] > 10000000 else 'medium',
                'description': f"Memory growth detected: {memory_data['memory_growth']} bytes"
            })
        
        if memory_data.get('peak_memory', 0) > 500000000:  # 峰值超过500MB
            memory_issues.append({
                'type': 'high_memory_usage',
                'severity': 'high',
                'description': f"High memory usage: {memory_data['peak_memory']} bytes"
            })
        
        return {
            'summary': {
                'initial_memory': memory_data.get('initial_memory'),
                'final_memory': memory_data.get('final_memory'),
                'peak_memory': memory_data.get('peak_memory'),
                'memory_growth': memory_data.get('memory_growth'),
                'memory_trend': memory_data.get('memory_trend')
            },
            'bottlenecks': memory_issues,
            'recommendations': [
                "Consider implementing memory pooling for frequently allocated objects",
                "Profile for memory leaks using tracemalloc",
                "Optimize data structures to reduce memory footprint"
            ]
        }
    
    def _analyze_io_performance(self, result: ProfilingResult) -> Dict[str, Any]:
        """分析I/O性能"""
        io_data = result.data
        
        # 识别I/O瓶颈
        io_bottlenecks = []
        
        total_ops = io_data.get('total_operations', {}).get('total', 0)
        if total_ops > 10000:  # I/O操作过多
            io_bottlenecks.append({
                'type': 'high_io_operations',
                'severity': 'medium',
                'description': f"High number of I/O operations: {total_ops}"
            })
        
        throughput = io_data.get('throughput', {}).get('total_bps', 0)
        if throughput > 100000000:  # 吞吐量超过100MB/s
            io_bottlenecks.append({
                'type': 'high_io_throughput',
                'severity': 'low',
                'description': f"High I/O throughput: {throughput} bytes/s"
            })
        
        pattern = io_data.get('io_patterns', {}).get('pattern')
        if pattern == 'bursty':
            io_bottlenecks.append({
                'type': 'bursty_io_pattern',
                'severity': 'medium',
                'description': "Bursty I/O pattern detected, consider I/O smoothing"
            })
        
        return {
            'summary': {
                'total_operations': total_ops,
                'total_bytes': io_data.get('total_bytes', {}).get('total'),
                'throughput_bps': throughput,
                'io_pattern': pattern
            },
            'bottlenecks': io_bottlenecks,
            'recommendations': [
                "Implement I/O buffering to reduce disk operations",
                "Consider using asynchronous I/O for better throughput",
                "Profile I/O patterns to identify optimization opportunities"
            ]
        }
    
    def _analyze_wall_time_performance(self, result: ProfilingResult) -> Dict[str, Any]:
        """分析壁钟时间性能"""
        wall_time_data = result.data
        functions = wall_time_data.get('function_stats', [])
        
        # 识别执行时间最长的函数
        slow_functions = [
            func for func in functions
            if func.get('avg_time', 0) > 0.1  # 平均执行时间超过100ms
        ]
        
        return {
            'summary': {
                'tracked_functions': len(functions),
                'total_tracked_time': wall_time_data.get('total_tracked_time'),
                'tracked_percentage': wall_time_data.get('tracked_percentage'),
                'slow_functions_count': len(slow_functions)
            },
            'bottlenecks': [
                {
                    'type': 'slow_function',
                    'function': func.get('function'),
                    'avg_time': func.get('avg_time'),
                    'severity': 'high' if func.get('avg_time', 0) > 1.0 else 'medium'
                }
                for func in slow_functions
            ],
            'recommendations': [
                f"Optimize function execution time: {func.get('function')}"
                for func in slow_functions[:5]
            ] + [
                "Consider algorithmic optimizations for slow functions",
                "Profile function call chains to identify optimization points",
                "Implement caching for expensive function calls"
            ]
        }

@contextmanager
def profile_performance(profiler_name: str = "default", 
                       profiling_types: List[ProfilingType] = None,
                       save_results: bool = True):
    """性能分析上下文管理器"""
    profiler = ComprehensiveProfiler(profiler_name)
    
    try:
        profiler.start_profiling(profiling_types)
        yield profiler
    finally:
        results = profiler.stop_profiling()
        
        if save_results and results:
            analyzer = PerformanceAnalyzer()
            analysis = analyzer.analyze_profiling_results(results)
            
            # 保存分析结果
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # 保存原始结果
            with open(f"{profiler_name}_results_{timestamp}.json", 'w') as f:
                json.dump({k: v.data for k, v in results.items()}, f, indent=2, default=str)
            
            # 保存分析报告
            with open(f"{profiler_name}_analysis_{timestamp}.json", 'w') as f:
                json.dump(analysis, f, indent=2, default=str)
            
            print(f"Performance analysis completed. Results saved to {profiler_name}_*_{timestamp}.json")
```

## 3. 性能优化策略

### 代码优化
```python
import functools
import threading
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import asyncio

class PerformanceOptimizer:
    """性能优化器"""
    
    def __init__(self):
        self.optimization_strategies = {
            'memoization': self._optimize_with_memoization,
            'caching': self._optimize_with_caching,
            'parallelization': self._optimize_with_parallelization,
            'lazy_loading': self._optimize_with_lazy_loading,
            'batch_processing': self._optimize_with_batch_processing
        }
    
    def optimize_function(self, func: Callable, strategy: str, **kwargs) -> Callable:
        """优化函数"""
        if strategy not in self.optimization_strategies:
            raise ValueError(f"Unknown optimization strategy: {strategy}")
        
        return self.optimization_strategies[strategy](func, **kwargs)
    
    def _optimize_with_memoization(self, func: Callable, max_size: int = 128) -> Callable:
        """使用记忆化优化"""
        @functools.lru_cache(maxsize=max_size)
        def cached_func(*args, **kwargs):
            return func(*args, **kwargs)
        
        return cached_func
    
    def _optimize_with_caching(self, func: Callable, cache_ttl: int = 300) -> Callable:
        """使用缓存优化"""
        cache = {}
        cache_timestamps = {}
        lock = threading.Lock()
        
        @functools.wraps(func)
        def cached_func(*args, **kwargs):
            # 创建缓存键
            cache_key = str(args) + str(sorted(kwargs.items()))
            
            with lock:
                # 检查缓存
                if cache_key in cache:
                    # 检查TTL
                    if time.time() - cache_timestamps[cache_key] < cache_ttl:
                        return cache[cache_key]
                    else:
                        # 缓存过期，删除
                        del cache[cache_key]
                        del cache_timestamps[cache_key]
                
                # 执行函数
                result = func(*args, **kwargs)
                
                # 缓存结果
                cache[cache_key] = result
                cache_timestamps[cache_key] = time.time()
                
                return result
        
        return cached_func
    
    def _optimize_with_parallelization(self, func: Callable, 
                                     max_workers: int = None,
                                     use_multiprocessing: bool = False) -> Callable:
        """使用并行化优化"""
        executor_class = ProcessPoolExecutor if use_multiprocessing else ThreadPoolExecutor
        executor = executor_class(max_workers=max_workers)
        
        @functools.wraps(func)
        def parallel_func(*args, **kwargs):
            # 对于可并行化的操作，这里只是一个示例
            # 实际使用时需要根据具体场景调整
            if len(args) > 0 and hasattr(args[0], '__iter__'):
                # 如果第一个参数是可迭代的，并行处理
                items = list(args[0])
                remaining_args = args[1:]
                
                futures = []
                for item in items:
                    future = executor.submit(func, item, *remaining_args, **kwargs)
                    futures.append(future)
                
                results = []
                for future in futures:
                    results.append(future.result())
                
                return results
            else:
                # 单个任务，直接执行
                return func(*args, **kwargs)
        
        return parallel_func
    
    def _optimize_with_lazy_loading(self, func: Callable) -> Callable:
        """使用懒加载优化"""
        class LazyWrapper:
            def __init__(self, func, *args, **kwargs):
                self.func = func
                self.args = args
                self.kwargs = kwargs
                self._result = None
                self._computed = False
            
            def __call__(self, *args, **kwargs):
                if not self._computed:
                    self._result = self.func(*self.args, **{**self.kwargs, **kwargs})
                    self._computed = True
                return self._result
            
            def __getattr__(self, name):
                if not self._computed:
                    self._result = self.func(*self.args, **self.kwargs)
                    self._computed = True
                return getattr(self._result, name)
        
        return LazyWrapper
    
    def _optimize_with_batch_processing(self, func: Callable, batch_size: int = 100) -> Callable:
        """使用批处理优化"""
        batch_buffer = []
        batch_lock = threading.Lock()
        batch_results = {}
        
        def flush_batch():
            nonlocal batch_buffer
            if not batch_buffer:
                return
            
            batch_items = batch_buffer[:]
            batch_buffer.clear()
            
            # 批量处理
            for i, (args, kwargs, result_future) in enumerate(batch_items):
                try:
                    result = func(*args, **kwargs)
                    batch_results[id(result_future)] = result
                except Exception as e:
                    batch_results[id(result_future)] = e
        
        @functools.wraps(func)
        def batch_func(*args, **kwargs):
            # 在实际实现中，需要一个更复杂的机制来管理future
            # 这里简化处理
            result = func(*args, **kwargs)
            
            # 定期刷新批处理缓冲区
            with batch_lock:
                batch_buffer.append((args, kwargs, None))
                
                if len(batch_buffer) >= batch_size:
                    flush_batch()
            
            return result
        
        # 添加刷新方法
        batch_func.flush = flush_batch
        return batch_func

class AsyncPerformanceOptimizer:
    """异步性能优化器"""
    
    def __init__(self):
        self.optimization_strategies = {
            'async_memoization': self._optimize_async_memoization,
            'async_caching': self._optimize_async_caching,
            'async_batch': self._optimize_async_batch
        }
    
    async def optimize_async_function(self, func: Callable, strategy: str, **kwargs) -> Callable:
        """优化异步函数"""
        if strategy not in self.optimization_strategies:
            raise ValueError(f"Unknown optimization strategy: {strategy}")
        
        return self.optimization_strategies[strategy](func, **kwargs)
    
    def _optimize_async_memoization(self, func: Callable, max_size: int = 128) -> Callable:
        """异步记忆化"""
        cache = {}
        cache_timestamps = {}
        cache_lock = asyncio.Lock()
        
        @functools.wraps(func)
        async def cached_func(*args, **kwargs):
            cache_key = str(args) + str(sorted(kwargs.items()))
            
            async with cache_lock:
                if cache_key in cache:
                    return cache[cache_key]
                
                result = await func(*args, **kwargs)
                cache[cache_key] = result
                
                # 简单的LRU eviction
                if len(cache) > max_size:
                    oldest_key = next(iter(cache))
                    del cache[oldest_key]
                
                return result
        
        return cached_func
    
    def _optimize_async_caching(self, func: Callable, cache_ttl: int = 300) -> Callable:
        """异步缓存"""
        cache = {}
        cache_timestamps = {}
        cache_lock = asyncio.Lock()
        
        @functools.wraps(func)
        async def cached_func(*args, **kwargs):
            cache_key = str(args) + str(sorted(kwargs.items()))
            
            async with cache_lock:
                if cache_key in cache:
                    if time.time() - cache_timestamps[cache_key] < cache_ttl:
                        return cache[cache_key]
                    else:
                        del cache[cache_key]
                        del cache_timestamps[cache_key]
                
                result = await func(*args, **kwargs)
                cache[cache_key] = result
                cache_timestamps[cache_key] = time.time()
                
                return result
        
        return cached_func
    
    def _optimize_async_batch(self, func: Callable, batch_size: int = 50) -> Callable:
        """异步批处理"""
        batch_buffer = []
        batch_lock = asyncio.Lock()
        pending_tasks = []
        
        async def flush_batch():
            nonlocal batch_buffer, pending_tasks
            if not batch_buffer:
                return
            
            batch_items = batch_buffer[:]
            batch_buffer.clear()
            
            # 创建批处理任务
            tasks = []
            for args, kwargs in batch_items:
                task = asyncio.create_task(func(*args, **kwargs))
                tasks.append(task)
            
            # 等待所有任务完成
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # 这里简化处理，实际应用中需要更复杂的result路由
            return results
        
        @functools.wraps(func)
        async def batch_func(*args, **kwargs):
            async with batch_lock:
                batch_buffer.append((args, kwargs))
                
                if len(batch_buffer) >= batch_size:
                    await flush_batch()
            
            # 单个调用时直接执行
            return await func(*args, **kwargs)
        
        # 添加刷新方法
        batch_func.flush = flush_batch
        return batch_func

# 性能优化装饰器
def optimize_performance(strategy: str = 'memoization', **kwargs):
    """性能优化装饰器"""
    def decorator(func):
        if asyncio.iscoroutinefunction(func):
            # 异步函数优化
            optimizer = AsyncPerformanceOptimizer()
            return optimizer.optimize_async_function(func, strategy, **kwargs)
        else:
            # 同步函数优化
            optimizer = PerformanceOptimizer()
            return optimizer.optimize_function(func, strategy, **kwargs)
    
    return decorator

# 使用示例
if __name__ == "__main__":
    # 记忆化示例
    @optimize_performance(strategy='memoization', max_size=256)
    def fibonacci(n):
        if n <= 1:
            return n
        return fibonacci(n-1) + fibonacci(n-2)
    
    # 缓存示例
    @optimize_performance(strategy='caching', cache_ttl=600)
    def expensive_computation(x, y):
        time.sleep(0.1)  # 模拟昂贵计算
        return x ** y + y ** x
    
    # 并行化示例
    @optimize_performance(strategy='parallelization', max_workers=4)
    def process_items(items):
        return [item * 2 for item in items]
    
    # 测试性能优化效果
    with profile_performance("optimization_test"):
        # 测试记忆化
        start_time = time.time()
        result1 = fibonacci(30)
        time1 = time.time() - start_time
        
        start_time = time.time()
        result2 = fibonacci(30)  # 应该从缓存中获取
        time2 = time.time() - start_time
        
        print(f"Fibonacci(30) - First call: {time1:.4f}s, Result: {result1}")
        print(f"Fibonacci(30) - Cached call: {time2:.4f}s, Result: {result2}")
        print(f"Speedup: {time1/time2:.2f}x")
```

通过以上性能分析与优化框架，可以系统性地识别系统瓶颈、实施优化策略，并持续监控性能改进效果。这些工具和方法为性能工程提供了完整的解决方案。