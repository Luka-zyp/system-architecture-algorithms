# Consistent Hashing 负载均衡算法详解

## 目录
1. [算法概述](#算法概述)
2. [算法原理](#算法原理)
3. [Python实现](#python实现)
4. [Go语言实现](#go-language实现)
5. [虚拟节点机制](#虚拟节点机制)
6. [哈希环管理](#哈希环管理)
7. [数据分片策略](#数据分片策略)
8. [性能分析](#性能分析)
9. [适用场景](#适用场景)
10. [故障处理](#故障处理)
11. [监控指标](#监控指标)
12. [实战案例](#实战案例)

## 算法概述

### 什么是Consistent Hashing

Consistent Hashing（一致性哈希）是分布式系统中广泛使用的负载均衡和数据分片算法。它通过将服务器映射到哈希环上，实现了最小化重新映射和数据迁移的负载均衡，特别适合动态添加或删除节点的场景。

### 核心特性

```python
from typing import List, Dict, Optional, Any, Tuple, Callable, Union
from dataclasses import dataclass, field
from enum import Enum
import time
import threading
import hashlib
import bisect
import random
import statistics
import json
import logging
from collections import defaultdict, deque
from concurrent.futures import ThreadPoolExecutor, as_completed
import copy
from abc import ABC, abstractmethod
import ipaddress
import zlib

@dataclass
class VirtualNode:
    """虚拟节点"""
    virtual_id: str
    physical_server_id: str
    position: float
    weight: float = 1.0
    
    # 状态信息
    is_healthy: bool = True
    load: float = 0.0
    request_count: int = 0
    last_accessed: float = field(default_factory=time.time)
    
    def update_load(self, request_load: float = 1.0):
        """更新负载"""
        self.load += request_load
        self.request_count += 1
        self.last_accessed = time.time()
    
    def reset_load(self):
        """重置负载"""
        self.load = 0.0

@dataclass
class PhysicalServer:
    """物理服务器"""
    id: str
    hostname: str
    port: int
    capacity: float = 1000.0
    
    # 虚拟节点管理
    virtual_nodes: List[VirtualNode] = field(default_factory=list)
    
    # 性能指标
    cpu_usage: float = 0.0
    memory_usage: float = 0.0
    disk_usage: float = 0.0
    network_io: float = 0.0
    
    # 统计信息
    total_requests: int = 0
    total_data_processed: float = 0.0
    avg_response_time: float = 0.0
    response_times: deque = field(default_factory=lambda: deque(maxlen=100))
    
    # 健康状态
    is_healthy: bool = True
    last_health_check: float = field(default_factory=time.time)
    failure_count: int = 0
    
    def get_capacity_utilization(self) -> float:
        """获取容量利用率"""
        utilization = self.total_requests / self.capacity if self.capacity > 0 else 0
        return min(1.0, utilization)
    
    def get_performance_score(self) -> float:
        """获取性能分数"""
        # 基于响应时间和资源利用率计算性能分数
        response_factor = max(0.1, 1.0 - (self.avg_response_time / 2000.0))
        resource_factor = 1.0 - ((self.cpu_usage + self.memory_usage) / 2.0 / 100.0)
        utilization_penalty = self.get_capacity_utilization() * 0.3
        
        score = (response_factor * 0.4 + resource_factor * 0.4) * (1 - utilization_penalty)
        return max(0.1, score)
    
    def can_handle_request(self, request_size: float = 1.0) -> bool:
        """检查是否可以处理请求"""
        return self.is_healthy and (self.get_capacity_utilization() + request_size / self.capacity) <= 1.0

class HashFunction(Enum):
    """哈希函数类型"""
    MD5 = "md5"
    SHA1 = "sha1"
    SHA256 = "sha256"
    MURMUR3 = "murmur3"
    FNV1A = "fnv1a"
    DJB2 = "djb2"

class ConsistentHashingStrategy(Enum):
    """一致性哈希策略"""
    BASIC_CONSISTENT_HASHING = "basic"
    WEIGHTED_CONSISTENT_HASHING = "weighted"
    KETAMA_CONSISTENT_HASHING = "ketama"
    JUMP_CONSISTENT_HASHING = "jump"

class ConsistentHashLoadBalancer:
    """一致性哈希负载均衡器"""
    
    def __init__(self, 
                 strategy: ConsistentHashingStrategy = ConsistentHashingStrategy.KETAMA_CONSISTENT_HASHING,
                 hash_function: HashFunction = HashFunction.MD5,
                 virtual_nodes_per_server: int = 150):
        
        self.strategy = strategy
        self.hash_function = hash_function
        self.virtual_nodes_per_server = virtual_nodes_per_server
        
        # 哈希环管理
        self.hash_ring: List[Tuple[float, VirtualNode]] = []  # (position, virtual_node)
        self.position_to_vnode: Dict[float, VirtualNode] = {}
        
        # 服务器管理
        self.servers: Dict[str, PhysicalServer] = {}
        self.server_positions: Dict[str, List[float]] = defaultdict(list)
        
        # 状态管理
        self.mutex = threading.RLock()
        self.ring_version = 0
        
        # 性能统计
        self.metrics = {
            "total_requests": 0,
            "cache_hits": 0,
            "ring_rebuilds": 0,
            "virtual_node_count": 0,
            "average_lookup_time": 0.0
        }
        
        # 设置日志
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger("ConsistentHash")
    
    def _calculate_hash(self, key: str) -> float:
        """计算哈希值"""
        if self.hash_function == HashFunction.MD5:
            hash_obj = hashlib.md5(key.encode('utf-8'))
        elif self.hash_function == HashFunction.SHA1:
            hash_obj = hashlib.sha1(key.encode('utf-8'))
        elif self.hash_function == HashFunction.SHA256:
            hash_obj = hashlib.sha256(key.encode('utf-8'))
        else:
            # 简单的自定义哈希
            hash_value = 0
            for char in key:
                if self.hash_function == HashFunction.DJB2:
                    hash_value = ((hash_value << 5) + hash_value) + ord(char)
                elif self.hash_function == HashFunction.FNV1A:
                    hash_value ^= ord(char)
                    hash_value *= 16777619
            return abs(hash_value) % (2**32)
        
        # 将哈希值转换为0-1之间的浮点数
        hash_hex = hash_obj.hexdigest()
        hash_int = int(hash_hex[:16], 16)  # 使用前16位
        return (hash_int % (2**31)) / (2**31)
    
    def _ketama_hash(self, key: str) -> float:
        """Ketama风格的哈希函数"""
        # Ketama使用MD5的多个字节组合
        hash_obj = hashlib.md5(key.encode('utf-8'))
        digest = hash_obj.digest()
        
        # 使用4个字节的组合
        hash_value = 0
        for i in range(0, 16, 4):
            hash_value = (hash_value << 8) | digest[i]
        
        return (hash_value % (2**31)) / (2**31)
    
    def _jump_hash(self, key: str, num_buckets: int) -> int:
        """Jump一致性哈希"""
        hash_value = self._calculate_hash(key) * 2**32
        
        int_hash = int(hash_value)
        if int_hash < 0:
            int_hash = -int_hash
        
        b = -1
        j = 0
        
        while j < num_buckets:
            b = j
            int_hash = int_hash * 1103515245 + 12345
            j = int((b + 1) * (2**31 / ((int_hash & 0x7fffffff) + 1)))
        
        return b
    
    def add_server(self, server: PhysicalServer):
        """添加服务器"""
        with self.mutex:
            self.servers[server.id] = server
            
            # 为服务器创建虚拟节点
            if self.strategy == ConsistentHashingStrategy.KETAMA_CONSISTENT_HASHING:
                self._create_ketama_virtual_nodes(server)
            elif self.strategy == ConsistentHashingStrategy.WEIGHTED_CONSISTENT_HASHING:
                self._create_weighted_virtual_nodes(server)
            else:
                self._create_basic_virtual_nodes(server)
            
            # 重建哈希环
            self._rebuild_hash_ring()
            
            self.logger.info(f"Added server {server.hostname}:{server.port} with {len(server.virtual_nodes)} virtual nodes")
    
    def _create_basic_virtual_nodes(self, server: PhysicalServer):
        """创建基础虚拟节点"""
        for i in range(self.virtual_nodes_per_server):
            virtual_node_id = f"{server.id}_vn_{i}"
            key = f"{server.hostname}:{server.port}:{virtual_node_id}"
            
            if self.hash_function == HashFunction.MD5:
                position = self._ketama_hash(key)
            else:
                position = self._calculate_hash(key)
            
            virtual_node = VirtualNode(
                virtual_id=virtual_node_id,
                physical_server_id=server.id,
                position=position,
                weight=1.0
            )
            
            server.virtual_nodes.append(virtual_node)
    
    def _create_weighted_virtual_nodes(self, server: PhysicalServer):
        """创建加权虚拟节点"""
        # 基于服务器容量和性能计算虚拟节点数量
        performance_score = server.get_performance_score()
        capacity_factor = min(3.0, server.capacity / 1000.0)
        
        weighted_vnode_count = int(self.virtual_nodes_per_server * performance_score * capacity_factor)
        weighted_vnode_count = max(50, min(500, weighted_vnode_count))  # 限制范围
        
        for i in range(weighted_vnode_count):
            virtual_node_id = f"{server.id}_vn_{i}"
            key = f"{server.hostname}:{server.port}:{virtual_node_id}:{i}"
            
            position = self._ketama_hash(key)
            
            virtual_node = VirtualNode(
                virtual_id=virtual_node_id,
                physical_server_id=server.id,
                position=position,
                weight=performance_score * capacity_factor
            )
            
            server.virtual_nodes.append(virtual_node)
    
    def _create_ketama_virtual_nodes(self, server: PhysicalServer):
        """创建Ketama风格的虚拟节点"""
        # Ketama使用固定的虚拟节点数量(100-400)
        ketama_vnodes = self.virtual_nodes_per_server
        
        for i in range(ketama_vnodes):
            virtual_node_id = f"{server.id}_ketama_{i}"
            
            # Ketama使用多个字符串组合生成更均匀的分布
            keys_to_hash = [
                f"{server.hostname}:{server.port}:{virtual_node_id}",
                f"{server.id}:{virtual_node_id}:A",
                f"{server.id}:{virtual_node_id}:B"
            ]
            
            # 计算组合哈希
            positions = []
            for key in keys_to_hash:
                pos = self._ketama_hash(key)
                positions.append(pos)
            
            # 使用位置组合
            final_position = sum(positions) / len(positions)
            
            virtual_node = VirtualNode(
                virtual_id=virtual_node_id,
                physical_server_id=server.id,
                position=final_position,
                weight=1.0
            )
            
            server.virtual_nodes.append(virtual_node)
    
    def _rebuild_hash_ring(self):
        """重建哈希环"""
        self.hash_ring = []
        self.position_to_vnode = {}
        self.server_positions.clear()
        
        total_vnodes = 0
        
        for server in self.servers.values():
            for vnode in server.virtual_nodes:
                self.hash_ring.append((vnode.position, vnode))
                self.position_to_vnode[vnode.position] = vnode
                self.server_positions[server.id].append(vnode.position)
                total_vnodes += 1
        
        # 按位置排序
        self.hash_ring.sort(key=lambda x: x[0])
        
        self.ring_version += 1
        self.metrics["virtual_node_count"] = total_vnodes
        
        self.logger.info(f"Rebuilt hash ring with {total_vnodes} virtual nodes")
    
    def remove_server(self, server_id: str):
        """移除服务器"""
        with self.mutex:
            if server_id not in self.servers:
                return
            
            server = self.servers[server_id]
            
            # 清除虚拟节点
            for vnode in server.virtual_nodes:
                if vnode.position in self.position_to_vnode:
                    del self.position_to_vnode[vnode.position]
            
            # 移除服务器
            del self.servers[server_id]
            
            # 重建哈希环
            self._rebuild_hash_ring()
            
            self.logger.info(f"Removed server {server.hostname}")
    
    def get_server_for_key(self, key: str) -> Optional[PhysicalServer]:
        """根据key获取服务器"""
        with self.mutex:
            if not self.hash_ring:
                return None
            
            start_time = time.time()
            
            # 计算key的哈希位置
            if self.strategy == ConsistentHashingStrategy.JUMP_CONSISTENT_HASHING:
                server = self._get_server_jump_hash(key)
            else:
                key_position = self._calculate_hash(key)
                server = self._find_server_by_position(key_position)
            
            # 更新统计信息
            lookup_time = time.time() - start_time
            self._update_lookup_metrics(lookup_time)
            
            return server
    
    def _find_server_by_position(self, position: float) -> Optional[PhysicalServer]:
        """根据位置查找服务器"""
        if not self.hash_ring:
            return None
        
        # 找到第一个位置大于等于key_position的虚拟节点
        vnode = None
        for ring_position, virtual_node in self.hash_ring:
            if ring_position >= position:
                vnode = virtual_node
                break
        
        # 如果没找到，循环到第一个虚拟节点（哈希环的环特性）
        if vnode is None:
            vnode = self.hash_ring[0][1]
        
        # 检查物理服务器是否健康
        physical_server = self.servers.get(vnode.physical_server_id)
        if physical_server and physical_server.is_healthy:
            vnode.update_load()
            return physical_server
        
        # 如果选择的服务器不健康，尝试下一个
        return self._find_next_healthy_server(position, vnode.physical_server_id)
    
    def _find_next_healthy_server(self, position: float, excluded_server_id: str) -> Optional[PhysicalServer]:
        """查找下一个健康的服务器"""
        if not self.hash_ring:
            return None
        
        # 查找下一个健康服务器
        excluded_positions = set(self.server_positions.get(excluded_server_id, []))
        
        for ring_position, virtual_node in self.hash_ring:
            if ring_position > position and virtual_node.physical_server_id != excluded_server_id:
                physical_server = self.servers.get(virtual_node.physical_server_id)
                if physical_server and physical_server.is_healthy:
                    virtual_node.update_load()
                    return physical_server
        
        # 从头开始查找
        for ring_position, virtual_node in self.hash_ring:
            if virtual_node.physical_server_id != excluded_server_id:
                physical_server = self.servers.get(virtual_server_id)
                if physical_server and physical_server.is_healthy:
                    virtual_node.update_load()
                    return physical_server
        
        return None
    
    def _get_server_jump_hash(self, key: str) -> Optional[PhysicalServer]:
        """使用Jump哈希获取服务器"""
        healthy_servers = [server for server in self.servers.values() if server.is_healthy]
        
        if not healthy_servers:
            return None
        
        bucket = self._jump_hash(key, len(healthy_servers))
        return healthy_servers[bucket]
    
    def _update_lookup_metrics(self, lookup_time: float):
        """更新查找指标"""
        # 更新平均查找时间
        current_avg = self.metrics["average_lookup_time"]
        total_requests = self.metrics["total_requests"]
        
        if total_requests == 0:
            self.metrics["average_lookup_time"] = lookup_time
        else:
            self.metrics["average_lookup_time"] = (current_avg * total_requests + lookup_time) / (total_requests + 1)
        
        self.metrics["total_requests"] += 1
    
    def get_responsible_servers(self, key: str, count: int = 1) -> List[PhysicalServer]:
        """获取负责指定key的服务器列表"""
        with self.mutex:
            if not self.hash_ring or count <= 0:
                return []
            
            key_position = self._calculate_hash(key)
            responsible_servers = []
            visited_servers = set()
            
            # 找到第一个服务器
            current_position = key_position
            while len(responsible_servers) < count and len(visited_servers) < len(self.servers):
                server = self._find_server_by_position(current_position)
                
                if server and server.id not in visited_servers:
                    responsible_servers.append(server)
                    visited_servers.add(server.id)
                
                current_position += 0.001  # 移动到下一个位置
            
            return responsible_servers
    
    def redistribute_after_node_change(self, changed_server_id: str, operation: str) -> Dict[str, Any]:
        """节点变更后的重新分配"""
        with self.mutex:
            self.metrics["ring_rebuilds"] += 1
            
            if operation == "add":
                return self._simulate_add_server_redistribution(changed_server_id)
            else:  # remove
                return self._simulate_remove_server_redistribution(changed_server_id)
    
    def _simulate_add_server_redistribution(self, new_server_id: str) -> Dict[str, Any]:
        """模拟添加服务器的重新分配"""
        affected_keys = 0
        redistributed_keys = 0
        
        # 模拟key重新分配
        for i in range(1000):  # 采样1000个key
            key = f"sample_key_{i}"
            old_server = self.get_server_for_key_before_change(key, new_server_id)
            new_server = self.get_server_for_key(key)
            
            if old_server != new_server:
                redistributed_keys += 1
            
            affected_keys += 1
        
        redistribution_ratio = redistributed_keys / affected_keys if affected_keys > 0 else 0
        
        return {
            "operation": "add",
            "server_id": new_server_id,
            "affected_keys": affected_keys,
            "redistributed_keys": redistributed_keys,
            "redistribution_ratio": redistribution_ratio,
            "efficiency": max(0.0, 1.0 - redistribution_ratio)
        }
    
    def _simulate_remove_server_redistribution(self, removed_server_id: str) -> Dict[str, Any]:
        """模拟移除服务器的重新分配"""
        # 在移除前获取一些示例key
        sample_keys = [f"sample_key_{i}" for i in range(1000)]
        
        affected_keys = len(sample_keys)
        redistributed_keys = affected_keys  # 移除服务器后，所有相关key都需要重新分配
        
        return {
            "operation": "remove",
            "server_id": removed_server_id,
            "affected_keys": affected_keys,
            "redistributed_keys": redistributed_keys,
            "redistribution_ratio": 1.0,
            "efficiency": 0.0
        }
    
    def get_server_for_key_before_change(self, key: str, new_server_id: str) -> Optional[PhysicalServer]:
        """在变更前获取key对应的服务器"""
        # 临时移除新服务器，查找key对应的服务器
        original_servers = self.servers.copy()
        if new_server_id in self.servers:
            temp_server = self.servers[new_server_id]
            del self.servers[new_server_id]
            
            # 重建哈希环
            old_ring = self.hash_ring.copy()
            old_positions = self.position_to_vnode.copy()
            old_server_positions = copy.deepcopy(self.server_positions)
            
            self._rebuild_hash_ring()
            
            # 查找服务器
            server = self.get_server_for_key(key)
            
            # 恢复状态
            self.servers = original_servers
            self.hash_ring = old_ring
            self.position_to_vnode = old_positions
            self.server_positions = old_server_positions
            
            return server
        
        return self.get_server_for_key(key)
    
    def get_load_distribution(self) -> Dict[str, Any]:
        """获取负载分布"""
        with self.mutex:
            if not self.servers:
                return {}
            
            # 计算虚拟节点分布
            vnode_distribution = {}
            server_loads = {}
            
            for server_id, server in self.servers.items():
                vnode_distribution[server_id] = len(server.virtual_nodes)
                server_loads[server_id] = {
                    "virtual_nodes": len(server.virtual_nodes),
                    "requests": sum(vnode.request_count for vnode in server.virtual_nodes),
                    "load": sum(vnode.load for vnode in server.virtual_nodes),
                    "capacity_utilization": server.get_capacity_utilization(),
                    "performance_score": server.get_performance_score()
                }
            
            # 计算负载均衡质量
            loads = [info["requests"] for info in server_loads.values()]
            if len(loads) > 1:
                load_variance = statistics.variance(loads)
                load_std = statistics.stdev(loads)
                load_mean = statistics.mean(loads)
                coefficient_of_variation = load_std / load_mean if load_mean > 0 else 0
                balance_quality = max(0.0, 100.0 - (coefficient_of_variation * 100))
            else:
                balance_quality = 100.0
            
            return {
                "total_virtual_nodes": sum(vnode_distribution.values()),
                "virtual_node_distribution": vnode_distribution,
                "server_loads": server_loads,
                "balance_quality": balance_quality,
                "ring_version": self.ring_version,
                "metrics": self.metrics
            }
    
    def simulate_traffic(self, num_requests: int = 10000) -> Dict[str, Any]:
        """仿真流量"""
        print(f"Simulating {num_requests} requests...")
        
        start_time = time.time()
        request_distribution = defaultdict(int)
        response_times = defaultdict(list)
        cache_hit_rate = 0.0
        
        # 生成不同类型的key
        key_types = {
            "user_data": 0.4,    # 用户数据
            "session_data": 0.3, # 会话数据
            "cache_data": 0.2,   # 缓存数据
            "temp_data": 0.1     # 临时数据
        }
        
        for i in range(num_requests):
            # 根据权重选择key类型
            key_type = random.choices(
                list(key_types.keys()),
                weights=list(key_types.values())
            )[0]
            
            # 生成key
            if key_type == "user_data":
                key = f"user:{random.randint(1, 10000)}"
            elif key_type == "session_data":
                key = f"session:{random.randint(1, 5000)}:{random.randint(1, 100)}"
            elif key_type == "cache_data":
                key = f"cache:item:{random.randint(1, 20000)}"
            else:  # temp_data
                key = f"temp:{random.randint(1, 1000)}:{int(time.time() // 3600)}"
            
            # 获取服务器并处理请求
            server = self.get_server_for_key(key)
            
            if server:
                server_id = server.id
                request_distribution[server_id] += 1
                
                # 模拟响应时间
                response_time = random.uniform(0.1, 2.0) / server.get_performance_score()
                response_times[server_id].append(response_time)
                
                # 模拟缓存命中
                if random.random() < 0.7:  # 70%缓存命中率
                    cache_hit_rate += 1
            
            # 控制请求频率
            if i % 1000 == 0:
                time.sleep(0.01)  # 避免过载
        
        end_time = time.time()
        
        # 分析结果
        total_requests = sum(request_distribution.values())
        load_distribution = self.get_load_distribution()
        
        # 计算性能指标
        avg_response_time = statistics.mean([
            statistics.mean(times) for times in response_times.values() if times
        ]) if response_times else 0.0
        
        throughput = total_requests / (end_time - start_time)
        cache_hit_rate = (cache_hit_rate / total_requests * 100) if total_requests > 0 else 0.0
        
        return {
            "simulation_duration": end_time - start_time,
            "total_requests": total_requests,
            "requests_per_second": throughput,
            "cache_hit_rate": cache_hit_rate,
            "average_response_time": avg_response_time,
            "request_distribution": dict(request_distribution),
            "response_time_stats": {
                server: {
                    "avg": statistics.mean(times),
                    "min": min(times),
                    "max": max(times),
                    "count": len(times)
                } for server, times in response_times.items() if times
            },
            "load_distribution": load_distribution
        }

class GoStyleConsistentHash:
    """Go风格的一致性哈希实现"""
    
    def __init__(self, servers: List[Dict[str, Any]], virtual_nodes: int = 150):
        self.servers = servers
        self.virtual_nodes = virtual_nodes
        self.ring = []  # [(hash, server_id)]
        self.sorted_keys = []
        
        self._build_ring()
    
    def _hash(self, key: str) -> int:
        """哈希函数"""
        hash_obj = hashlib.md5(key.encode('utf-8'))
        return int(hash_obj.hexdigest(), 16)
    
    def _build_ring(self):
        """构建哈希环"""
        self.ring = []
        
        for server in self.servers:
            server_id = server["id"]
            for i in range(self.virtual_nodes):
                key = f"{server_id}:{i}"
                hash_value = self._hash(key)
                self.ring.append((hash_value, server_id))
        
        # 按哈希值排序
        self.ring.sort(key=lambda x: x[0])
        self.sorted_keys = [item[0] for item in self.ring]
    
    def Get(self, key: str) -> Optional[str]:
        """获取服务器（Go语言风格）"""
        if not self.ring:
            return None
        
        hash_value = self._hash(key)
        
        # 二分查找第一个大于等于hash_value的位置
        index = bisect.bisect_left(self.sorted_keys, hash_value)
        
        # 如果超出范围，循环到第一个
        if index == len(self.sorted_keys):
            index = 0
        
        return self.ring[index][1]
    
    def Add(self, server: Dict[str, Any]):
        """添加服务器"""
        server_id = server["id"]
        
        # 只添加新的虚拟节点，不重建整个环
        for i in range(self.virtual_nodes):
            key = f"{server_id}:{i}"
            hash_value = self._hash(key)
            bisect.insort(self.ring, (hash_value, server_id))
            bisect.insort(self.sorted_keys, hash_value)
    
    def Remove(self, server_id: str):
        """移除服务器"""
        # 移除该服务器的所有虚拟节点
        self.ring = [(hash_val, sid) for hash_val, sid in self.ring if sid != server_id]
        self.sorted_keys = [item[0] for item in self.ring]
    
    def GetN(self, key: str, n: int) -> List[str]:
        """获取前n个服务器"""
        if not self.ring or n <= 0:
            return []
        
        hash_value = self._hash(key)
        index = bisect.bisect_left(self.sorted_keys, hash_value)
        
        servers = []
        visited = set()
        current_index = index
        
        while len(servers) < n and len(visited) < len(set(sid for _, sid in self.ring)):
            if current_index >= len(self.sorted_keys):
                current_index = 0
            
            server_id = self.ring[current_index][1]
            
            if server_id not in visited:
                servers.append(server_id)
                visited.add(server_id)
            
            current_index += 1
        
        return servers

class ConsistentHashOptimization:
    """一致性哈希优化"""
    
    @staticmethod
    def optimize_virtual_nodes(server_count: int, target_distribution_error: float = 0.01) -> int:
        """优化虚拟节点数量"""
        # 基于服务器数量和目标分布误差计算最优虚拟节点数
        # 经验公式：vnodes = 100 + (server_count - 1) * 20
        optimal_vnodes = int(100 + (server_count - 1) * 20)
        
        # 确保在合理范围内
        return max(50, min(500, optimal_vnodes))
    
    @staticmethod
    def calculate_rebalancing_cost(server_count: int, vnodes_per_server: int) -> Dict[str, float]:
        """计算重新平衡成本"""
        total_vnodes = server_count * vnodes_per_server
        
        # 添加服务器的成本（需要重新分配）
        add_cost = (vnodes_per_server / total_vnodes) * 100
        
        # 移除服务器的成本
        remove_cost = (vnodes_per_server / total_vnodes) * 100
        
        # 迁移的数据量
        migration_data = (vnodes_per_server / total_vnodes) * 1000  # 假设1000个key
        
        return {
            "add_server_cost": add_cost,
            "remove_server_cost": remove_cost,
            "data_migration_percentage": migration_data,
            "total_virtual_nodes": total_vnodes
        }
    
    @staticmethod
    def analyze_distribution_uniformity(virtual_positions: List[float]) -> Dict[str, float]:
        """分析分布均匀性"""
        if len(virtual_positions) < 2:
            return {"uniformity_score": 100.0, "standard_deviation": 0.0}
        
        # 计算相邻虚拟节点的距离
        sorted_positions = sorted(virtual_positions)
        distances = []
        
        for i in range(len(sorted_positions)):
            current_pos = sorted_positions[i]
            next_pos = sorted_positions[(i + 1) % len(sorted_positions)]
            
            # 处理环的边界
            distance = next_pos - current_pos if next_pos > current_pos else (1.0 - current_pos) + next_pos
            distances.append(distance)
        
        # 计算统计指标
        mean_distance = statistics.mean(distances)
        std_distance = statistics.stdev(distances)
        
        # 均匀性分数（标准差越小，分布越均匀）
        uniformity_score = max(0.0, 100.0 - (std_distance / mean_distance * 100))
        
        return {
            "uniformity_score": uniformity_score,
            "standard_deviation": std_distance,
            "mean_distance": mean_distance
        }

# 主演示函数
def demo_consistent_hashing():
    """主演示函数"""
    
    print("=== Consistent Hashing Load Balancer Demo ===\n")
    
    # 1. 创建测试服务器
    print("1. Setting up Servers")
    print("="*50)
    
    servers = [
        PhysicalServer("server1", "webserver1.com", 8080, capacity=1500.0),
        PhysicalServer("server2", "webserver2.com", 8080, capacity=2000.0),
        PhysicalServer("server3", "webserver3.com", 8080, capacity=1200.0),
        PhysicalServer("server4", "webserver4.com", 8080, capacity=1800.0)
    ]
    
    print("Server configurations:")
    for server in servers:
        print(f"  {server.hostname}: capacity={server.capacity:.0f}")
    
    # 2. 测试不同策略
    print("\n2. Testing Different Strategies")
    print("="*50)
    
    strategies = [
        ConsistentHashingStrategy.BASIC_CONSISTENT_HASHING,
        ConsistentHashingStrategy.KETAMA_CONSISTENT_HASHING,
        ConsistentHashingStrategy.WEIGHTED_CONSISTENT_HASHING
    ]
    
    strategy_results = {}
    
    for strategy in strategies:
        print(f"\n--- Testing {strategy.value} ---")
        
        lb = ConsistentHashingLoadBalancer(strategy=strategy, virtual_nodes_per_server=100)
        
        for server in servers:
            lb.add_server(copy.deepcopy(server))
        
        # 运行流量仿真
        results = lb.simulate_traffic(num_requests=5000)
        strategy_results[strategy.value] = results
        
        print(f"Requests: {results['total_requests']}")
        print(f"Cache hit rate: {results['cache_hit_rate']:.1f}%")
        print(f"Average response time: {results['average_response_time']:.3f}s")
        print(f"Balance quality: {results['load_distribution']['balance_quality']:.1f}")
    
    # 3. 虚拟节点分布分析
    print("\n3. Virtual Node Distribution Analysis")
    print("="*50)
    
    ketama_lb = ConsistentHashingLoadBalancer(ConsistentHashingStrategy.KETAMA_CONSISTENT_HASHING)
    
    for server in servers:
        ketama_lb.add_server(server)
    
    load_dist = ketama_lb.get_load_distribution()
    
    print(f"Total virtual nodes: {load_dist['total_virtual_nodes']}")
    print("Virtual node distribution:")
    for server_id, count in load_dist["virtual_node_distribution"].items():
        percentage = (count / load_dist['total_virtual_nodes'] * 100)
        server = ketama_lb.servers[server_id]
        print(f"  {server.hostname}: {count} nodes ({percentage:.1f}%)")
    
    # 4. 节点变更影响分析
    print("\n4. Node Change Impact Analysis")
    print("="*50)
    
    # 添加新服务器的影响
    new_server = PhysicalServer("server5", "webserver5.com", 8080, capacity=1600.0)
    add_impact = ketama_lb.redistribute_after_node_change(new_server.id, "add")
    
    print("Adding new server impact:")
    print(f"  Affected keys: {add_impact['affected_keys']}")
    print(f"  Redistributed keys: {add_impact['redistributed_keys']}")
    print(f"  Redistribution ratio: {add_impact['redistribution_ratio']:.3f}")
    print(f"  Efficiency: {add_impact['efficiency']:.3f}")
    
    # 移除服务器的影响
    remove_impact = ketama_lb.redistribute_after_node_change("server1", "remove")
    
    print("\nRemoving server impact:")
    print(f"  Affected keys: {remove_impact['affected_keys']}")
    print(f"  Redistributed keys: {remove_impact['redistributed_keys']}")
    print(f"  Redistribution ratio: {remove_impact['redistribution_ratio']:.3f}")
    print(f"  Efficiency: {remove_impact['efficiency']:.3f}")
    
    # 5. Go风格实现演示
    print("\n5. Go-Style Implementation Demo")
    print("="*50)
    
    go_servers = [
        {"id": "go1", "host": "go-server1", "port": 8080},
        {"id": "go2", "host": "go-server2", "port": 8080},
        {"id": "go3", "host": "go-server3", "port": 8080}
    ]
    
    go_hash = GoStyleConsistentHash(go_servers, virtual_nodes=50)
    
    print("Go-style key distribution (first 20 keys):")
    key_distribution = defaultdict(int)
    
    for i in range(20):
        key = f"user_{i}_data"
        server_id = go_hash.Get(key)
        if server_id:
            key_distribution[server_id] += 1
            print(f"  Key '{key}' -> {server_id}")
    
    print(f"\nDistribution: {dict(key_distribution)}")
    
    # 6. 多副本请求演示
    print("\n6. Multi-Replica Request Demo")
    print("="*50)
    
    multi_lb = ConsistentHashingLoadBalancer(ConsistentHashingStrategy.KETAMA_CONSISTENT_HASHING)
    
    for server in servers[:3]:  # 只使用3台服务器
        multi_lb.add_server(server)
    
    test_key = "important_data_123"
    responsible_servers = multi_lb.get_responsible_servers(test_key, count=3)
    
    print(f"Key '{test_key}' is responsible for:")
    for i, server in enumerate(responsible_servers):
        print(f"  Replica {i+1}: {server.hostname}:{server.port}")
    
    # 7. 性能基准测试
    print("\n7. Performance Benchmark")
    print("="*50)
    
    print(f"{'Strategy':<25} {'Throughput':<12} {'Hit Rate':<10} {'Balance':<10} {'Avg Time':<12}")
    print("-" * 75)
    
    for strategy, results in strategy_results.items():
        throughput = results['requests_per_second']
        hit_rate = results['cache_hit_rate']
        balance = results['load_distribution']['balance_quality']
        avg_time = results['average_response_time']
        
        print(f"{strategy:<25} {throughput:<12.1f} {hit_rate:<10.1f} {balance:<10.1f} {avg_time:<12.3f}")
    
    # 8. 分布均匀性分析
    print("\n8. Distribution Uniformity Analysis")
    print("="*50)
    
    # 分析虚拟节点分布
    all_positions = []
    for server in servers:
        for vnode in server.virtual_nodes:
            all_positions.append(vnode.position)
    
    uniformity_analysis = ConsistentHashOptimization.analyze_distribution_uniformity(all_positions)
    
    print(f"Virtual node distribution uniformity:")
    print(f"  Uniformity score: {uniformity_analysis['uniformity_score']:.2f}/100")
    print(f"  Standard deviation: {uniformity_analysis['standard_deviation']:.4f}")
    print(f"  Mean distance: {uniformity_analysis['mean_distance']:.4f}")
    
    # 9. 优化建议
    print("\n9. Optimization Recommendations")
    print("="*50)
    
    rebalancing_cost = ConsistentHashOptimization.calculate_rebalancing_cost(
        len(servers), 150
    )
    
    optimal_vnodes = ConsistentHashOptimization.optimize_virtual_nodes(len(servers))
    
    print(f"Current configuration:")
    print(f"  Servers: {len(servers)}")
    print(f"  Virtual nodes per server: 150")
    print(f"  Total virtual nodes: {rebalancing_cost['total_virtual_nodes']}")
    
    print(f"\nOptimization recommendations:")
    print(f"  Optimal virtual nodes per server: {optimal_vnodes}")
    print(f"  Add server cost: {rebalancing_cost['add_server_cost']:.1f}%")
    print(f"  Remove server cost: {rebalancing_cost['remove_server_cost']:.1f}%")
    print(f"  Expected data migration: {rebalancing_cost['data_migration_percentage']:.1f}%")
    
    print("\n=== Consistent Hashing Summary ===")
    print("Consistent Hashing Algorithm provides:")
    print("• Minimal key redistribution on node changes")
    print("• Efficient lookup with O(log n) complexity")
    print("• Excellent distribution uniformity")
    print("• Support for weighted load balancing")
    print("\nKey Advantages:")
    print("• Handles dynamic server addition/removal")
    print("• Minimal data migration during topology changes")
    print("• Consistent hashing behavior")
    print("• Supports multiple replicas per key")
    print("\nUse Cases:")
    print("• Distributed caching systems")
    print("• Load balancing with session affinity")
    print("• Database sharding")
    print("• Content delivery networks (CDN)")
    print("• Distributed storage systems")
    print("\nStrategy Variations:")
    print("• Basic: Simple hash ring")
    print("• Ketama: Optimized for cache systems")
    print("• Weighted: Considers server capacity")
    print("• Jump: Deterministic hashing")

if __name__ == "__main__":
    demo_consistent_hashing()