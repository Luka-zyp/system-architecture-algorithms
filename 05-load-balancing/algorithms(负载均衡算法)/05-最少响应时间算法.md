# Least Response Time 负载均衡算法详解

## 目录
1. [算法概述](#算法概述)
2. [算法原理](#算法原理)
3. [Python实现](#python实现)
4. [Go语言实现](#go-language实现)
5. [响应时间监控](#响应时间监控)
6. [性能评估](#性能评估)
7. [适用场景](#适用场景)
8. [故障处理](#故障处理)
9. [监控指标](#监控指标)
10. [实战案例](#实战案例)

## 算法概述

### 什么是Least Response Time

Least Response Time（最少响应时间）是一种智能负载均衡算法，它基于服务器的实时响应时间来选择服务器。该算法优先将请求分配给响应时间最短的服务器，从而确保用户体验的最佳化。

### 核心特性

```python
from typing import List, Dict, Optional, Any, Tuple, Callable, Union, Deque
from dataclasses import dataclass, field
from enum import Enum
import time
import threading
import statistics
import random
import logging
from collections import defaultdict, deque
from concurrent.futures import ThreadPoolExecutor, as_completed
import copy
from abc import ABC, abstractmethod
import json
import time
import math

@dataclass
class ServerMetrics:
    """服务器性能指标"""
    server_id: str
    hostname: str
    port: int
    
    # 响应时间指标
    avg_response_time: float = 0.0
    min_response_time: float = float('inf')
    max_response_time: float = 0.0
    p50_response_time: float = 0.0
    p95_response_time: float = 0.0
    p99_response_time: float = 0.0
    
    # 请求统计
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    timeout_requests: int = 0
    
    # 响应时间历史
    response_times: Deque[float] = field(default_factory=lambda: deque(maxlen=100))
    
    # 健康状态
    is_healthy: bool = True
    last_health_check: float = field(default_factory=time.time)
    health_check_failures: int = 0
    
    # 性能分数（0-100）
    performance_score: float = 100.0
    
    def add_response_time(self, response_time: float, success: bool = True):
        """添加响应时间记录"""
        self.response_times.append(response_time)
        
        # 更新统计
        self.total_requests += 1
        if success:
            self.successful_requests += 1
        else:
            self.failed_requests += 1
        
        # 更新响应时间指标
        if response_time < self.min_response_time:
            self.min_response_time = response_time
        
        if response_time > self.max_response_time:
            self.max_response_time = response_time
        
        # 重新计算平均响应时间
        if self.response_times:
            self.avg_response_time = sum(self.response_times) / len(self.response_times)
            
            # 计算分位数
            sorted_times = sorted(self.response_times)
            n = len(sorted_times)
            
            self.p50_response_time = sorted_times[int(0.5 * n)]
            self.p95_response_time = sorted_times[int(0.95 * n)]
            self.p99_response_time = sorted_times[int(0.99 * n)]
    
    def get_error_rate(self) -> float:
        """获取错误率"""
        return (self.failed_requests / max(1, self.total_requests)) * 100
    
    def get_success_rate(self) -> float:
        """获取成功率"""
        return (self.successful_requests / max(1, self.total_requests)) * 100
    
    def calculate_performance_score(self) -> float:
        """计算综合性能分数"""
        if self.total_requests == 0:
            return 100.0
        
        # 响应时间权重
        response_time_score = max(0, 100 - (self.avg_response_time * 50))
        
        # 成功率权重
        success_rate_score = self.get_success_rate()
        
        # 综合分数
        self.performance_score = (response_time_score * 0.7 + success_rate_score * 0.3)
        
        # 考虑健康状态
        if not self.is_healthy:
            self.performance_score *= 0.1  # 严重降权
        
        return max(0.0, min(100.0, self.performance_score))
    
    def should_exclude(self) -> bool:
        """判断是否应该排除此服务器"""
        if not self.is_healthy:
            return True
        
        if self.get_error_rate() > 50:  # 错误率超过50%
            return True
        
        if self.avg_response_time > 10000:  # 平均响应时间超过10秒
            return True
        
        return False
    
    def get_readiness_score(self) -> float:
        """获取就绪分数（用于选择）"""
        if self.total_requests == 0:
            return 100.0  # 新服务器默认最高分数
        
        # 响应时间越短，分数越高
        if self.avg_response_time == 0:
            return 100.0
        
        # 使用对数缩放避免响应时间差异过大
        normalized_time = min(10.0, self.avg_response_time / 1000.0)  # 标准化到10秒
        time_score = math.exp(-normalized_time) * 100
        
        # 考虑成功率和错误率
        success_factor = self.get_success_rate() / 100.0
        
        # 综合分数
        readiness_score = time_score * success_factor
        
        return max(0.0, min(100.0, readiness_score))

@dataclass
class LoadBalancingRequest:
    """负载均衡请求"""
    request_id: str
    start_time: float
    timeout: float = 30.0
    
    def is_timeout(self) -> bool:
        """检查是否超时"""
        return time.time() - self.start_time > self.timeout

class HealthCheckStrategy(Enum):
    """健康检查策略"""
    PASSIVE = "passive"  # 被动检查（基于请求结果）
    ACTIVE = "active"    # 主动检查（定期ping）
    COMBINED = "combined"  # 组合检查

class ResponseTimeAggregation(Enum):
    """响应时间聚合策略"""
    SIMPLE_MOVING_AVERAGE = "sma"  # 简单移动平均
    EXPONENTIAL_MOVING_AVERAGE = "ema"  # 指数移动平均
    WEIGHTED_AVERAGE = "weighted"  # 加权平均
    PERCENTILE = "percentile"  # 分位数

class LeastResponseTimeLoadBalancer:
    """最少响应时间负载均衡器"""
    
    def __init__(self,
                 health_check_strategy: HealthCheckStrategy = HealthCheckStrategy.COMBINED,
                 aggregation_strategy: ResponseTimeAggregation = ResponseTimeAggregation.SIMPLE_MOVING_AVERAGE,
                 ema_alpha: float = 0.3,
                 response_time_weight: float = 0.7,
                 failure_penalty: float = 0.8,
                 minimum_requests: int = 5):
        
        self.health_check_strategy = health_check_strategy
        self.aggregation_strategy = aggregation_strategy
        self.ema_alpha = ema_alpha
        self.response_time_weight = response_time_weight
        self.failure_penalty = failure_penalty
        self.minimum_requests = minimum_requests
        
        # 服务器管理
        self.servers: Dict[str, ServerMetrics] = {}
        self.server_order: List[str] = []  # 用于稳定排序
        
        # 状态管理
        self.mutex = threading.RLock()
        self.request_counter = 0
        self.start_time = time.time()
        
        # 性能统计
        self.metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_response_time": 0.0,
            "average_response_time": 0.0,
            "selection_decisions": 0,
            "health_checks": 0,
            "server_exclusions": 0
        }
        
        # 设置日志
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger("LeastResponseTime")
    
    def add_server(self, server_id: str, hostname: str, port: int):
        """添加服务器"""
        with self.mutex:
            if server_id not in self.servers:
                self.servers[server_id] = ServerMetrics(server_id, hostname, port)
                self.server_order.append(server_id)
                self.logger.info(f"Added server {hostname}:{port}")
            else:
                self.logger.warning(f"Server {server_id} already exists")
    
    def remove_server(self, server_id: str):
        """移除服务器"""
        with self.mutex:
            if server_id in self.servers:
                del self.servers[server_id]
                if server_id in self.server_order:
                    self.server_order.remove(server_id)
                self.logger.info(f"Removed server {server_id}")
    
    def record_response(self, server_id: str, response_time: float, success: bool = True):
        """记录响应时间和结果"""
        with self.mutex:
            if server_id not in self.servers:
                self.logger.warning(f"Response recorded for unknown server: {server_id}")
                return
            
            server = self.servers[server_id]
            
            # 使用聚合策略计算响应时间
            if self.aggregation_strategy == ResponseTimeAggregation.EXPONENTIAL_MOVING_AVERAGE:
                if server.total_requests > 0:
                    response_time = (self.ema_alpha * response_time + 
                                   (1 - self.ema_alpha) * server.avg_response_time)
            
            server.add_response_time(response_time, success)
            
            # 更新全局统计
            self.metrics["total_requests"] += 1
            if success:
                self.metrics["successful_requests"] += 1
                self.metrics["total_response_time"] += response_time
            else:
                self.metrics["failed_requests"] += 1
            
            # 重新计算平均响应时间
            if self.metrics["total_requests"] > 0:
                self.metrics["average_response_time"] = (
                    self.metrics["total_response_time"] / 
                    max(1, self.metrics["successful_requests"])
                )
            
            # 检查是否需要更新健康状态
            if self.health_check_strategy in [HealthCheckStrategy.COMBINED, HealthCheckStrategy.PASSIVE]:
                self._passive_health_check(server)
            
            server.calculate_performance_score()
            
            self.logger.debug(f"Recorded response: {server_id} - {response_time:.3f}s (success: {success})")
    
    def _passive_health_check(self, server: ServerMetrics):
        """被动健康检查"""
        if server.total_requests >= self.minimum_requests:
            error_rate = server.get_error_rate()
            avg_response_time = server.avg_response_time
            
            # 如果错误率过高或响应时间过长，标记为不健康
            if error_rate > 50 and server.successful_requests > 0:
                server.is_healthy = False
                server.health_check_failures += 1
                self.metrics["server_exclusions"] += 1
                self.logger.warning(f"Server {server.server_id} marked unhealthy due to high error rate: {error_rate:.1f}%")
            
            elif avg_response_time > 30000 and server.total_requests >= 10:  # 30秒
                server.is_healthy = False
                server.health_check_failures += 1
                self.metrics["server_exclusions"] += 1
                self.logger.warning(f"Server {server.server_id} marked unhealthy due to slow response: {avg_response_time:.1f}ms")
    
    def select_server(self) -> Optional[ServerMetrics]:
        """选择响应时间最短的服务器"""
        with self.mutex:
            if not self.servers:
                self.logger.warning("No servers available")
                return None
            
            # 获取健康的服务器
            healthy_servers = []
            for server in self.servers.values():
                if not server.should_exclude():
                    healthy_servers.append(server)
            
            if not healthy_servers:
                self.logger.warning("No healthy servers available")
                return None
            
            # 如果只有一台健康服务器，直接返回
            if len(healthy_servers) == 1:
                self.metrics["selection_decisions"] += 1
                return healthy_servers[0]
            
            # 计算每台服务器的就绪分数
            server_scores = []
            for server in healthy_servers:
                readiness_score = server.get_readiness_score()
                
                # 应用失败惩罚
                error_rate = server.get_error_rate()
                failure_factor = (1 - error_rate / 100.0) ** self.failure_penalty
                final_score = readiness_score * failure_factor
                
                server_scores.append((final_score, server))
            
            # 按分数排序（分数高的优先）
            server_scores.sort(key=lambda x: x[0], reverse=True)
            
            # 选择分数最高的服务器
            selected_server = server_scores[0][1]
            self.metrics["selection_decisions"] += 1
            
            self.logger.debug(f"Selected server: {selected_server.server_id} "
                            f"(score: {server_scores[0][0]:.2f}, "
                            f"avg_time: {selected_server.avg_response_time:.3f}s)")
            
            return selected_server
    
    def select_server_for_request(self, request_id: str = None) -> Tuple[Optional[ServerMetrics], Optional[str]]:
        """为请求选择服务器"""
        selected_server = self.select_server()
        
        if not selected_server:
            return None, None
        
        request_id = request_id or f"req_{self.request_counter}"
        self.request_counter += 1
        
        return selected_server, request_id
    
    def get_load_balancing_info(self) -> Dict[str, Any]:
        """获取负载均衡信息"""
        with self.mutex:
            if not self.servers:
                return {"error": "No servers registered"}
            
            server_info = {}
            
            for server_id, server in self.servers.items():
                server_info[server_id] = {
                    "hostname": server.hostname,
                    "port": server.port,
                    "is_healthy": server.is_healthy,
                    "total_requests": server.total_requests,
                    "successful_requests": server.successful_requests,
                    "failed_requests": server.failed_requests,
                    "error_rate": server.get_error_rate(),
                    "success_rate": server.get_success_rate(),
                    "avg_response_time": server.avg_response_time,
                    "min_response_time": server.min_response_time,
                    "max_response_time": server.max_response_time,
                    "p50_response_time": server.p50_response_time,
                    "p95_response_time": server.p95_response_time,
                    "p99_response_time": server.p99_response_time,
                    "performance_score": server.performance_score,
                    "readiness_score": server.get_readiness_score()
                }
            
            # 计算全局统计
            total_requests = sum(server.total_requests for server in self.servers.values())
            total_success = sum(server.successful_requests for server in self.servers.values())
            total_fail = sum(server.failed_requests for server in self.servers.values())
            avg_response_time = sum(server.avg_response_time * server.total_requests 
                                  for server in self.servers.values()) / max(1, total_requests)
            
            return {
                "servers": server_info,
                "global_stats": {
                    "total_servers": len(self.servers),
                    "healthy_servers": sum(1 for s in self.servers.values() if s.is_healthy),
                    "total_requests": total_requests,
                    "total_success": total_success,
                    "total_fail": total_fail,
                    "overall_success_rate": (total_success / max(1, total_requests)) * 100,
                    "overall_error_rate": (total_fail / max(1, total_requests)) * 100,
                    "average_response_time": avg_response_time,
                    "metrics": self.metrics
                }
            }
    
    def simulate_traffic(self, duration: float = 60.0, requests_per_second: int = 100) -> Dict[str, Any]:
        """仿真流量测试"""
        print(f"Starting traffic simulation: {requests_per_second} req/s for {duration} seconds")
        
        start_time = time.time()
        request_count = 0
        server_request_counts = defaultdict(int)
        response_time_samples = []
        error_samples = []
        
        # 模拟服务器响应时间分布
        server_performance = {}
        for server_id, server in self.servers.items():
            # 模拟每台服务器的基础性能
            base_response_time = random.uniform(100, 500)  # 100-500ms基础响应时间
            server_performance[server_id] = {
                "base_response_time": base_response_time,
                "reliability": random.uniform(0.9, 0.99),  # 90-99%可靠性
                "current_load": 0.0
            }
        
        while time.time() - start_time < duration:
            request_start = time.time()
            
            # 选择服务器
            selected_server = self.select_server()
            if selected_server:
                server_id = selected_server.server_id
                server_perf = server_performance[server_id]
                
                # 模拟服务器负载对响应时间的影响
                load_factor = 1.0 + (server_perf["current_load"] * 0.5)
                
                # 生成响应时间
                base_time = server_perf["base_response_time"]
                response_time = random.normalvariate(base_time, base_time * 0.2) * load_factor
                response_time = max(50, response_time)  # 最小50ms
                
                # 模拟成功/失败
                is_success = random.random() < server_perf["reliability"]
                
                # 记录响应
                self.record_response(server_id, response_time, is_success)
                
                # 更新统计
                server_request_counts[server_id] += 1
                if is_success:
                    response_time_samples.append(response_time)
                else:
                    error_samples.append(response_time)
                
                request_count += 1
                
                # 模拟处理时间
                processing_time = response_time / 1000.0  # 转换为秒
                time.sleep(min(0.1, processing_time / 10))  # 加速仿真
                
                # 更新服务器负载
                server_perf["current_load"] = max(0, server_perf["current_load"] - 0.1)
            
            # 控制请求频率
            elapsed = time.time() - request_start
            sleep_time = max(0, (1.0 / requests_per_second) - elapsed)
            time.sleep(sleep_time)
        
        # 收集结果
        end_time = time.time()
        actual_duration = end_time - start_time
        
        # 计算统计指标
        load_info = self.get_load_balancing_info()
        
        results = {
            "simulation_config": {
                "duration": duration,
                "requested_rps": requests_per_second,
                "actual_duration": actual_duration
            },
            "results": {
                "total_requests": request_count,
                "actual_rps": request_count / actual_duration,
                "response_times": {
                    "count": len(response_time_samples),
                    "mean": statistics.mean(response_time_samples) if response_time_samples else 0,
                    "median": statistics.median(response_time_samples) if response_time_samples else 0,
                    "min": min(response_time_samples) if response_time_samples else 0,
                    "max": max(response_time_samples) if response_time_samples else 0,
                    "std": statistics.stdev(response_time_samples) if len(response_time_samples) > 1 else 0
                },
                "errors": {
                    "count": len(error_samples),
                    "rate": len(error_samples) / request_count * 100 if request_count > 0 else 0
                },
                "server_distribution": dict(server_request_counts),
                "server_details": load_info
            }
        }
        
        return results
    
    def get_performance_recommendations(self) -> Dict[str, Any]:
        """获取性能优化建议"""
        with self.mutex:
            if not self.servers:
                return {"error": "No servers to analyze"}
            
            recommendations = []
            server_analysis = {}
            
            # 分析每台服务器
            for server_id, server in self.servers.items():
                analysis = {
                    "server_id": server_id,
                    "performance_grade": self._get_performance_grade(server),
                    "issues": [],
                    "recommendations": [],
                    "scores": {
                        "response_time": self._get_response_time_score(server),
                        "reliability": self._get_reliability_score(server),
                        "overall": server.get_readiness_score()
                    }
                }
                
                # 检查响应时间问题
                if server.avg_response_time > 1000:  # 大于1秒
                    analysis["issues"].append("High average response time")
                    analysis["recommendations"].append("Consider optimizing server performance or reducing load")
                
                if server.p99_response_time > 5000:  # 大于5秒
                    analysis["issues"].append("High P99 response time indicates performance issues")
                    analysis["recommendations"].append("Investigate slow queries or performance bottlenecks")
                
                # 检查可靠性问题
                error_rate = server.get_error_rate()
                if error_rate > 5:  # 错误率超过5%
                    analysis["issues"].append(f"High error rate: {error_rate:.1f}%")
                    analysis["recommendations"].append("Check server health and error logs")
                
                # 检查负载不均衡
                total_requests = sum(s.total_requests for s in self.servers.values())
                if total_requests > 0:
                    expected_requests = total_requests / len(self.servers)
                    if server.total_requests < expected_requests * 0.5:
                        analysis["issues"].append("Under-utilized server")
                        analysis["recommendations"].append("Consider increasing traffic to this server")
                    elif server.total_requests > expected_requests * 2:
                        analysis["issues"].append("Over-utilized server")
                        analysis["recommendations"].append("Consider reducing load or adding more servers")
                
                server_analysis[server_id] = analysis
            
            # 全局建议
            total_servers = len(self.servers)
            healthy_servers = sum(1 for s in self.servers.values() if s.is_healthy)
            
            if healthy_servers < total_servers * 0.8:
                recommendations.append("Multiple servers are unhealthy - investigate infrastructure issues")
            
            if total_servers < 3:
                recommendations.append("Consider adding more servers for better fault tolerance")
            
            return {
                "server_analysis": server_analysis,
                "global_recommendations": recommendations,
                "configuration_suggestions": {
                    "health_check_strategy": self.health_check_strategy.value,
                    "aggregation_strategy": self.aggregation_strategy.value,
                    "current_metrics": self.metrics
                }
            }
    
    def _get_performance_grade(self, server: ServerMetrics) -> str:
        """获取性能等级"""
        score = server.get_readiness_score()
        
        if score >= 90:
            return "A (Excellent)"
        elif score >= 80:
            return "B (Good)"
        elif score >= 70:
            return "C (Fair)"
        elif score >= 60:
            return "D (Poor)"
        else:
            return "F (Failing)"
    
    def _get_response_time_score(self, server: ServerMetrics) -> float:
        """获取响应时间分数"""
        if server.total_requests == 0:
            return 100.0
        
        # 响应时间越短分数越高
        avg_time = server.avg_response_time / 1000.0  # 转换为秒
        
        if avg_time <= 0.1:  # 100ms以下
            return 100.0
        elif avg_time <= 0.5:  # 500ms以下
            return 90.0
        elif avg_time <= 1.0:  # 1秒以下
            return 80.0
        elif avg_time <= 2.0:  # 2秒以下
            return 60.0
        else:
            return max(0.0, 40.0 - (avg_time - 2.0) * 10)
    
    def _get_reliability_score(self, server: ServerMetrics) -> float:
        """获取可靠性分数"""
        if server.total_requests == 0:
            return 100.0
        
        success_rate = server.get_success_rate()
        return success_rate

class GoStyleLeastResponseTime:
    """Go语言风格的最少响应时间实现"""
    
    def __init__(self, servers: List[Dict[str, Any]]):
        self.servers = servers
        self.response_times = {server["id"]: [] for server in servers}
        self.lock = threading.Lock()
    
    def RecordResponse(self, server_id: str, response_time: float, success: bool):
        """记录响应时间（Go风格）"""
        with self.lock:
            if server_id in self.response_times:
                self.response_times[server_id].append(response_time)
                
                # 保持最近100个记录
                if len(self.response_times[server_id]) > 100:
                    self.response_times[server_id] = self.response_times[server_id][-100:]
    
    def GetBestServer(self) -> Optional[str]:
        """获取最佳服务器"""
        best_server = None
        best_score = float('inf')
        
        with self.lock:
            for server in self.servers:
                server_id = server["id"]
                response_times = self.response_times[server_id]
                
                if response_times:
                    avg_time = sum(response_times) / len(response_times)
                    
                    # 动态调整分数
                    if len(response_times) < 10:
                        # 新服务器给予一定优惠
                        avg_time *= 0.8
                    
                    if avg_time < best_score:
                        best_score = avg_time
                        best_server = server_id
        
        return best_server
    
    def GetServerStats(self) -> Dict[str, Dict[str, Any]]:
        """获取服务器统计信息"""
        with self.lock:
            stats = {}
            
            for server in self.servers:
                server_id = server["id"]
                response_times = self.response_times[server_id]
                
                if response_times:
                    stats[server_id] = {
                        "avg_response_time": sum(response_times) / len(response_times),
                        "min_response_time": min(response_times),
                        "max_response_time": max(response_times),
                        "request_count": len(response_times)
                    }
                else:
                    stats[server_id] = {
                        "avg_response_time": 0,
                        "min_response_time": 0,
                        "max_response_time": 0,
                        "request_count": 0
                    }
            
            return stats

class AdvancedResponseTimeLoadBalancer(LeastResponseTimeLoadBalancer):
    """高级最少响应时间负载均衡器"""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # 高级配置
        self.trend_analysis_window = 50  # 趋势分析窗口
        self.concurrency_threshold = 10  # 并发阈值
        self.load_factor_weight = 0.3    # 负载因子权重
        
        # 趋势数据
        self.response_time_trends: Dict[str, deque] = defaultdict(
            lambda: deque(maxlen=self.trend_analysis_window)
        )
        
        # 负载监控
        self.current_load = defaultdict(float)
        self.server_capacities = {}
    
    def record_response_with_load(self, server_id: str, response_time: float, 
                                success: bool, concurrent_requests: int = 0):
        """记录响应时间并考虑负载"""
        # 记录基础响应时间
        self.record_response(server_id, response_time, success)
        
        # 记录趋势数据
        self.response_time_trends[server_id].append(response_time)
        
        # 更新当前负载
        self.current_load[server_id] = concurrent_requests
        
        # 计算负载影响
        if server_id in self.servers:
            self._update_load_impact(server_id)
    
    def _update_load_impact(self, server_id: str):
        """更新负载影响"""
        server = self.servers[server_id]
        
        # 基于趋势数据计算性能衰减
        trends = self.response_time_trends[server_id]
        if len(trends) >= 10:
            recent_avg = sum(list(trends)[-10:]) / 10
            early_avg = sum(list(trends)[:10]) / 10
            
            if recent_avg > early_avg * 1.5:  # 响应时间增长超过50%
                server.is_healthy = False
                self.logger.warning(f"Server {server_id} showing performance degradation")
    
    def select_server_advanced(self) -> Optional[ServerMetrics]:
        """高级服务器选择（考虑负载和趋势）"""
        with self.mutex:
            if not self.servers:
                return None
            
            # 获取候选服务器
            candidates = []
            
            for server in self.servers.values():
                if not server.should_exclude():
                    # 计算综合分数
                    base_score = server.get_readiness_score()
                    
                    # 负载调整
                    current_load = self.current_load.get(server.server_id, 0)
                    capacity = self.server_capacities.get(server.server_id, 100)
                    load_ratio = current_load / max(1, capacity)
                    
                    # 负载调整分数
                    load_penalty = max(0, load_ratio - 1.0) * 50  # 超过容量惩罚
                    
                    # 趋势分析调整
                    trend_penalty = self._calculate_trend_penalty(server)
                    
                    # 综合分数
                    adjusted_score = base_score - load_penalty - trend_penalty
                    
                    candidates.append((adjusted_score, server))
            
            if not candidates:
                return None
            
            # 按分数排序
            candidates.sort(key=lambda x: x[0], reverse=True)
            
            return candidates[0][1] if candidates else None
    
    def _calculate_trend_penalty(self, server: ServerMetrics) -> float:
        """计算趋势惩罚"""
        trends = self.response_time_trends[server.server_id]
        
        if len(trends) < 20:  # 数据不足
            return 0.0
        
        # 计算响应时间趋势
        recent_trend = self._calculate_trend(trends[-10:])
        historical_trend = self._calculate_trend(trends[-20:-10])
        
        # 如果最近趋势比历史趋势差，施加惩罚
        if recent_trend > historical_trend * 1.2:
            return (recent_trend - historical_trend) * 10
        
        return 0.0
    
    def _calculate_trend(self, values: List[float]) -> float:
        """计算趋势（简单线性回归斜率）"""
        if len(values) < 2:
            return 0.0
        
        n = len(values)
        x_mean = (n - 1) / 2
        y_mean = sum(values) / len(values)
        
        numerator = sum((i - x_mean) * (values[i] - y_mean) for i in range(n))
        denominator = sum((i - x_mean) ** 2 for i in range(n))
        
        return numerator / denominator if denominator != 0 else 0.0
    
    def set_server_capacity(self, server_id: str, capacity: float):
        """设置服务器容量"""
        with self.mutex:
            self.server_capacities[server_id] = capacity
    
    def get_advanced_metrics(self) -> Dict[str, Any]:
        """获取高级指标"""
        with self.mutex:
            base_metrics = self.get_load_balancing_info()
            
            # 添加趋势和负载信息
            advanced_info = {
                "response_time_trends": {
                    server_id: {
                        "current_trend": self._calculate_trend(list(trends)[-10:]),
                        "historical_trend": self._calculate_trend(list(trends)[-20:-10]) if len(trends) >= 20 else 0,
                        "trend_direction": "improving" if self._calculate_trend(list(trends)[-10:]) < 0 else "degrading"
                    }
                    for server_id, trends in self.response_time_trends.items()
                },
                "load_distribution": dict(self.current_load),
                "server_capacities": self.server_capacities,
                "capacity_utilization": {
                    server_id: self.current_load.get(server_id, 0) / max(1, capacity)
                    for server_id, capacity in self.server_capacities.items()
                }
            }
            
            base_metrics["advanced_metrics"] = advanced_info
            return base_metrics

# 主演示函数
def demo_least_response_time():
    """主演示函数"""
    
    print("=== Least Response Time Load Balancer Demo ===\n")
    
    # 1. 基础最少响应时间算法演示
    print("1. Basic Least Response Time Algorithm")
    print("="*50)
    
    lb = LeastResponseTimeLoadBalancer(
        health_check_strategy=HealthCheckStrategy.COMBINED,
        aggregation_strategy=ResponseTimeAggregation.EXPONENTIAL_MOVING_AVERAGE,
        ema_alpha=0.3
    )
    
    # 添加测试服务器
    servers = [
        ("server1", "web1.example.com", 8080),
        ("server2", "web2.example.com", 8080),
        ("server3", "web3.example.com", 8080),
        ("server4", "web4.example.com", 8080)
    ]
    
    for server_id, hostname, port in servers:
        lb.add_server(server_id, hostname, port)
    
    print("Added servers:")
    for server_id, hostname, port in servers:
        print(f"  {server_id}: {hostname}:{port}")
    
    # 2. 模拟服务器响应
    print("\n2. Simulating Server Responses")
    print("="*50)
    
    # 模拟不同性能的服务器
    server_performance = {
        "server1": {"avg_time": 150, "reliability": 0.98},
        "server2": {"avg_time": 200, "reliability": 0.95},
        "server3": {"avg_time": 300, "reliability": 0.92},
        "server4": {"avg_time": 500, "reliability": 0.88}
    }
    
    print("Server performance profiles:")
    for server_id, perf in server_performance.items():
        print(f"  {server_id}: {perf['avg_time']}ms avg, {perf['reliability']:.0%} reliability")
    
    # 生成模拟请求
    request_count = 1000
    print(f"\nGenerating {request_count} simulated requests...")
    
    for i in range(request_count):
        # 选择服务器
        selected_server, request_id = lb.select_server_for_request()
        
        if selected_server:
            server_id = selected_server.server_id
            perf = server_performance[server_id]
            
            # 生成响应时间
            response_time = random.normalvariate(perf["avg_time"], perf["avg_time"] * 0.2)
            response_time = max(50, response_time)  # 最小50ms
            
            # 模拟成功/失败
            is_success = random.random() < perf["reliability"]
            
            # 记录响应
            lb.record_response(server_id, response_time, is_success)
    
    # 3. 分析结果
    print("\n3. Performance Analysis")
    print("="*50)
    
    # 获取负载均衡信息
    lb_info = lb.get_load_balancing_info()
    
    print("Server Performance Summary:")
    print(f"{'Server':<12} {'Requests':<10} {'Avg Time':<12} {'Error Rate':<12} {'Readiness':<10} {'Health':<8}")
    print("-" * 70)
    
    for server_id, info in lb_info["servers"].items():
        requests = info["total_requests"]
        avg_time = info["avg_response_time"]
        error_rate = info["error_rate"]
        readiness = info["readiness_score"]
        health = "✓" if info["is_healthy"] else "✗"
        
        print(f"{server_id:<12} {requests:<10} {avg_time:<12.1f} {error_rate:<12.1f} {readiness:<10.1f} {health:<8}")
    
    print(f"\nGlobal Statistics:")
    global_stats = lb_info["global_stats"]
    print(f"  Total Requests: {global_stats['total_requests']}")
    print(f"  Success Rate: {global_stats['overall_success_rate']:.1f}%")
    print(f"  Average Response Time: {global_stats['average_response_time']:.1f}ms")
    
    # 4. 高级算法演示
    print("\n4. Advanced Algorithm with Load Awareness")
    print("="*50)
    
    advanced_lb = AdvancedResponseTimeLoadBalancer(
        health_check_strategy=HealthCheckStrategy.COMBINED,
        aggregation_strategy=ResponseTimeAggregation.EXPONENTIAL_MOVING_AVERAGE,
        ema_alpha=0.2
    )
    
    # 设置服务器容量
    capacities = {"server1": 50, "server2": 30, "server3": 20, "server4": 10}
    for server_id, capacity in capacities.items():
        advanced_lb.set_server_capacity(server_id, capacity)
    
    for server_id, hostname, port in servers:
        advanced_lb.add_server(server_id, hostname, port)
    
    print("Advanced load balancing with capacity constraints:")
    print(f"Capacities: {capacities}")
    
    # 模拟带负载的请求
    print("\nSimulating requests with concurrent load...")
    
    for i in range(500):
        selected_server = advanced_lb.select_server_advanced()
        
        if selected_server:
            server_id = selected_server.server_id
            
            # 模拟并发请求数
            concurrent_requests = random.randint(1, capacities[server_id] + 20)
            
            # 生成响应时间
            perf = server_performance[server_id]
            load_factor = 1.0 + (concurrent_requests / max(1, capacities[server_id])) * 0.5
            response_time = random.normalvariate(perf["avg_time"] * load_factor, 
                                               perf["avg_time"] * 0.2)
            
            is_success = random.random() < perf["reliability"]
            
            advanced_lb.record_response_with_load(
                server_id, response_time, is_success, concurrent_requests
            )
    
    # 5. Go风格实现演示
    print("\n5. Go-Style Implementation")
    print("="*50)
    
    go_servers = [
        {"id": "go1", "host": "go-server1", "port": 8080},
        {"id": "go2", "host": "go-server2", "port": 8080},
        {"id": "go3", "host": "go-server3", "port": 8080}
    ]
    
    go_lb = GoStyleLeastResponseTime(go_servers)
    
    # 模拟Go风格的API调用
    print("Go-style API usage:")
    
    for i in range(100):
        # 模拟响应记录
        for server in go_servers:
            server_id = server["id"]
            response_time = random.uniform(100, 400)
            success = random.random() > 0.1  # 90%成功率
            go_lb.RecordResponse(server_id, response_time, success)
        
        # 获取最佳服务器
        best_server = go_lb.GetBestServer()
        if best_server:
            print(f"  Request {i+1}: Selected {best_server}")
    
    # 显示统计信息
    stats = go_lb.GetServerStats()
    print(f"\nGo-style statistics:")
    for server_id, stat in stats.items():
        print(f"  {server_id}: {stat['avg_response_time']:.1f}ms avg, {stat['request_count']} requests")
    
    # 6. 性能优化建议
    print("\n6. Performance Optimization Recommendations")
    print("="*50)
    
    recommendations = lb.get_performance_recommendations()
    
    print("Server Analysis:")
    for server_id, analysis in recommendations["server_analysis"].items():
        print(f"\n  {server_id} - Grade: {analysis['performance_grade']}")
        print(f"    Issues: {', '.join(analysis['issues']) if analysis['issues'] else 'None'}")
        if analysis['recommendations']:
            print(f"    Recommendations:")
            for rec in analysis['recommendations']:
                print(f"      - {rec}")
    
    print(f"\nGlobal Recommendations:")
    for rec in recommendations["global_recommendations"]:
        print(f"  - {rec}")
    
    # 7. 流量仿真测试
    print("\n7. Traffic Simulation Test")
    print("="*50)
    
    # 使用基础负载均衡器进行仿真
    simulation_results = lb.simulate_traffic(duration=30.0, requests_per_second=50)
    
    print("Simulation Results:")
    print(f"  Duration: {simulation_results['simulation_config']['actual_duration']:.1f}s")
    print(f"  Total Requests: {simulation_results['results']['total_requests']}")
    print(f"  Actual RPS: {simulation_results['results']['actual_rps']:.1f}")
    print(f"  Success Rate: {100 - simulation_results['results']['errors']['rate']:.1f}%")
    
    rt_stats = simulation_results['results']['response_times']
    print(f"  Response Time Stats:")
    print(f"    Mean: {rt_stats['mean']:.1f}ms")
    print(f"    Median: {rt_stats['median']:.1f}ms")
    print(f"    Min: {rt_stats['min']:.1f}ms")
    print(f"    Max: {rt_stats['max']:.1f}ms")
    
    print(f"  Server Distribution:")
    for server_id, count in simulation_results['results']['server_distribution'].items():
        percentage = count / simulation_results['results']['total_requests'] * 100
        print(f"    {server_id}: {count} requests ({percentage:.1f}%)")
    
    # 8. 高级指标
    print("\n8. Advanced Metrics and Trends")
    print("="*50)
    
    advanced_metrics = advanced_lb.get_advanced_metrics()
    
    if "response_time_trends" in advanced_metrics["advanced_metrics"]:
        print("Response Time Trends:")
        for server_id, trend_info in advanced_metrics["advanced_metrics"]["response_time_trends"].items():
            current_trend = trend_info["current_trend"]
            direction = trend_info["trend_direction"]
            print(f"  {server_id}: {current_trend:.2f}ms/trend ({direction})")
    
    if "capacity_utilization" in advanced_metrics["advanced_metrics"]:
        print(f"\nCapacity Utilization:")
        for server_id, utilization in advanced_metrics["advanced_metrics"]["capacity_utilization"].items():
            status = "Overloaded" if utilization > 1.0 else "Normal"
            print(f"  {server_id}: {utilization:.1%} ({status})")
    
    print("\n=== Least Response Time Algorithm Summary ===")
    print("Least Response Time Algorithm provides:")
    print("• Intelligent server selection based on actual response times")
    print("• Automatic performance optimization")
    print("• Real-time health monitoring")
    print("• Adaptive load balancing")
    print("\nKey Advantages:")
    print("• Improves user experience with fastest servers")
    print("• Automatically adapts to changing server performance")
    print("• Built-in failure detection and recovery")
    print("• Supports advanced load and trend analysis")
    print("• Go-style simple API design")
    print("\nUse Cases:")
    print("• Web applications requiring optimal response times")
    print("• API gateways with performance-sensitive requests")
    print("• Microservices with varying performance characteristics")
    print("• Content delivery networks (CDN)")
    print("• Real-time communication systems")
    print("\nAlgorithm Variations:")
    print("• Simple Moving Average: Basic statistical approach")
    print("• Exponential Moving Average: Recent performance weighted")
    print("• Weighted Average: Custom weighting factors")
    print("• Percentile-based: Focus on P50/P95/P99 performance")
    print("\nConfiguration Options:")
    print("• Health check strategies (passive/active/combined)")
    print("• Response time aggregation methods")
    print("• Failure penalties and minimum request thresholds")
    print("• Advanced load and trend analysis")
    print("• Capacity-aware selection")

if __name__ == "__main__":
    demo_least_response_time()