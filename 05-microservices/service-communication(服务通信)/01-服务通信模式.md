# 服务间通信模式

## 目录
1. [通信模式概述](#通信模式概述)
2. [同步通信模式](#同步通信模式)
3. [异步通信模式](#异步通信模式)
4. [通信协议选择](#通信协议选择)
5. [数据序列化](#数据序列化)
6. [错误处理和重试](#错误处理和重试)
7. [性能优化](#性能优化)
8. [监控和观测](#监控和观测)

## 通信模式概述

### 什么是微服务间通信？

在微服务架构中，每个微服务都是一个独立的应用程序，负责特定的业务功能。为了完成复杂的业务操作，微服务之间需要相互协作和通信。就像人类社会中人与人之间的交流一样，微服务之间的通信是整个系统正常运行的基石。

微服务间通信是指一个微服务如何向另一个微服务发送请求、接收响应或通知事件的过程。这就像餐厅中的点餐流程：
1. 顾客（前端应用）向服务员（API网关）点餐
2. 服务员将订单传递给厨房（订单服务）
3. 厨房可能需要向仓库（库存服务）确认食材
4. 厨房还需要通知收银台（支付服务）准备结账

在这个例子中，我们看到了多种通信方式：
- 同步通信：顾客等待服务员确认菜单
- 异步通信：厨房不需要立即确认食材，可以稍后通知

### 为什么通信模式很重要？

选择合适的通信方式直接影响：
1. **性能**：快速响应 vs 吞吐量
2. **可靠性**：服务故障时系统的表现
3. **可扩展性**：系统处理增长负载的能力
4. **用户体验**：系统对用户的响应速度

想象一下，如果你每次网购都要等待仓库、配货、物流等部门全部确认完毕才能收到"正在处理"的反馈，你会觉得这个网站好用吗？这就是为什么需要不同的通信模式。

### 通信模式分类
```
服务间通信模式
├── 同步通信
│   ├── 请求-响应模式
│   ├── RPC调用
│   └── REST API
├── 异步通信
│   ├── 消息队列
│   ├── 事件驱动
│   └── 发布-订阅
└── 混合模式
    ├── 同步查询 + 异步更新
    ├── 事件溯源
    └── CQRS模式
```

每种通信模式都有其独特的优势和适用场景：
- **同步通信**就像打电话：直接、实时，但通话双方必须同时在线
- **异步通信**就像发短信：不需要立即响应，不阻塞发送方
- **混合模式**结合两者优点：像发短信的同时用电话确认重要事情

## 同步通信模式

### 什么时候使用同步通信？

同步通信就像面对面交流，你说话时必须等对方回应后再继续。主要适用于：

1. **需要立即反馈的场景**：如用户登录验证、支付确认
2. **业务流程强依赖的场景**：如库存检查、订单校验
3. **用户界面需要同步更新的场景**：如个人资料修改

想象你在自助餐厅点餐：服务员（前端）向厨房（服务）点餐，服务员必须等待厨房确认菜品是否还有库存，才能继续为你服务，这就是典型的同步通信场景。

### 1. HTTP/REST通信

HTTP/REST是最常见的同步通信方式，几乎所有的网站都在使用。简单理解，它就像我们日常浏览网页的方式：你发送一个请求，网站返回响应。

#### 基础概念

- **HTTP方法**：
  - GET：获取数据（如查看商品信息）
  - POST：创建数据（如注册新用户）
  - PUT：更新数据（如修改个人信息）
  - DELETE：删除数据（如取消订单）

- **状态码**：
  - 200：成功
  - 404：未找到资源
  - 500：服务器错误

#### HTTP/REST实战示例
```python
import requests
import aiohttp
import asyncio
from typing import Dict, Any, Optional

class HTTPServiceClient:
    def __init__(self, base_url: str, timeout: int = 30):
        self.base_url = base_url.rstrip('/')
        self.timeout = timeout
        self.session = requests.Session()
        
        # 设置默认headers
        self.session.headers.update({
            'Content-Type': 'application/json',
            'User-Agent': 'Microservice-Client/1.0'
        })
    
    def get(self, path: str, params: Dict = None, **kwargs) -> requests.Response:
        """GET请求"""
        url = f"{self.base_url}/{path.lstrip('/')}"
        return self.session.get(url, params=params, timeout=self.timeout, **kwargs)
    
    def post(self, path: str, data: Dict = None, json: Dict = None, **kwargs) -> requests.Response:
        """POST请求"""
        url = f"{self.base_url}/{path.lstrip('/')}"
        return self.session.post(url, data=data, json=json, timeout=self.timeout, **kwargs)
    
    def put(self, path: str, data: Dict = None, json: Dict = None, **kwargs) -> requests.Response:
        """PUT请求"""
        url = f"{self.base_url}/{path.lstrip('/')}"
        return self.session.put(url, data=data, json=json, timeout=self.timeout, **kwargs)
    
    def delete(self, path: str, **kwargs) -> requests.Response:
        """DELETE请求"""
        url = f"{self.base_url}/{path.lstrip('/')}"
        return self.session.delete(url, timeout=self.timeout, **kwargs)

class AsyncHTTPServiceClient:
    def __init__(self, base_url: str, timeout: int = 30):
        self.base_url = base_url.rstrip('/')
        self.timeout = aiohttp.ClientTimeout(total=timeout)
        self._session = None
    
    async def __aenter__(self):
        self._session = aiohttp.ClientSession(timeout=self.timeout)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self._session:
            await self._session.close()
    
    async def get(self, path: str, params: Dict = None, **kwargs) -> aiohttp.ClientResponse:
        """异步GET请求"""
        url = f"{self.base_url}/{path.lstrip('/')}"
        async with self._session.get(url, params=params, **kwargs) as response:
            return response
    
    async def post(self, path: str, data: Dict = None, json: Dict = None, **kwargs) -> aiohttp.ClientResponse:
        """异步POST请求"""
        url = f"{self.base_url}/{path.lstrip('/')}"
        async with self._session.post(url, data=data, json=json, **kwargs) as response:
            return response

# 使用示例
async def example_usage():
    async with AsyncHTTPServiceClient('http://user-service:8080') as client:
        try:
            response = await client.get('/api/users/123')
            if response.status == 200:
                user_data = await response.json()
                print(f"User data: {user_data}")
            else:
                print(f"Error: {response.status}")
        except Exception as e:
            print(f"Request failed: {e}")
```

### 2. gRPC通信

#### gRPC基础概念

gRPC（Google Remote Procedure Call）是一种高性能的RPC框架，由Google开发。可以将它想象成一个更高效、更严格的"远程调用"系统。

**为什么使用gRPC？**

1. **性能更高**：使用Protobuf格式传输数据，比JSON更紧凑，解析更快
2. **强类型定义**：使用.proto文件明确定义数据结构和接口，像签订正式合同
3. **自动生成代码**：根据.proto文件自动生成客户端和服务端代码
4. **支持多种编程语言**：可以用不同语言编写的服务相互通信

**gRPC vs HTTP/REST对比**

| 特性 | gRPC | HTTP/REST |
|------|------|-----------|
| 数据格式 | Protobuf | JSON/XML |
| 传输协议 | HTTP/2 | HTTP/1.1 |
| 数据体积 | 更小 | 相对较大 |
| 接口定义 | 强类型(.proto) | 弱类型(无规范) |
| 学习成本 | 较高 | 较低 |
| 浏览器支持 | 有限 | 广泛 |

#### gRPC实战示例
```python
import grpc
from grpc import aio as grpc_aio
from concurrent import futures
import sys
sys.path.append('proto')  # 假设proto文件在这里

import user_service_pb2
import user_service_pb2_grpc

class UserServiceClient:
    def __init__(self, server_address: str):
        self.channel = grpc.insecure_channel(server_address)
        self.stub = user_service_pb2_grpc.UserServiceStub(self.channel)
    
    def get_user(self, user_id: str) -> user_service_pb2.User:
        """同步获取用户信息"""
        request = user_service_pb2.GetUserRequest(user_id=user_id)
        return self.stub.GetUser(request)
    
    def create_user(self, name: str, email: str) -> user_service_pb2.User:
        """同步创建用户"""
        request = user_service_pb2.CreateUserRequest(
            name=name,
            email=email
        )
        return self.stub.CreateUser(request)
    
    def close(self):
        """关闭连接"""
        self.channel.close()

class AsyncUserServiceClient:
    def __init__(self, server_address: str):
        self.channel = grpc_aio.insecure_channel(server_address)
        self.stub = user_service_pb2_grpc.UserServiceStub(self.channel)
    
    async def get_user(self, user_id: str) -> user_service_pb2.User:
        """异步获取用户信息"""
        request = user_service_pb2.GetUserRequest(user_id=user_id)
        return await self.stub.GetUser(request)
    
    async def create_user(self, name: str, email: str) -> user_service_pb2.User:
        """异步创建用户"""
        request = user_service_pb2.CreateUserRequest(
            name=name,
            email=email
        )
        return await self.stub.CreateUser(request)
    
    async def close(self):
        """关闭连接"""
        await self.channel.close()

# gRPC服务器实现示例
class UserServiceServicer(user_service_pb2_grpc.UserServiceServicer):
    def __init__(self, user_repository):
        self.user_repository = user_repository
    
    def GetUser(self, request, context):
        """获取用户信息实现"""
        try:
            user = self.user_repository.get_user(request.user_id)
            if user:
                return user_service_pb2.User(
                    id=user.id,
                    name=user.name,
                    email=user.email,
                    created_at=user.created_at
                )
            else:
                context.set_code(grpc.StatusCode.NOT_FOUND)
                context.set_details('User not found')
                return user_service_pb2.User()
        except Exception as e:
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f'Internal error: {str(e)}')
            return user_service_pb2.User()
    
    def CreateUser(self, request, context):
        """创建用户实现"""
        try:
            user_data = {
                'name': request.name,
                'email': request.email
            }
            user = self.user_repository.create_user(user_data)
            
            return user_service_pb2.User(
                id=user.id,
                name=user.name,
                email=user.email,
                created_at=user.created_at
            )
        except Exception as e:
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f'Internal error: {str(e)}')
            return user_service_pb2.User()

def serve_grpc(user_repository):
    """启动gRPC服务器"""
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    user_service_pb2_grpc.add_UserServiceServicer_to_server(
        UserServiceServicer(user_repository), server
    )
    
    server.add_insecure_port('[::]:50051')
    server.start()
    server.wait_for_termination()
```

### 3. 同步通信的最佳实践

在微服务架构中，同步通信虽然简单直接，但也容易导致系统性能瓶颈和级联故障。就像在高峰期打电话，不仅占线时间长，还可能因为一方忙碌而失败。以下是一些常用的最佳实践：

#### 1. 重试机制

网络请求有时会失败，这可能是由于临时的网络问题或服务暂时不可用。重试机制可以提高请求成功的概率，但需要谨慎设计，避免增加系统负载。

#### 2. 断路器模式

当一个服务连续失败时，断路器可以"跳闸"，暂时阻止对该服务的请求，给服务恢复的时间。这就像家里的电路保护器，当电流过大时会自动跳闸，防止设备损坏。

#### 3. 超时控制

为每个请求设置合理的超时时间，防止请求无限等待。就像在餐厅点餐，如果15分钟还没上菜，你可能会询问服务员或取消订单。

#### 实践示例
```python
import time
import logging
from functools import wraps
from typing import Callable, Any

# 配置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def retry_on_failure(max_retries: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """重试装饰器"""
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            last_exception = None
            
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_retries - 1:
                        wait_time = delay * (backoff ** attempt)
                        logger.warning(f"Attempt {attempt + 1} failed, retrying in {wait_time}s: {e}")
                        time.sleep(wait_time)
                    else:
                        logger.error(f"All {max_retries} attempts failed")
            
            raise last_exception
        return wrapper
    return decorator

class CircuitBreaker:
    """断路器实现"""
    def __init__(self, failure_threshold: int = 5, timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN
    
    def call(self, func: Callable, *args, **kwargs) -> Any:
        """调用函数，带断路器保护"""
        if self.state == 'OPEN':
            if self._should_attempt_reset():
                self.state = 'HALF_OPEN'
            else:
                raise Exception("Circuit breaker is OPEN")
        
        try:
            result = func(*args, **kwargs)
            self._on_success()
            return result
        except Exception as e:
            self._on_failure()
            raise e
    
    def _should_attempt_reset(self) -> bool:
        """检查是否应该尝试重置断路器"""
        return (self.last_failure_time and 
                time.time() - self.last_failure_time >= self.timeout)
    
    def _on_success(self):
        """成功回调"""
        self.failure_count = 0
        self.state = 'CLOSED'
    
    def _on_failure(self):
        """失败回调"""
        self.failure_count += 1
        self.last_failure_time = time.time()
        
        if self.failure_count >= self.failure_threshold:
            self.state = 'OPEN'

# 使用断路器的HTTP客户端
class ResilientHTTPClient:
    def __init__(self, base_url: str):
        self.client = HTTPServiceClient(base_url)
        self.circuit_breaker = CircuitBreaker(failure_threshold=3, timeout=30)
    
    @retry_on_failure(max_retries=3)
    def get(self, path: str, **kwargs):
        """带重试和断路器的GET请求"""
        return self.circuit_breaker.call(self.client.get, path, **kwargs)
    
    @retry_on_failure(max_retries=3)
    def post(self, path: str, **kwargs):
        """带重试和断路器的POST请求"""
        return self.circuit_breaker.call(self.client.post, path, **kwargs)
```

## 异步通信模式

### 什么时候使用异步通信？

异步通信就像发短信或电子邮件：你发送消息后不需要等待对方立即响应，可以继续处理其他任务。适用于：

1. **不需要立即反馈的操作**：如发送通知邮件、生成报表
2. **资源密集型操作**：如视频转码、大数据分析
3. **高并发场景**：需要提高系统吞吐量时
4. **跨服务的业务流程**：如订单处理，其中涉及库存、物流等多个步骤

想象你在网上购物：提交订单后，系统会立即返回"订单提交成功"的确认，然后异步处理支付、库存检查和物流安排，这就是典型的异步通信场景。

### 1. 基于消息队列的异步通信

#### 消息队列基础概念

消息队列可以比作邮局：
- **生产者**：寄信人（发送消息的服务）
- **消息**：信件（要传输的数据）
- **队列**：邮箱（暂存消息的地方）
- **消费者**：收信人（处理消息的服务）
- **交换机**：分拣中心（决定消息如何路由）

#### 为什么使用消息队列？

1. **解耦**：服务之间不直接通信，而是通过消息队列间接交流，降低了依赖
2. **可靠性**：即使消费者暂时不可用，消息也不会丢失
3. **异步处理**：生产者不需要等待消费者处理完成
4. **流量削峰**：可以缓冲突发的请求量，避免系统过载
5. **数据一致性**：通过分布式事务保证数据最终一致

#### 消息队列实战示例
```python
import pika
import json
import asyncio
from datetime import datetime
from typing import Callable, Dict, Any, Optional
import threading

class MessageQueueClient:
    """基于RabbitMQ的消息队列客户端"""
    
    def __init__(self, host: str = 'localhost', port: int = 5672):
        self.host = host
        self.port = port
        self.connection = None
        self.channel = None
        self.exchange_name = 'microservice.events'
        self.connection_lock = threading.Lock()
    
    def connect(self):
        """建立连接"""
        with self.connection_lock:
            if self.connection is None or self.connection.is_closed:
                self.connection = pika.BlockingConnection(
                    pika.ConnectionParameters(host=self.host, port=self.port)
                )
                self.channel = self.connection.channel()
                
                # 声明交换机
                self.channel.exchange_declare(
                    exchange=self.exchange_name,
                    exchange_type='topic',
                    durable=True
                )
    
    def publish(self, routing_key: str, message: Dict[str, Any]):
        """发布消息"""
        self.connect()
        
        message_body = json.dumps(message, default=str)
        
        self.channel.basic_publish(
            exchange=self.exchange_name,
            routing_key=routing_key,
            body=message_body,
            properties=pika.BasicProperties(
                delivery_mode=2,  # 消息持久化
                content_type='application/json',
                timestamp=int(datetime.now().timestamp())
            )
        )
    
    def subscribe(self, routing_pattern: str, callback: Callable[[Dict], None]):
        """订阅消息"""
        self.connect()
        
        # 创建临时队列
        result = self.channel.queue_declare('', exclusive=True)
        queue_name = result.method.queue
        
        # 绑定队列到交换机
        self.channel.queue_bind(
            exchange=self.exchange_name,
            queue=queue_name,
            routing_key=routing_pattern
        )
        
        # 设置QoS
        self.channel.basic_qos(prefetch_count=1)
        
        # 开始消费消息
        self.channel.basic_consume(
            queue=queue_name,
            on_message_callback=lambda ch, method, properties, body: self._on_message(
                callback, ch, method, properties, body
            ),
            auto_ack=False
        )
        
        self.channel.start_consuming()
    
    def _on_message(self, callback: Callable, ch, method, properties, body):
        """消息处理回调"""
        try:
            message = json.loads(body)
            callback(message)
            ch.basic_ack(delivery_tag=method.delivery_tag)
        except Exception as e:
            print(f"Error processing message: {e}")
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)

# 异步消息队列客户端
class AsyncMessageQueueClient:
    """基于异步消息队列的客户端"""
    
    def __init__(self, host: str = 'localhost', port: int = 5672):
        self.host = host
        self.port = port
        self.connection = None
        self.channel = None
        self.exchange_name = 'microservice.events'
    
    async def connect(self):
        """建立异步连接"""
        if self.connection is None or self.connection.is_closed:
            self.connection = await pika.asyncio_connection.AsyncConnectionParameters(
                host=self.host, port=self.port
            )
            self.channel = await self.connection.channel()
            
            # 声明交换机
            await self.channel.exchange_declare(
                exchange=self.exchange_name,
                exchange_type='topic',
                durable=True
            )
    
    async def publish(self, routing_key: str, message: Dict[str, Any]):
        """发布异步消息"""
        await self.connect()
        
        message_body = json.dumps(message, default=str)
        
        await self.channel.basic_publish(
            exchange=self.exchange_name,
            routing_key=routing_key,
            body=message_body,
            properties=pika.BasicProperties(
                delivery_mode=2,
                content_type='application/json',
                timestamp=int(datetime.now().timestamp())
            )
        )
    
    async def subscribe(self, routing_pattern: str, callback: Callable[[Dict], None]):
        """订阅异步消息"""
        await self.connect()
        
        # 创建临时队列
        result = await self.channel.queue_declare('', exclusive=True)
        queue_name = result.method.queue
        
        # 绑定队列
        await self.channel.queue_bind(
            exchange=self.exchange_name,
            queue=queue_name,
            routing_key=routing_pattern
        )
        
        # 设置QoS
        await self.channel.basic_qos(prefetch_count=1)
        
        # 开始消费消息
        await self.channel.basic_consume(
            queue=queue_name,
            callback=lambda ch, method, properties, body: self._on_message(
                callback, ch, method, properties, body
            ),
            auto_ack=False
        )
        
        await self.channel.start_consuming()
    
    async def _on_message(self, callback: Callable, ch, method, properties, body):
        """异步消息处理"""
        try:
            message = json.loads(body)
            await callback(message)
            await ch.basic_ack(delivery_tag=method.delivery_tag)
        except Exception as e:
            print(f"Error processing message: {e}")
            await ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
```

### 2. 事件驱动架构

#### 事件驱动基础概念

事件驱动架构就像社交媒体上的通知系统：
- **领域事件**：发布者（社交媒体）上的活动，如有人关注你
- **事件处理器**：关注者（订阅者），对特定事件感兴趣
- **事件总线**：社交媒体平台，负责将事件传递给相关订阅者

简单来说，就是当"某事发生"时（事件），"谁关心这件事"（处理器）就会"做什么"（响应）。

#### 为什么使用事件驱动？

1. **松耦合**：发布者不需要知道谁在监听，就像你发朋友圈不需要知道谁会点赞
2. **扩展性**：可以轻松添加新的事件处理器而不影响现有代码
3. **业务解耦**：将复杂业务流程分解为独立的事件处理
4. **审计日志**：事件本身就是完整的操作记录

#### 实际应用场景

**场景一：电商系统中的订单处理**

1. 用户下单时，订单服务发布"订单创建"事件
2. 支付服务监听此事件，处理支付
3. 库存服务监听此事件，扣减库存
4. 物流服务监听此事件，安排发货
5. 通知服务监听此事件，发送确认邮件

**场景二：用户系统中的资料更新**

1. 用户更新资料时，用户服务发布"资料更新"事件
2. 缓存服务监听此事件，更新缓存
3. 搜索服务监听此事件，更新搜索索引
4. 审计服务监听此事件，记录变更日志

#### 事件驱动实战示例
```python
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Type
import threading
from datetime import datetime

class DomainEvent(ABC):
    """领域事件基类"""
    
    def __init__(self, event_type: str, data: Dict[str, Any]):
        self.event_type = event_type
        self.data = data
        self.timestamp = datetime.now()
        self.event_id = self._generate_event_id()
    
    def _generate_event_id(self) -> str:
        """生成事件ID"""
        import uuid
        return str(uuid.uuid4())
    
    def to_dict(self) -> Dict[str, Any]:
        """转换为字典"""
        return {
            'event_id': self.event_id,
            'event_type': self.event_type,
            'data': self.data,
            'timestamp': self.timestamp.isoformat()
        }

class EventDispatcher:
    """事件调度器"""
    
    def __init__(self):
        self._handlers: Dict[str, List[Callable]] = {}
        self._lock = threading.Lock()
    
    def subscribe(self, event_type: str, handler: Callable):
        """订阅事件"""
        with self._lock:
            if event_type not in self._handlers:
                self._handlers[event_type] = []
            self._handlers[event_type].append(handler)
    
    def dispatch(self, event: DomainEvent):
        """分发事件"""
        handlers = self._handlers.get(event.event_type, [])
        
        for handler in handlers:
            try:
                handler(event)
            except Exception as e:
                print(f"Error handling event {event.event_type}: {e}")

# 具体事件类型
class UserCreatedEvent(DomainEvent):
    """用户创建事件"""
    
    def __init__(self, user_id: str, name: str, email: str):
        super().__init__('user.created', {
            'user_id': user_id,
            'name': name,
            'email': email
        })

class OrderPlacedEvent(DomainEvent):
    """订单创建事件"""
    
    def __init__(self, order_id: str, user_id: str, amount: float, items: List[Dict]):
        super().__init__('order.placed', {
            'order_id': order_id,
            'user_id': user_id,
            'amount': amount,
            'items': items
        })

# 事件处理器
class UserEventHandlers:
    """用户事件处理器"""
    
    def __init__(self, user_service, notification_service):
        self.user_service = user_service
        self.notification_service = notification_service
    
    def handle_user_created(self, event: UserCreatedEvent):
        """处理用户创建事件"""
        print(f"Sending welcome email to {event.data['email']}")
        self.notification_service.send_welcome_email(
            event.data['email'], 
            event.data['name']
        )
    
    def handle_user_profile_updated(self, event: DomainEvent):
        """处理用户信息更新事件"""
        print(f"Invalidating cache for user {event.data['user_id']}")
        self.user_service.invalidate_user_cache(event.data['user_id'])

class OrderEventHandlers:
    """订单事件处理器"""
    
    def __init__(self, inventory_service, payment_service):
        self.inventory_service = inventory_service
        self.payment_service = payment_service
    
    def handle_order_placed(self, event: OrderPlacedEvent):
        """处理订单创建事件"""
        # 预留库存
        for item in event.data['items']:
            self.inventory_service.reserve_stock(
                item['product_id'], 
                item['quantity']
            )
        
        # 处理支付
        self.payment_service.charge(
            event.data['user_id'],
            event.data['amount'],
            event.data['order_id']
        )
    
    def handle_payment_succeeded(self, event: DomainEvent):
        """处理支付成功事件"""
        order_id = event.data['order_id']
        print(f"Order {order_id} payment succeeded, processing...")
        
        # 更新订单状态
        # 发送订单确认
        # 触发库存扣减
```

### 3. 发布-订阅模式
```python
import asyncio
from typing import Dict, List, Any
from dataclasses import dataclass
from datetime import datetime

@dataclass
class PublishOptions:
    """发布选项"""
    persistent: bool = True
    ttl: int = 3600  # 消息生存时间（秒）
    priority: int = 0
    correlation_id: str = None
    reply_to: str = None

class PubSubManager:
    """发布-订阅管理器"""
    
    def __init__(self):
        self._topics: Dict[str, List[asyncio.Queue]] = {}
        self._global_subscribers: List[asyncio.Queue] = []
        self._lock = asyncio.Lock()
    
    async def publish(self, topic: str, message: Any, options: PublishOptions = None):
        """发布消息"""
        async with self._lock:
            if topic not in self._topics:
                self._topics[topic] = []
            
            # 发送给主题订阅者
            for queue in self._topics[topic]:
                try:
                    await queue.put({
                        'topic': topic,
                        'message': message,
                        'timestamp': datetime.now(),
                        'options': options or PublishOptions()
                    })
                except asyncio.QueueFull:
                    print(f"Queue full for topic {topic}, message dropped")
            
            # 发送给全局订阅者
            for queue in self._global_subscribers:
                try:
                    await queue.put({
                        'topic': topic,
                        'message': message,
                        'timestamp': datetime.now(),
                        'options': options or PublishOptions()
                    })
                except asyncio.QueueFull:
                    print(f"Global queue full, message dropped")
    
    async def subscribe_to_topic(self, topic: str, maxsize: int = 100) -> asyncio.Queue:
        """订阅主题"""
        async with self._lock:
            if topic not in self._topics:
                self._topics[topic] = []
            
            queue = asyncio.Queue(maxsize=maxsize)
            self._topics[topic].append(queue)
            return queue
    
    async def subscribe_global(self, maxsize: int = 100) -> asyncio.Queue:
        """全局订阅"""
        async with self._lock:
            queue = asyncio.Queue(maxsize=maxsize)
            self._global_subscribers.append(queue)
            return queue
    
    async def unsubscribe_from_topic(self, topic: str, queue: asyncio.Queue):
        """取消主题订阅"""
        async with self._lock:
            if topic in self._topics and queue in self._topics[topic]:
                self._topics[topic].remove(queue)

# 使用示例
class EventBus:
    """事件总线"""
    
    def __init__(self):
        self.pubsub = PubSubManager()
        self.dispatcher = EventDispatcher()
    
    async def publish_event(self, event: DomainEvent):
        """发布领域事件"""
        await self.pubsub.publish(
            topic=event.event_type,
            message=event.to_dict(),
            options=PublishOptions(persistent=True)
        )
    
    async def subscribe_events(self, event_types: List[str]):
        """订阅事件"""
        tasks = []
        for event_type in event_types:
            queue = await self.pubsub.subscribe_to_topic(event_type)
            task = asyncio.create_task(self._handle_events(event_type, queue))
            tasks.append(task)
        
        return tasks
    
    async def _handle_events(self, event_type: str, queue: asyncio.Queue):
        """处理事件"""
        while True:
            try:
                event_data = await queue.get()
                # 创建领域事件并分发
                event = self._create_domain_event(event_data)
                self.dispatcher.dispatch(event)
            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"Error handling event {event_type}: {e}")
    
    def _create_domain_event(self, event_data: Dict) -> DomainEvent:
        """根据数据创建领域事件"""
        event_type = event_data['message']['event_type']
        event_data_content = event_data['message']['data']
        
        if event_type == 'user.created':
            return UserCreatedEvent(**event_data_content)
        elif event_type == 'order.placed':
            return OrderPlacedEvent(**event_data_content)
        else:
            return DomainEvent(event_type, event_data_content)
```

## 通信协议选择

### 1. 协议对比分析
```python
class ProtocolComparison:
    """通信协议对比"""
    
    def __init__(self):
        self.protocols = {
            'http_rest': {
                'latency': 'low',
                'throughput': 'medium',
                'reliability': 'high',
                'complexity': 'low',
                'caching': 'excellent',
                'documentation': 'excellent',
                'browser_support': 'yes',
                'ideal_for': ['CRUD operations', 'public APIs', 'simple integrations']
            },
            'grpc': {
                'latency': 'very_low',
                'throughput': 'very_high',
                'reliability': 'high',
                'complexity': 'medium',
                'caching': 'none',
                'documentation': 'good',
                'browser_support': 'no',
                'ideal_for': ['microservices', 'high performance', 'real-time']
            },
            'websocket': {
                'latency': 'very_low',
                'throughput': 'high',
                'reliability': 'medium',
                'complexity': 'medium',
                'caching': 'none',
                'documentation': 'good',
                'browser_support': 'yes',
                'ideal_for': ['real-time communication', 'chat', 'live updates']
            },
            'message_queue': {
                'latency': 'high',
                'throughput': 'very_high',
                'reliability': 'very_high',
                'complexity': 'high',
                'caching': 'built_in',
                'documentation': 'good',
                'browser_support': 'no',
                'ideal_for': ['async processing', 'event driven', 'reliable delivery']
            }
        }
    
    def recommend_protocol(self, requirements: Dict[str, Any]) -> str:
        """根据需求推荐协议"""
        scores = {}
        
        for protocol, specs in self.protocols.items():
            score = 0
            
            # 性能要求
            if 'low_latency' in requirements and specs['latency'] in ['very_low', 'low']:
                score += 3
            if 'high_throughput' in requirements and specs['throughput'] in ['very_high', 'high']:
                score += 3
            if 'high_reliability' in requirements and specs['reliability'] == 'very_high':
                score += 3
            
            # 功能要求
            if 'needs_caching' in requirements and specs['caching'] != 'none':
                score += 2
            if 'browser_client' in requirements and specs['browser_support'] == 'yes':
                score += 2
            if 'async_processing' in requirements and specs['ideal_for'] == 'async processing':
                score += 2
            
            scores[protocol] = score
        
        return max(scores, key=scores.get)

# 使用示例
comparator = ProtocolComparison()

# 场景1：高性能微服务间通信
requirements1 = {
    'low_latency': True,
    'high_throughput': True,
    'high_reliability': True,
    'browser_client': False
}
recommended1 = comparator.recommend_protocol(requirements1)
print(f"Recommended protocol for high-performance microservices: {recommended1}")  # grpc

# 场景2：公开API服务
requirements2 = {
    'browser_client': True,
    'needs_caching': True,
    'low_latency': False,
    'high_reliability': True
}
recommended2 = comparator.recommend_protocol(requirements2)
print(f"Recommended protocol for public API: {recommended2}")  # http_rest
```

### 2. 协议适配器模式
```python
from abc import ABC, abstractmethod
from typing import Any, Dict

class ServiceProtocol(ABC):
    """服务协议抽象"""
    
    @abstractmethod
    async def send(self, request: Dict[str, Any]) -> Dict[str, Any]:
        pass
    
    @abstractmethod
    async def receive(self) -> Dict[str, Any]:
        pass

class HTTPProtocol(ServiceProtocol):
    """HTTP协议实现"""
    
    def __init__(self, base_url: str):
        self.client = AsyncHTTPServiceClient(base_url)
    
    async def send(self, request: Dict[str, Any]) -> Dict[str, Any]:
        method = request.get('method', 'GET')
        path = request.get('path', '/')
        data = request.get('data', {})
        
        if method == 'GET':
            response = await self.client.get(path, params=data)
        elif method == 'POST':
            response = await self.client.post(path, json=data)
        elif method == 'PUT':
            response = await self.client.put(path, json=data)
        elif method == 'DELETE':
            response = await self.client.delete(path)
        else:
            raise ValueError(f"Unsupported HTTP method: {method}")
        
        return {
            'status': response.status,
            'data': await response.json() if response.status == 200 else None,
            'headers': dict(response.headers)
        }
    
    async def receive(self) -> Dict[str, Any]:
        # HTTP是请求-响应模式，不支持主动接收
        raise NotImplementedError("HTTP protocol doesn't support receiving")

class gRPCProtocol(ServiceProtocol):
    """gRPC协议实现"""
    
    def __init__(self, service_stub):
        self.stub = service_stub
    
    async def send(self, request: Dict[str, Any]) -> Dict[str, Any]:
        method = request.get('method')
        data = request.get('data', {})
        
        if method == 'get_user':
            response = await self.stub.GetUser(
                user_service_pb2.GetUserRequest(user_id=data['user_id'])
            )
            return {'status': 200, 'data': self._serialize_user(response)}
        elif method == 'create_user':
            response = await self.stub.CreateUser(
                user_service_pb2.CreateUserRequest(
                    name=data['name'],
                    email=data['email']
                )
            )
            return {'status': 200, 'data': self._serialize_user(response)}
        else:
            raise ValueError(f"Unsupported gRPC method: {method}")
    
    async def receive(self) -> Dict[str, Any]:
        # gRPC流式接收（需要单独实现流式服务）
        raise NotImplementedError("Streaming gRPC not implemented")
    
    def _serialize_user(self, user) -> Dict[str, Any]:
        return {
            'id': user.id,
            'name': user.name,
            'email': user.email,
            'created_at': user.created_at
        }

class ProtocolAdapter:
    """协议适配器"""
    
    def __init__(self, protocol: ServiceProtocol):
        self.protocol = protocol
    
    async def call_service(self, method: str, **kwargs) -> Dict[str, Any]:
        """调用服务"""
        request = {
            'method': method,
            'data': kwargs
        }
        
        response = await self.protocol.send(request)
        
        if response['status'] != 200:
            raise Exception(f"Service call failed with status {response['status']}")
        
        return response['data']
    
    async def receive_notifications(self) -> Dict[str, Any]:
        """接收通知（如果协议支持）"""
        return await self.protocol.receive()

# 使用示例
async def example_protocol_usage():
    # HTTP协议
    http_adapter = ProtocolAdapter(HTTPProtocol('http://user-service:8080'))
    user = await http_adapter.call_service('get', user_id='123')
    print(f"HTTP User: {user}")
    
    # gRPC协议
    grpc_client = AsyncUserServiceClient('localhost:50051')
    grpc_adapter = ProtocolAdapter(gRPCProtocol(grpc_client))
    user = await grpc_adapter.call_service('get_user', user_id='123')
    print(f"gRPC User: {user}")
```

## 数据序列化

### 1. 序列化格式对比
```python
import json
import pickle
import msgpack
import yaml
from datetime import datetime, date

class DataSerializer:
    """数据序列化器"""
    
    @staticmethod
    def to_json(obj: Any) -> str:
        """JSON序列化"""
        def json_serializer(obj):
            if isinstance(obj, (datetime, date)):
                return obj.isoformat()
            raise TypeError(f"Object of type {type(obj)} is not JSON serializable")
        
        return json.dumps(obj, default=json_serializer)
    
    @staticmethod
    def from_json(json_str: str) -> Any:
        """JSON反序列化"""
        def json_deserializer(obj):
            return obj
        
        return json.loads(json_str, object_hook=json_deserializer)
    
    @staticmethod
    def to_msgpack(obj: Any) -> bytes:
        """MessagePack序列化"""
        def msgpack_serializer(obj):
            if isinstance(obj, (datetime, date)):
                return obj.isoformat()
            return obj
        
        return msgpack.packb(obj, default=msgpack_serializer, use_bin_type=True)
    
    @staticmethod
    def from_msgpack(data: bytes) -> Any:
        """MessagePack反序列化"""
        def msgpack_deserializer(obj):
            return obj
        
        return msgpack.unpackb(data, object_hook=msgpack_deserializer, raw=False)
    
    @staticmethod
    def to_yaml(obj: Any) -> str:
        """YAML序列化"""
        return yaml.dump(obj, default_flow_style=False)
    
    @staticmethod
    def from_yaml(yaml_str: str) -> Any:
        """YAML反序列化"""
        return yaml.safe_load(yaml_str)

# 序列化性能对比
import time

def compare_serialization():
    """对比不同序列化方式的性能"""
    test_data = {
        'users': [
            {
                'id': i,
                'name': f'User {i}',
                'email': f'user{i}@example.com',
                'created_at': datetime.now().isoformat(),
                'metadata': {
                    'role': 'user',
                    'permissions': ['read', 'write'] if i % 2 == 0 else ['read'],
                    'settings': {'theme': 'dark', 'language': 'en'}
                }
            }
            for i in range(1000)
        ]
    }
    
    # JSON
    start = time.time()
    json_data = DataSerializer.to_json(test_data)
    json_deserialized = DataSerializer.from_json(json_data)
    json_time = time.time() - start
    
    # MessagePack
    start = time.time()
    msgpack_data = DataSerializer.to_msgpack(test_data)
    msgpack_deserialized = DataSerializer.from_msgpack(msgpack_data)
    msgpack_time = time.time() - start
    
    print(f"JSON serialization time: {json_time:.4f}s")
    print(f"JSON size: {len(json_data)} bytes")
    print(f"MessagePack serialization time: {msgpack_time:.4f}s")
    print(f"MessagePack size: {len(msgpack_data)} bytes")
    print(f"Performance improvement: {(json_time / msgpack_time):.2f}x")
    print(f"Size reduction: {(1 - len(msgpack_data) / len(json_data)) * 100:.1f}%")
```

### 2. 版本化序列化
```python
from typing import Dict, Any, Optional
import json

class VersionedData:
    """版本化数据"""
    
    def __init__(self, version: str, data: Any, metadata: Optional[Dict] = None):
        self.version = version
        self.data = data
        self.metadata = metadata or {}
        self.timestamp = datetime.now().isoformat()
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'version': self.version,
            'data': self.data,
            'metadata': self.metadata,
            'timestamp': self.timestamp
        }

class BackwardCompatibleSerializer:
    """向后兼容序列化器"""
    
    def __init__(self):
        self.migration_rules: Dict[str, Dict[str, callable]] = {}
        self.current_version = '1.0'
    
    def register_migration(self, from_version: str, to_version: str, 
                          migration_func: callable):
        """注册迁移规则"""
        if from_version not in self.migration_rules:
            self.migration_rules[from_version] = {}
        self.migration_rules[from_version][to_version] = migration_func
    
    def serialize(self, obj: Any, version: str = None) -> str:
        """序列化"""
        versioned_data = VersionedData(
            version=version or self.current_version,
            data=obj
        )
        return json.dumps(versioned_data.to_dict())
    
    def deserialize(self, serialized_data: str, target_version: str = None) -> Any:
        """反序列化并迁移"""
        versioned_data = json.loads(serialized_data)
        
        current_version = versioned_data['version']
        target = target_version or self.current_version
        
        if current_version == target:
            return versioned_data['data']
        
        # 执行版本迁移
        migrated_data = versioned_data['data']
        
        # 按路径迁移到目标版本
        while current_version != target:
            if current_version not in self.migration_rules:
                raise ValueError(f"No migration rule from version {current_version}")
            
            # 选择下一个版本（简化实现，实际应该是多路径迁移）
            next_versions = self.migration_rules[current_version].keys()
            if not next_versions:
                raise ValueError(f"No migration path from version {current_version}")
            
            next_version = next(iter(next_versions))
            migration_func = self.migration_rules[current_version][next_version]
            
            migrated_data = migration_func(migrated_data)
            current_version = next_version
        
        return migrated_data

# 迁移规则示例
def user_v1_to_v2_migration(data: Dict[str, Any]) -> Dict[str, Any]:
    """用户数据从v1迁移到v2"""
    migrated = data.copy()
    
    # 添加新字段
    migrated['profile'] = {
        'display_name': migrated.get('name', ''),
        'bio': '',
        'avatar_url': ''
    }
    
    # 重命名字段
    if 'email' in migrated:
        migrated['email_address'] = migrated.pop('email')
    
    # 移动字段位置
    if 'metadata' in migrated:
        migrated['extended_metadata'] = migrated['metadata']
        del migrated['metadata']
    
    return migrated

def user_v2_to_v3_migration(data: Dict[str, Any]) -> Dict[str, Any]:
    """用户数据从v2迁移到v3"""
    migrated = data.copy()
    
    # 拆分profile
    if 'profile' in migrated:
        profile = migrated['profile']
        migrated['personal_info'] = {
            'display_name': profile.get('display_name', ''),
            'bio': profile.get('bio', ''),
            'avatar_url': profile.get('avatar_url', '')
        }
        del migrated['profile']
    
    # 添加新字段
    migrated['preferences'] = {
        'notifications': True,
        'privacy_level': 'public'
    }
    
    return migrated

# 使用示例
serializer = BackwardCompatibleSerializer()
serializer.register_migration('1.0', '2.0', user_v1_to_v2_migration)
serializer.register_migration('2.0', '3.0', user_v2_to_v3_migration)

# 序列化老版本数据
old_data = {
    'id': '123',
    'name': 'John Doe',
    'email': 'john@example.com',
    'metadata': {'created_by': 'admin'}
}

serialized = serializer.serialize(old_data, '1.0')
print(f"Serialized (v1.0): {serialized}")

# 迁移到当前版本
migrated = serializer.deserialize(serialized)
print(f"Migrated (v3.0): {json.dumps(migrated, indent=2)}")
```

## 错误处理和重试

### 1. 错误分类和处理策略
```python
from enum import Enum
from typing import Optional, Dict, Any
import logging

class ErrorType(Enum):
    """错误类型"""
    NETWORK_ERROR = "network_error"
    TIMEOUT_ERROR = "timeout_error"
    RATE_LIMIT_ERROR = "rate_limit_error"
    AUTHENTICATION_ERROR = "authentication_error"
    AUTHORIZATION_ERROR = "authorization_error"
    VALIDATION_ERROR = "validation_error"
    NOT_FOUND_ERROR = "not_found_error"
    INTERNAL_ERROR = "internal_error"
    SERVICE_UNAVAILABLE = "service_unavailable"
    CIRCUIT_BREAKER_OPEN = "circuit_breaker_open"

class ServiceError(Exception):
    """服务错误基类"""
    
    def __init__(self, error_type: ErrorType, message: str, 
                 status_code: Optional[int] = None, 
                 details: Optional[Dict[str, Any]] = None):
        self.error_type = error_type
        self.message = message
        self.status_code = status_code
        self.details = details or {}
        super().__init__(self.message)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'error_type': self.error_type.value,
            'message': self.message,
            'status_code': self.status_code,
            'details': self.details
        }

class ErrorHandler:
    """错误处理器"""
    
    def __init__(self):
        self.retry_strategies = {
            ErrorType.NETWORK_ERROR: {'max_retries': 3, 'backoff': 2.0},
            ErrorType.TIMEOUT_ERROR: {'max_retries': 2, 'backoff': 1.5},
            ErrorType.RATE_LIMIT_ERROR: {'max_retries': 5, 'backoff': 3.0},
            ErrorType.SERVICE_UNAVAILABLE: {'max_retries': 3, 'backoff': 2.0},
            ErrorType.CIRCUIT_BREAKER_OPEN: {'max_retries': 1, 'backoff': 5.0}
        }
        self.logger = logging.getLogger(__name__)
    
    def should_retry(self, error: ServiceError) -> bool:
        """判断是否应该重试"""
        return error.error_type in self.retry_strategies
    
    def get_retry_config(self, error: ServiceError) -> Dict[str, Any]:
        """获取重试配置"""
        return self.retry_strategies.get(error.error_type, {})
    
    def handle_error(self, error: ServiceError) -> None:
        """处理错误"""
        self.logger.error(f"Service error: {error.to_dict()}")
        
        if error.error_type == ErrorType.AUTHENTICATION_ERROR:
            # 触发重新认证流程
            self._trigger_reauthentication()
        elif error.error_type == ErrorType.AUTHORIZATION_ERROR:
            # 记录授权失败
            self._log_authorization_failure(error)
        elif error.error_type == ErrorType.VALIDATION_ERROR:
            # 返回详细验证错误信息
            self._handle_validation_error(error)
    
    def _trigger_reauthentication(self):
        """触发重新认证"""
        self.logger.info("Triggering reauthentication")
        # 实现重新认证逻辑
    
    def _log_authorization_failure(self, error: ServiceError):
        """记录授权失败"""
        self.logger.warning(f"Authorization failed: {error.message}")
        # 实现授权失败处理
    
    def _handle_validation_error(self, error: ServiceError):
        """处理验证错误"""
        self.logger.info(f"Validation error: {error.message}")
        # 实现验证错误处理

# 错误映射
class ErrorMapping:
    """HTTP状态码到错误类型映射"""
    
    @staticmethod
    def from_http_status(status_code: int, response_data: Dict = None) -> ErrorType:
        """从HTTP状态码映射到错误类型"""
        mapping = {
            400: ErrorType.VALIDATION_ERROR,
            401: ErrorType.AUTHENTICATION_ERROR,
            403: ErrorType.AUTHORIZATION_ERROR,
            404: ErrorType.NOT_FOUND_ERROR,
            429: ErrorType.RATE_LIMIT_ERROR,
            500: ErrorType.INTERNAL_ERROR,
            502: ErrorType.SERVICE_UNAVAILABLE,
            503: ErrorType.SERVICE_UNAVAILABLE,
            504: ErrorType.TIMEOUT_ERROR
        }
        
        return mapping.get(status_code, ErrorType.INTERNAL_ERROR)
```

### 2. 高级重试策略
```python
import asyncio
from typing import Optional, Callable, Any
import random

class ExponentialBackoffRetry:
    """指数退避重试策略"""
    
    def __init__(self, initial_delay: float = 1.0, 
                 max_delay: float = 60.0, 
                 max_retries: int = 3,
                 backoff_multiplier: float = 2.0,
                 jitter: bool = True):
        self.initial_delay = initial_delay
        self.max_delay = max_delay
        self.max_retries = max_retries
        self.backoff_multiplier = backoff_multiplier
        self.jitter = jitter
    
    async def retry(self, func: Callable, *args, **kwargs) -> Any:
        """执行重试"""
        last_exception = None
        
        for attempt in range(self.max_retries + 1):
            try:
                return await func(*args, **kwargs)
            except Exception as e:
                last_exception = e
                
                if attempt < self.max_retries:
                    delay = self._calculate_delay(attempt)
                    await asyncio.sleep(delay)
                else:
                    break
        
        raise last_exception
    
    def _calculate_delay(self, attempt: int) -> float:
        """计算重试延迟"""
        delay = self.initial_delay * (self.backoff_multiplier ** attempt)
        delay = min(delay, self.max_delay)
        
        if self.jitter:
            # 添加随机抖动，避免雷群效应
            jitter_range = delay * 0.1
            delay += random.uniform(-jitter_range, jitter_range)
        
        return max(0, delay)

class CircuitBreakerRetry:
    """断路器重试策略"""
    
    def __init__(self, failure_threshold: int = 5, 
                 timeout: float = 60.0,
                 success_threshold: int = 3):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.success_threshold = success_threshold
        self.failure_count = 0
        self.success_count = 0
        self.last_failure_time = None
        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN
        self._lock = asyncio.Lock()
    
    async def retry_with_circuit_breaker(self, func: Callable, *args, **kwargs) -> Any:
        """带断路器的重试"""
        async with self._lock:
            if self.state == 'OPEN':
                if self._should_attempt_reset():
                    self.state = 'HALF_OPEN'
                else:
                    raise ServiceError(ErrorType.CIRCUIT_BREAKER_OPEN, 
                                     "Circuit breaker is OPEN")
        
        try:
            result = await func(*args, **kwargs)
            await self._on_success()
            return result
        except Exception as e:
            await self._on_failure()
            raise e
    
    def _should_attempt_reset(self) -> bool:
        """检查是否应该尝试重置断路器"""
        return (self.last_failure_time and 
                asyncio.get_event_loop().time() - self.last_failure_time >= self.timeout)
    
    async def _on_success(self):
        """成功回调"""
        async with self._lock:
            if self.state == 'HALF_OPEN':
                self.success_count += 1
                if self.success_count >= self.success_threshold:
                    self.failure_count = 0
                    self.success_count = 0
                    self.state = 'CLOSED'
            else:
                self.failure_count = max(0, self.failure_count - 1)
    
    async def _on_failure(self):
        """失败回调"""
        async with self._lock:
            self.failure_count += 1
            self.last_failure_time = asyncio.get_event_loop().time()
            
            if self.failure_count >= self.failure_threshold:
                self.state = 'OPEN'

class AdaptiveRetry:
    """自适应重试策略"""
    
    def __init__(self, initial_delay: float = 1.0, 
                 max_retries: int = 5):
        self.initial_delay = initial_delay
        self.max_retries = max_retries
        self.retry_history = []
    
    async def adaptive_retry(self, func: Callable, error_handler: ErrorHandler, 
                           *args, **kwargs) -> Any:
        """自适应重试"""
        last_exception = None
        
        for attempt in range(self.max_retries + 1):
            try:
                result = await func(*args, **kwargs)
                
                # 记录成功信息
                self._record_success(attempt)
                
                return result
                
            except ServiceError as e:
                last_exception = e
                error_handler.handle_error(e)
                
                # 根据错误类型和历史记录调整策略
                if not error_handler.should_retry(e):
                    raise e
                
                delay = self._calculate_adaptive_delay(attempt, e)
                await asyncio.sleep(delay)
                
            except Exception as e:
                # 非预期错误，不重试
                raise e
        
        raise last_exception
    
    def _calculate_adaptive_delay(self, attempt: int, error: ServiceError) -> float:
        """计算自适应延迟"""
        base_delay = self.initial_delay * (2 ** attempt)
        
        # 根据错误类型调整
        retry_config = error_handler.get_retry_config(error)
        if retry_config:
            base_delay = base_delay * retry_config.get('backoff', 2.0)
        
        # 根据历史成功率调整
        success_rate = self._get_recent_success_rate()
        if success_rate < 0.5:
            base_delay *= 2  # 成功率低，增加延迟
        
        return min(base_delay, 60.0)
    
    def _record_success(self, attempt: int):
        """记录成功信息"""
        self.retry_history.append({
            'attempt': attempt,
            'success': True,
            'timestamp': asyncio.get_event_loop().time()
        })
        
        # 只保留最近100次记录
        if len(self.retry_history) > 100:
            self.retry_history = self.retry_history[-100:]
    
    def _get_recent_success_rate(self) -> float:
        """获取最近的成功率"""
        if not self.retry_history:
            return 1.0
        
        recent = self.retry_history[-20:]  # 最近20次
        successful = sum(1 for record in recent if record['success'])
        return successful / len(recent)

# 综合重试包装器
class RetryableServiceClient:
    """可重试的服务客户端"""
    
    def __init__(self):
        self.retry_strategies = {
            'exponential_backoff': ExponentialBackoffRetry(),
            'circuit_breaker': CircuitBreakerRetry(),
            'adaptive': AdaptiveRetry()
        }
        self.error_handler = ErrorHandler()
    
    async def call_with_retry(self, func: Callable, 
                            retry_strategy: str = 'adaptive',
                            *args, **kwargs) -> Any:
        """使用指定策略调用函数"""
        retry_strategy_obj = self.retry_strategies[retry_strategy]
        
        if retry_strategy == 'circuit_breaker':
            return await retry_strategy_obj.retry_with_circuit_breaker(func, *args, **kwargs)
        elif retry_strategy == 'adaptive':
            return await retry_strategy_obj.adaptive_retry(func, self.error_handler, *args, **kwargs)
        else:
            return await retry_strategy_obj.retry(func, *args, **kwargs)
```

## 性能优化

### 1. 连接池管理
```python
import asyncio
import aiohttp
from typing import Dict, Optional
import time

class ConnectionPool:
    """连接池管理器"""
    
    def __init__(self, max_connections: int = 100, 
                 max_connections_per_host: int = 30,
                 keepalive_timeout: int = 30):
        self.max_connections = max_connections
        self.max_connections_per_host = max_connections_per_host
        self.keepalive_timeout = keepalive_timeout
        self._pools: Dict[str, aiohttp.TCPConnector] = {}
        self._locks: Dict[str, asyncio.Lock] = {}
    
    async def get_session(self, host: str, port: int = 80) -> aiohttp.ClientSession:
        """获取客户端会话"""
        key = f"{host}:{port}"
        
        if key not in self._pools:
            async with self._locks.setdefault(key, asyncio.Lock()):
                if key not in self._pools:  # 双重检查
                    connector = aiohttp.TCPConnector(
                        limit=self.max_connections,
                        limit_per_host=self.max_connections_per_host,
                        keepalive_timeout=self.keepalive_timeout,
                        enable_cleanup_closed=True
                    )
                    self._pools[key] = connector
        
        connector = self._pools[key]
        timeout = aiohttp.ClientTimeout(total=30, connect=10)
        
        return aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'Connection': 'keep-alive'}
        )
    
    async def close_all(self):
        """关闭所有连接"""
        for connector in self._pools.values():
            await connector.close()
        self._pools.clear()

class ConnectionPoolManager:
    """连接池管理器"""
    
    def __init__(self):
        self.pools: Dict[str, ConnectionPool] = {}
    
    def get_pool(self, service_name: str, 
                host: str, port: int = 80,
                max_connections: int = 100) -> ConnectionPool:
        """获取服务连接池"""
        key = f"{service_name}:{host}:{port}"
        
        if key not in self.pools:
            self.pools[key] = ConnectionPool(max_connections=max_connections)
        
        return self.pools[key]
    
    async def close_all_pools(self):
        """关闭所有连接池"""
        for pool in self.pools.values():
            await pool.close_all()
        self.pools.clear()

# HTTP连接池客户端
class PooledHTTPClient:
    """带连接池的HTTP客户端"""
    
    def __init__(self, pool_manager: ConnectionPoolManager):
        self.pool_manager = pool_manager
        self.active_sessions: Dict[str, aiohttp.ClientSession] = {}
    
    async def get_session(self, service_name: str, host: str, port: int = 80) -> aiohttp.ClientSession:
        """获取HTTP会话"""
        key = f"{service_name}:{host}:{port}"
        
        if key not in self.active_sessions:
            pool = self.pool_manager.get_pool(service_name, host, port)
            self.active_sessions[key] = await pool.get_session(host, port)
        
        return self.active_sessions[key]
    
    async def make_request(self, service_name: str, host: str, port: int,
                          method: str, path: str, **kwargs) -> aiohttp.ClientResponse:
        """发起HTTP请求"""
        session = await self.get_session(service_name, host, port)
        url = f"http://{host}:{port}{path}"
        
        async with session.request(method, url, **kwargs) as response:
            return response
    
    async def close(self):
        """关闭所有会话"""
        for session in self.active_sessions.values():
            await session.close()
        self.active_sessions.clear()
        await self.pool_manager.close_all_pools()
```

### 2. 请求批处理和合并
```python
from collections import defaultdict
from typing import List, Dict, Any, Callable
import asyncio

class RequestBatcher:
    """请求批处理器"""
    
    def __init__(self, batch_size: int = 10, 
                 max_wait_time: float = 0.1):
        self.batch_size = batch_size
        self.max_wait_time = max_wait_time
        self.pending_requests: Dict[str, List[Dict]] = defaultdict(list)
        self.processors: Dict[str, Callable] = {}
        self.running = False
    
    def register_processor(self, request_type: str, processor: Callable):
        """注册批处理器"""
        self.processors[request_type] = processor
    
    async def add_request(self, request_type: str, request_data: Dict[str, Any]) -> Any:
        """添加请求到批处理"""
        if request_type not in self.processors:
            raise ValueError(f"No processor registered for request type: {request_type}")
        
        future = asyncio.Future()
        
        self.pending_requests[request_type].append({
            'data': request_data,
            'future': future
        })
        
        # 检查是否需要立即处理
        if len(self.pending_requests[request_type]) >= self.batch_size:
            await self._process_batch(request_type)
        
        return await future
    
    async def start_batching(self):
        """启动批处理"""
        self.running = True
        
        while self.running:
            await asyncio.sleep(self.max_wait_time)
            
            # 处理所有到达批处理时间的请求
            for request_type in list(self.pending_requests.keys()):
                if self.pending_requests[request_type]:
                    await self._process_batch(request_type)
    
    async def stop_batching(self):
        """停止批处理"""
        self.running = False
    
    async def _process_batch(self, request_type: str):
        """处理一批请求"""
        if not self.pending_requests[request_type]:
            return
        
        batch = self.pending_requests[request_type]
        self.pending_requests[request_type] = []
        
        # 准备批处理数据
        batch_data = [req['data'] for req in batch]
        
        try:
            # 调用批处理器
            results = await self.processors[request_type](batch_data)
            
            # 分发结果
            for i, req in enumerate(batch):
                result = results[i] if isinstance(results, list) else results
                if not req['future'].done():
                    req['future'].set_result(result)
                    
        except Exception as e:
            # 设置异常
            for req in batch:
                if not req['future'].done():
                    req['future'].set_exception(e)

# 批处理示例：用户信息批量获取
class BatchUserService:
    """批处理用户服务"""
    
    def __init__(self, user_repository):
        self.user_repository = user_repository
        self.batcher = RequestBatcher(batch_size=5, max_wait_time=0.05)
        
        # 注册批处理器
        self.batcher.register_processor('get_users', self._batch_get_users)
    
    async def get_user(self, user_id: str) -> Dict[str, Any]:
        """获取单个用户（自动批处理）"""
        return await self.batcher.add_request('get_users', {'user_id': user_id})
    
    async def _batch_get_users(self, batch_data: List[Dict]) -> List[Dict[str, Any]]:
        """批量获取用户"""
        user_ids = [req['user_id'] for req in batch_data]
        
        # 批量查询数据库
        users = await self.user_repository.batch_get_users(user_ids)
        
        # 按请求顺序返回结果
        results = []
        for req in batch_data:
            user_id = req['user_id']
            user = next((u for u in users if u['id'] == user_id), None)
            results.append(user)
        
        return results

# 预取和缓存
class PrefetchCache:
    """预取缓存"""
    
    def __init__(self, cache_ttl: int = 300):
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.cache_timestamps: Dict[str, float] = {}
        self.cache_ttl = cache_ttl
        self.lock = asyncio.Lock()
    
    async def get(self, key: str) -> Optional[Any]:
        """获取缓存"""
        async with self.lock:
            if key in self.cache:
                timestamp = self.cache_timestamps[key]
                if asyncio.get_event_loop().time() - timestamp < self.cache_ttl:
                    return self.cache[key]
                else:
                    # 缓存过期，删除
                    del self.cache[key]
                    del self.cache_timestamps[key]
            return None
    
    async def set(self, key: str, value: Any):
        """设置缓存"""
        async with self.lock:
            self.cache[key] = value
            self.cache_timestamps[key] = asyncio.get_event_loop().time()
    
    async def prefetch(self, fetch_func: Callable, keys: List[str]) -> Dict[str, Any]:
        """预取数据"""
        results = {}
        
        # 获取未缓存的键
        uncached_keys = []
        async with self.lock:
            for key in keys:
                cached_value = await self.get(key)
                if cached_value is not None:
                    results[key] = cached_value
                else:
                    uncached_keys.append(key)
        
        if uncached_keys:
            # 批量获取未缓存的数据
            fetched_data = await fetch_func(uncached_keys)
            
            # 缓存并添加到结果
            for key in uncached_keys:
                if key in fetched_data:
                    value = fetched_data[key]
                    await self.set(key, value)
                    results[key] = value
        
        return results
```

## 监控和观测

### 为什么需要监控和观测？

想象一下，你经营一家餐厅，但你从未关注过：
- 每道菜的平均制作时间
- 顾客的平均等待时间
- 最受欢迎的菜品
- 厨房设备的工作状态

没有这些信息，你很难知道哪里需要改进，哪里可能出现问题。微服务系统的监控和观测也是同样的道理，它帮助我们：

1. **发现性能瓶颈**：像找出餐厅中最忙碌的时段
2. **快速定位问题**：类似找出为什么某道菜制作变慢了
3. **预测系统容量**：像规划餐厅需要多少张桌子
4. **优化资源使用**：如合理安排厨房人员班次

### 1. 性能指标收集
```python
import time
import asyncio
from typing import Dict, List, Optional
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import statistics

@dataclass
class RequestMetrics:
    """请求指标"""
    timestamp: float
    duration: float
    status_code: Optional[int] = None
    error_type: Optional[str] = None
    service_name: str = ""
    endpoint: str = ""

@dataclass
class ServiceMetrics:
    """服务指标"""
    service_name: str
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    avg_response_time: float = 0.0
    p50_response_time: float = 0.0
    p95_response_time: float = 0.0
    p99_response_time: float = 0.0
    throughput: float = 0.0
    error_rate: float = 0.0
    last_updated: float = field(default_factory=time.time)

class MetricsCollector:
    """指标收集器"""
    
    def __init__(self, retention_period: int = 3600):  # 1小时
        self.retention_period = retention_period
        self.request_metrics: List[RequestMetrics] = []
        self.service_metrics: Dict[str, ServiceMetrics] = {}
        self.lock = asyncio.Lock()
    
    async def record_request(self, metrics: RequestMetrics):
        """记录请求指标"""
        async with self.lock:
            self.request_metrics.append(metrics)
            
            # 更新服务指标
            service_name = metrics.service_name
            if service_name not in self.service_metrics:
                self.service_metrics[service_name] = ServiceMetrics(
                    service_name=service_name
                )
            
            service_metrics = self.service_metrics[service_name]
            service_metrics.total_requests += 1
            
            if metrics.status_code and 200 <= metrics.status_code < 400:
                service_metrics.successful_requests += 1
            else:
                service_metrics.failed_requests += 1
            
            # 更新响应时间统计
            await self._update_response_time_stats(service_metrics, metrics.duration)
            
            # 清理过期指标
            await self._cleanup_old_metrics()
    
    async def _update_response_time_stats(self, service_metrics: ServiceMetrics, duration: float):
        """更新响应时间统计"""
        # 获取最近100个请求的响应时间
        recent_durations = [
            m.duration for m in self.request_metrics[-100:]
            if m.service_name == service_metrics.service_name
        ]
        
        if recent_durations:
            service_metrics.avg_response_time = statistics.mean(recent_durations)
            service_metrics.p50_response_time = statistics.median(recent_durations)
            service_metrics.p95_response_time = self._calculate_percentile(recent_durations, 95)
            service_metrics.p99_response_time = self._calculate_percentile(recent_durations, 99)
    
    def _calculate_percentile(self, data: List[float], percentile: int) -> float:
        """计算百分位数"""
        if not data:
            return 0.0
        
        sorted_data = sorted(data)
        index = (percentile / 100) * (len(sorted_data) - 1)
        
        if index.is_integer():
            return sorted_data[int(index)]
        else:
            lower = sorted_data[int(index)]
            upper = sorted_data[int(index) + 1]
            return lower + (upper - lower) * (index - int(index))
    
    async def _cleanup_old_metrics(self):
        """清理过期指标"""
        cutoff_time = time.time() - self.retention_period
        
        # 清理请求指标
        self.request_metrics = [
            m for m in self.request_metrics
            if m.timestamp > cutoff_time
        ]
    
    async def get_service_metrics(self, service_name: str) -> Optional[ServiceMetrics]:
        """获取服务指标"""
        async with self.lock:
            return self.service_metrics.get(service_name)
    
    async def get_all_metrics(self) -> Dict[str, ServiceMetrics]:
        """获取所有服务指标"""
        async with self.lock:
            return self.service_metrics.copy()

# 带指标收集的HTTP客户端
class InstrumentedHTTPClient:
    """带指标收集的HTTP客户端"""
    
    def __init__(self, base_url: str, metrics_collector: MetricsCollector, 
                 service_name: str):
        self.base_url = base_url
        self.metrics_collector = metrics_collector
        self.service_name = service_name
        self.session = AsyncHTTPServiceClient(base_url)
    
    async def request(self, method: str, path: str, **kwargs) -> aiohttp.ClientResponse:
        """发起请求并收集指标"""
        start_time = time.time()
        request_metrics = RequestMetrics(
            timestamp=start_time,
            duration=0.0,  # 稍后更新
            service_name=self.service_name,
            endpoint=f"{method} {path}"
        )
        
        try:
            response = await self.session.request(method, path, **kwargs)
            
            # 更新指标
            request_metrics.duration = time.time() - start_time
            request_metrics.status_code = response.status
            
            await self.metrics_collector.record_request(request_metrics)
            
            return response
            
        except Exception as e:
            # 记录错误
            request_metrics.duration = time.time() - start_time
            request_metrics.error_type = type(e).__name__
            
            await self.metrics_collector.record_request(request_metrics)
            raise
```

### 2. 分布式追踪

#### 什么是分布式追踪？

想象一下，你在一家大型快递公司工作，需要追踪一个包裹的完整旅程：
1. 从寄件人处揽收
2. 运送到分拣中心
3. 运输到目的地城市
4. 分拣到具体配送站
5. 最后配送到收件人

分布式追踪就像是这个包裹追踪系统，但它追踪的是一次请求在微服务系统中的完整路径。每一个"步骤"就是一个"span"，整个旅程就是一个"trace"。

就像快递单号可以追踪包裹一样，每个请求都有一个唯一的Trace ID，通过它我们可以追踪请求在各个服务间的流转过程。

#### 为什么需要分布式追踪？

在微服务系统中，一个简单的用户请求可能会经过多个服务：
```
用户请求 → API网关 → 用户服务 → 订单服务 → 库存服务 → 支付服务 → 返回结果
```

如果没有追踪，我们就像在黑暗中摸索，不知道：
- 请求在哪个环节变慢了
- 哪个服务出现了错误
- 请求的完整路径是什么样的
- 各个服务的调用关系如何

分布式追踪帮助我们：
1. **可视化调用链**：像看地图一样了解请求路径
2. **定位性能问题**：快速找到慢的环节
3. **分析服务依赖**：了解服务间的调用关系
4. **调试分布式错误**：追踪错误产生的完整上下文
```python
import uuid
from typing import Dict, Any, Optional
from contextlib import asynccontextmanager

class TraceContext:
    """追踪上下文"""
    
    def __init__(self, trace_id: str = None, span_id: str = None, 
                 parent_span_id: str = None):
        self.trace_id = trace_id or str(uuid.uuid4())
        self.span_id = span_id or str(uuid.uuid4())
        self.parent_span_id = parent_span_id
        self.baggage: Dict[str, Any] = {}
        self.start_time = time.time()
        self.tags: Dict[str, str] = {}
        self.logs: List[Dict] = []
    
    def add_tag(self, key: str, value: str):
        """添加标签"""
        self.tags[key] = value
    
    def add_log(self, message: str, **fields):
        """添加日志"""
        self.logs.append({
            'timestamp': time.time(),
            'message': message,
            **fields
        })
    
    def set_baggage_item(self, key: str, value: Any):
        """设置 baggage 项"""
        self.baggage[key] = value
    
    def get_baggage_item(self, key: str, default=None):
        """获取 baggage 项"""
        return self.baggage.get(key, default)

class TraceManager:
    """追踪管理器"""
    
    def __init__(self):
        self.current_context: Optional[TraceContext] = None
        self.span_stack: List[TraceContext] = []
    
    def start_span(self, operation_name: str, parent_context: Optional[TraceContext] = None) -> TraceContext:
        """开始Span"""
        parent_span_id = None
        
        if parent_context:
            parent_span_id = parent_context.span_id
        elif self.current_context:
            parent_span_id = self.current_context.span_id
        
        span = TraceContext(
            parent_span_id=parent_span_id
        )
        
        span.add_tag('operation.name', operation_name)
        
        self.span_stack.append(span)
        self.current_context = span
        
        return span
    
    def finish_span(self, span: Optional[TraceContext] = None):
        """结束Span"""
        if span is None:
            span = self.current_context
        
        if not span:
            return
        
        span.add_tag('duration', str(time.time() - span.start_time))
        
        if self.span_stack and self.span_stack[-1] == span:
            self.span_stack.pop()
        
        if self.span_stack:
            self.current_context = self.span_stack[-1]
        else:
            self.current_context = None
    
    @asynccontextmanager
    async def span(self, operation_name: str):
        """Span上下文管理器"""
        span = self.start_span(operation_name)
        try:
            yield span
        finally:
            self.finish_span(span)

# 带追踪的HTTP客户端
class TracedHTTPClient:
    """带追踪的HTTP客户端"""
    
    def __init__(self, base_url: str, trace_manager: TraceManager):
        self.base_url = base_url
        self.trace_manager = trace_manager
        self.session = AsyncHTTPServiceClient(base_url)
    
    async def request(self, method: str, path: str, **kwargs) -> aiohttp.ClientResponse:
        """发起带追踪的请求"""
        async with self.trace_manager.span(f"http.{method.lower()}.{path.lstrip('/')}"):
            # 添加追踪头
            if self.trace_manager.current_context:
                trace_headers = {
                    'X-Trace-ID': self.trace_manager.current_context.trace_id,
                    'X-Span-ID': self.trace_manager.current_context.span_id,
                    'X-Parent-Span-ID': self.trace_manager.current_context.parent_span_id
                }
                
                if 'headers' not in kwargs:
                    kwargs['headers'] = {}
                kwargs['headers'].update(trace_headers)
            
            # 添加服务标签
            self.trace_manager.current_context.add_tag('http.method', method)
            self.trace_manager.current_context.add_tag('http.url', f"{self.base_url}{path}")
            
            # 发起请求
            response = await self.session.request(method, path, **kwargs)
            
            # 记录响应信息
            self.trace_manager.current_context.add_tag('http.status_code', str(response.status))
            
            if response.status >= 400:
                self.trace_manager.current_context.add_tag('error', 'true')
            
            return response

# 使用示例
async def example_with_tracing():
    trace_manager = TraceManager()
    traced_client = TracedHTTPClient('http://user-service:8080', trace_manager)
    
    # 模拟调用链
    async with trace_manager.span("process_order"):
        # 获取用户信息
        async with trace_manager.span("get_user"):
            user_response = await traced_client.request('GET', '/api/users/123')
            user_data = await user_response.json()
        
        # 创建订单
        async with trace_manager.span("create_order"):
            order_response = await traced_client.request('POST', '/api/orders', 
                                                       json={'user_id': '123', 'items': []})
            order_data = await order_response.json()
    
    # 输出追踪信息
    print(f"Trace completed. Trace ID: {trace_manager.current_context.trace_id}")
    for span in trace_manager.span_stack:
        print(f"Span: {span.tags.get('operation.name')} - {span.span_id}")
```

## 总结

微服务间通信就像人体中的神经系统，选择合适的通信模式对于构建健康、高效的系统至关重要。让我们用旅行的比喻来总结关键要点：

### 选择指南

**1. 同步通信 - 就像预订酒店**
- 适合场景：需要立即确认的事情，如用户登录验证、查询订单状态
- 特点：直接、快速，但需要双方同时在线
- 使用建议：当用户体验需要实时反馈时

**2. 异步通信 - 就像发送快递**
- 适合场景：不需要立即结果的事情，如发送通知邮件、数据分析
- 特点：解耦、可靠，但响应延迟
- 使用建议：当业务流程允许延迟或需要确保消息不丢失时

**3. 混合模式 - 就像旅行套餐**
- 适合场景：复杂业务流程，如电商订单处理
- 特点：结合两种方式的优点
- 使用建议：当业务流程既有实时部分又有异步部分时

### 初学者实践建议

**第一步：选择合适的通信方式**
从简单开始：
- 用户查询用同步（像查地图）
- 发送通知用异步（像发短信）
- 复杂流程用混合（像网购下单）

**第二步：添加必要的安全措施**
- 超时控制：不要让请求无限等待（像餐厅点餐限时）
- 重试机制：给失败的服务第二次机会（像考试补考）
- 断路器：保护系统免受级联故障（像电路保护器）

**第三步：监控和优化**
- 收集性能指标：像记录餐厅的运营数据
- 实施分布式追踪：像追踪包裹的物流信息
- 持续改进：根据数据优化系统性能

### 学习路径建议

1. **先掌握同步通信**：从HTTP/REST开始，这是最常用的方式
2. **再学习异步通信**：了解消息队列，这是微服务解耦的关键
3. **最后掌握高级特性**：如重试策略、断路器、性能优化等

记住，好的微服务通信不仅仅是技术实现，更是架构设计。选择合适的方式，理解其原理，持续优化和改进，这样你的微服务系统才能健康、稳定地运行。