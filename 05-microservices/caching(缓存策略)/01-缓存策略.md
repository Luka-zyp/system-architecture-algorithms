# 缓存策略概述

## 目录
1. [缓存概述](#缓存概述)
2. [缓存架构模式](#缓存架构模式)
3. [缓存策略](#缓存策略)
4. [缓存一致性](#缓存一致性)
5. [缓存穿透与击穿](#缓存穿透与击穿)
6. [分布式缓存](#分布式缓存)
7. [缓存预热与更新](#缓存预热与更新)
8. [缓存监控与优化](#缓存监控与优化)
9. [实际应用案例](#实际应用案例)
10. [最佳实践](#最佳实践)

## 缓存概述

缓存是提升系统性能的重要手段，通过将热点数据存储在高速存储介质中，减少对后端数据源的访问压力。

### 缓存的价值
```
┌─────────────────┐    缓存命中     ┌─────────────────┐
│   应用程序       │───────────────▶│     缓存层       │
└─────────────────┘                └─────────────────┘
       │                                   │
       │ 缓存未命中                         │
       ▼                                   ▼
┌─────────────────┐    查询数据源     ┌─────────────────┐
│   数据源层       │◀─────────────────│   缓存层         │
│ (数据库/文件等)  │                   │ (Redis/Memcached)│
└─────────────────┘                   └─────────────────┘
```

### 缓存的层次结构
```
┌─────────────────────────────────────────┐
│           应用层缓存                      │
│     (内存缓存、本地缓存)                   │
│         访问速度: 纳秒级                   │
└─────────────────┬───────────────────────┘
                  │
┌─────────────────▼───────────────────────┐
│           分布式缓存                      │
│      (Redis Cluster、Memcached)          │
│         访问速度: 微秒级                   │
└─────────────────┬───────────────────────┘
                  │
┌─────────────────▼───────────────────────┐
│           持久化存储                      │
│      (MySQL、PostgreSQL、MongoDB)        │
│         访问速度: 毫秒级                   │
└─────────────────────────────────────────┘
```

## 缓存架构模式

### 1. Cache Aside Pattern（缓存旁路模式）
```python
import asyncio
import time
from typing import Optional, Any, Callable
from dataclasses import dataclass
from enum import Enum

class CacheStrategy(Enum):
    """缓存策略"""
    WRITE_THROUGH = "write_through"      # 写透
    WRITE_BACK = "write_back"            # 写回
    CACHE_ASIDE = "cache_aside"          # 缓存旁路
    READ_THROUGH = "read_through"        # 读透

@dataclass
class CacheEntry:
    """缓存条目"""
    key: str
    value: Any
    expire_time: Optional[float]
    access_count: int = 0
    last_access_time: float = 0.0
    
    def is_expired(self) -> bool:
        """检查是否过期"""
        if self.expire_time is None:
            return False
        return time.time() > self.expire_time
    
    def access(self):
        """记录访问"""
        self.access_count += 1
        self.last_access_time = time.time()

class SimpleCache:
    """简单内存缓存"""
    
    def __init__(self, max_size: int = 1000, default_ttl: float = 3600):
        self.cache: dict[str, CacheEntry] = {}
        self.max_size = max_size
        self.default_ttl = default_ttl
        self.hit_count = 0
        self.miss_count = 0
    
    async def get(self, key: str) -> Optional[Any]:
        """获取缓存值"""
        if key in self.cache:
            entry = self.cache[key]
            
            # 检查是否过期
            if entry.is_expired():
                del self.cache[key]
                self.miss_count += 1
                return None
            
            # 记录访问
            entry.access()
            self.hit_count += 1
            return entry.value
        
        self.miss_count += 1
        return None
    
    async def set(self, key: str, value: Any, ttl: Optional[float] = None):
        """设置缓存值"""
        expire_time = time.time() + (ttl or self.default_ttl)
        
        # 如果缓存已满，清理过期或最少使用的条目
        if len(self.cache) >= self.max_size:
            await self._evict_entries()
        
        self.cache[key] = CacheEntry(
            key=key,
            value=value,
            expire_time=expire_time
        )
    
    async def delete(self, key: str) -> bool:
        """删除缓存值"""
        if key in self.cache:
            del self.cache[key]
            return True
        return False
    
    async def _evict_entries(self):
        """淘汰条目"""
        current_time = time.time()
        
        # 首先清理过期的条目
        expired_keys = [
            key for key, entry in self.cache.items()
            if entry.is_expired()
        ]
        
        for key in expired_keys:
            del self.cache[key]
        
        # 如果还需要清理，使用LRU策略
        if len(self.cache) >= self.max_size:
            # 按最后访问时间排序，清理最少使用的条目
            sorted_entries = sorted(
                self.cache.items(),
                key=lambda x: x[1].last_access_time
            )
            
            # 清理10%的最少使用条目
            evict_count = max(1, len(self.cache) // 10)
            for i in range(evict_count):
                del self.cache[sorted_entries[i][0]]
    
    def get_stats(self) -> dict[str, Any]:
        """获取缓存统计信息"""
        total_requests = self.hit_count + self.miss_count
        hit_rate = self.hit_count / total_requests if total_requests > 0 else 0
        
        return {
            'hit_count': self.hit_count,
            'miss_count': self.miss_count,
            'hit_rate': hit_rate,
            'cache_size': len(self.cache),
            'max_size': self.max_size
        }

class CacheAside:
    """缓存旁路模式"""
    
    def __init__(self, cache: SimpleCache, data_source: Callable):
        self.cache = cache
        self.data_source = data_source
    
    async def get_data(self, key: str) -> Optional[Any]:
        """获取数据（缓存旁路模式）"""
        # 1. 先尝试从缓存获取
        cached_value = await self.cache.get(key)
        if cached_value is not None:
            return cached_value
        
        # 2. 缓存未命中，从数据源获取
        try:
            value = await self.data_source(key)
            if value is not None:
                # 3. 将数据存入缓存
                await self.cache.set(key, value)
            return value
        except Exception as e:
            print(f"从数据源获取数据失败: {e}")
            return None
    
    async def update_data(self, key: str, value: Any) -> bool:
        """更新数据"""
        try:
            # 1. 更新数据源
            await self.data_source(key, value)  # 假设data_source支持更新
            
            # 2. 删除缓存中的旧数据
            await self.cache.delete(key)
            
            return True
        except Exception as e:
            print(f"更新数据失败: {e}")
            return False

# 模拟数据源
class MockDataSource:
    """模拟数据源"""
    
    def __init__(self):
        self.data = {}
    
    async def get(self, key: str) -> Optional[Any]:
        """获取数据"""
        # 模拟数据库查询延迟
        await asyncio.sleep(0.1)
        return self.data.get(key)
    
    async def set(self, key: str, value: Any):
        """设置数据"""
        # 模拟数据库写入延迟
        await asyncio.sleep(0.2)
        self.data[key] = value

# 使用示例
async def demo_cache_aside():
    """演示缓存旁路模式"""
    print("\n=== 缓存旁路模式演示 ===")
    
    # 创建缓存和数据源
    cache = SimpleCache(max_size=100, default_ttl=300)
    data_source = MockDataSource()
    cache_aside = CacheAside(cache, data_source)
    
    # 添加一些测试数据
    await data_source.set("user:1", {"name": "Alice", "age": 30})
    await data_source.set("user:2", {"name": "Bob", "age": 25})
    
    # 第一次访问（缓存未命中）
    print("第一次访问用户1:")
    start_time = time.time()
    user1 = await cache_aside.get_data("user:1")
    end_time = time.time()
    print(f"数据: {user1}, 耗时: {end_time - start_time:.3f}秒")
    
    # 第二次访问（缓存命中）
    print("\n第二次访问用户1:")
    start_time = time.time()
    user1_cached = await cache_aside.get_data("user:1")
    end_time = time.time()
    print(f"数据: {user1_cached}, 耗时: {end_time - start_time:.3f}秒")
    
    # 查看缓存统计
    print("\n缓存统计:")
    stats = cache.get_stats()
    print(f"命中次数: {stats['hit_count']}")
    print(f"未命中次数: {stats['miss_count']}")
    print(f"命中率: {stats['hit_rate']:.2%}")
```

### 2. Write Through Pattern（写透模式）
```python
class WriteThrough:
    """写透模式"""
    
    def __init__(self, cache: SimpleCache, data_source: Callable):
        self.cache = cache
        self.data_source = data_source
    
    async def write_data(self, key: str, value: Any) -> bool:
        """写入数据（写透模式）"""
        try:
            # 1. 先写入数据源
            await self.data_source(key, value)
            
            # 2. 同时写入缓存
            await self.cache.set(key, value)
            
            return True
        except Exception as e:
            print(f"写透模式失败: {e}")
            return False

class ReadThrough:
    """读透模式"""
    
    def __init__(self, cache: SimpleCache, data_source: Callable):
        self.cache = cache
        self.data_source = data_source
    
    async def read_data(self, key: str) -> Optional[Any]:
        """读取数据（读透模式）"""
        # 1. 先尝试从缓存获取
        cached_value = await self.cache.get(key)
        if cached_value is not None:
            return cached_value
        
        # 2. 缓存未命中，自动从数据源加载到缓存
        try:
            value = await self.data_source(key)
            if value is not None:
                await self.cache.set(key, value)
            return value
        except Exception as e:
            print(f"读透模式失败: {e}")
            return None

class WriteBehind:
    """写回模式"""
    
    def __init__(self, cache: SimpleCache, data_source: Callable, 
                 flush_interval: float = 5.0):
        self.cache = cache
        self.data_source = data_source
        self.flush_interval = flush_interval
        self.dirty_entries: dict[str, Any] = {}  # 脏数据
        self.flush_task = None
        self.is_running = False
    
    async def start(self):
        """启动写回缓存"""
        self.is_running = True
        self.flush_task = asyncio.create_task(self._flush_loop())
    
    async def stop(self):
        """停止写回缓存"""
        self.is_running = False
        if self.flush_task:
            self.flush_task.cancel()
            try:
                await self.flush_task
            except asyncio.CancelledError:
                pass
        # 停止前强制刷新所有脏数据
        await self._flush_all()
    
    async def write_data(self, key: str, value: Any) -> bool:
        """写入数据（写回模式）"""
        try:
            # 1. 写入缓存
            await self.cache.set(key, value)
            
            # 2. 标记为脏数据，等待异步刷新到数据源
            self.dirty_entries[key] = value
            
            return True
        except Exception as e:
            print(f"写回模式失败: {e}")
            return False
    
    async def _flush_loop(self):
        """异步刷新循环"""
        while self.is_running:
            try:
                await asyncio.sleep(self.flush_interval)
                await self._flush_dirty_entries()
            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"刷新循环异常: {e}")
    
    async def _flush_dirty_entries(self):
        """刷新脏数据"""
        if not self.dirty_entries:
            return
        
        print(f"开始刷新 {len(self.dirty_entries)} 个脏数据...")
        
        # 批量刷新到数据源
        for key, value in self.dirty_entries.items():
            try:
                await self.data_source(key, value)
            except Exception as e:
                print(f"刷新数据失败 {key}: {e}")
        
        self.dirty_entries.clear()
    
    async def _flush_all(self):
        """刷新所有脏数据"""
        if self.dirty_entries:
            print("强制刷新所有脏数据...")
            await self._flush_dirty_entries()
```

## 缓存策略

### 1. TTL（Time To Live）策略
```python
import random
from typing import List, Dict, Any

class TTLManager:
    """TTL管理器"""
    
    def __init__(self):
        self.key_ttl: dict[str, float] = {}
        self.default_ttl = 300  # 5分钟
    
    def set_ttl(self, key: str, ttl: float):
        """设置键的TTL"""
        expire_time = time.time() + ttl
        self.key_ttl[key] = expire_time
    
    def get_ttl(self, key: str) -> Optional[float]:
        """获取键的剩余TTL"""
        expire_time = self.key_ttl.get(key)
        if expire_time is None:
            return None
        
        remaining = expire_time - time.time()
        return max(0, remaining)
    
    def is_expired(self, key: str) -> bool:
        """检查键是否过期"""
        expire_time = self.key_ttl.get(key)
        if expire_time is None:
            return False
        return time.time() > expire_time
    
    def cleanup_expired(self) -> List[str]:
        """清理过期键"""
        current_time = time.time()
        expired_keys = []
        
        for key, expire_time in list(self.key_ttl.items()):
            if current_time > expire_time:
                expired_keys.append(key)
                del self.key_ttl[key]
        
        return expired_keys

class AdaptiveTTL:
    """自适应TTL策略"""
    
    def __init__(self, cache: SimpleCache):
        self.cache = cache
        self.key_access_history: dict[str, List[float]] = {}
        self.adaptation_factor = 0.1
    
    def calculate_adaptive_ttl(self, key: str, base_ttl: float = 300) -> float:
        """计算自适应TTL"""
        if key not in self.key_access_history:
            return base_ttl
        
        # 分析访问模式
        access_times = self.key_access_history[key]
        if len(access_times) < 2:
            return base_ttl
        
        # 计算访问间隔
        intervals = [access_times[i] - access_times[i-1] 
                    for i in range(1, len(access_times))]
        
        if not intervals:
            return base_ttl
        
        # 平均访问间隔
        avg_interval = sum(intervals) / len(intervals)
        
        # 根据访问频率调整TTL
        # 访问频率越高，TTL越长
        access_frequency = 1 / max(avg_interval, 1)  # 避免除零
        adaptation = 1 + (access_frequency * self.adaptation_factor)
        
        # 限制在合理范围内
        adapted_ttl = base_ttl * adaptation
        return min(adapted_ttl, base_ttl * 3)  # 最大不超过基础TTL的3倍
    
    async def get_with_adaptive_ttl(self, key: str) -> Optional[Any]:
        """获取数据并更新TTL策略"""
        # 记录访问时间
        if key not in self.key_access_history:
            self.key_access_history[key] = []
        
        self.key_access_history[key].append(time.time())
        
        # 保持历史记录在合理范围内
        if len(self.key_access_history[key]) > 100:
            self.key_access_history[key] = self.key_access_history[key][-50:]
        
        # 从缓存获取数据
        return await self.cache.get(key)

class TTLOptimizer:
    """TTL优化器"""
    
    def __init__(self, cache: SimpleCache):
        self.cache = cache
        self.hot_data_threshold = 0.8  # 热点数据命中率阈值
    
    def analyze_access_patterns(self, access_logs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """分析访问模式"""
        key_stats = {}
        
        for log in access_logs:
            key = log['key']
            access_time = log['timestamp']
            hit = log.get('hit', False)
            
            if key not in key_stats:
                key_stats[key] = {
                    'access_count': 0,
                    'hit_count': 0,
                    'access_times': [],
                    'intervals': []
                }
            
            stats = key_stats[key]
            stats['access_count'] += 1
            stats['access_times'].append(access_time)
            
            if hit:
                stats['hit_count'] += 1
        
        # 计算派生指标
        for key, stats in key_stats.items():
            hit_rate = stats['hit_count'] / stats['access_count']
            stats['hit_rate'] = hit_rate
            stats['is_hot_data'] = hit_rate > self.hot_data_threshold
            
            # 计算访问间隔
            access_times = sorted(stats['access_times'])
            if len(access_times) > 1:
                intervals = [access_times[i] - access_times[i-1] 
                           for i in range(1, len(access_times))]
                stats['avg_interval'] = sum(intervals) / len(intervals)
                stats['interval_std'] = self._calculate_std(intervals)
        
        return key_stats
    
    def _calculate_std(self, values: List[float]) -> float:
        """计算标准差"""
        if len(values) < 2:
            return 0
        
        mean = sum(values) / len(values)
        variance = sum((x - mean) ** 2 for x in values) / len(values)
        return variance ** 0.5
    
    def recommend_ttl_values(self, key_stats: Dict[str, Any]) -> Dict[str, float]:
        """推荐TTL值"""
        recommendations = {}
        
        for key, stats in key_stats.items():
            if stats['is_hot_data']:
                # 热点数据使用较长TTL
                base_ttl = 1800  # 30分钟
                if stats.get('avg_interval'):
                    # 根据访问间隔调整
                    interval_factor = min(stats['avg_interval'] / 300, 2)  # 最大2倍
                    recommendations[key] = base_ttl * interval_factor
                else:
                    recommendations[key] = base_ttl
            else:
                # 冷数据使用较短TTL
                recommendations[key] = 300  # 5分钟
        
        return recommendations

# 使用示例
async def demo_ttl_strategies():
    """演示TTL策略"""
    print("\n=== TTL策略演示 ===")
    
    # 创建自适应TTL缓存
    cache = SimpleCache(max_size=100, default_ttl=60)
    adaptive_ttl = AdaptiveTTL(cache)
    
    # 模拟访问模式
    access_logs = []
    hot_keys = ['user:1', 'user:2', 'product:1']
    cold_keys = ['user:100', 'user:200', 'product:100']
    
    # 模拟热点数据高频访问
    for i in range(50):
        for key in hot_keys:
            # 缓存命中
            await cache.set(key, f"data_{key}")
            await adaptive_ttl.get_with_adaptive_ttl(key)
            
            access_logs.append({
                'key': key,
                'timestamp': time.time() + i * 0.1,
                'hit': True
            })
    
    # 模拟冷数据偶尔访问
    for i in range(10):
        for key in cold_keys:
            access_logs.append({
                'key': key,
                'timestamp': time.time() + i * 0.5,
                'hit': False  # 缓存未命中
            })
    
    # 分析访问模式并推荐TTL
    optimizer = TTLOptimizer(cache)
    key_stats = optimizer.analyze_access_patterns(access_logs)
    ttl_recommendations = optimizer.recommend_ttl_values(key_stats)
    
    print("TTL建议:")
    for key, ttl in ttl_recommendations.items():
        print(f"  {key}: {ttl:.0f}秒")
    
    # 显示热点数据分析
    print("\n热点数据分析:")
    for key, stats in key_stats.items():
        if stats['is_hot_data']:
            print(f"  {key}: 命中率 {stats['hit_rate']:.2%}, 平均间隔 {stats['avg_interval']:.1f}秒")
```

### 2. 缓存预热策略
```python
import json
from typing import Set, List, Dict, Any, Callable

class CacheWarmer:
    """缓存预热器"""
    
    def __init__(self, cache: SimpleCache, data_source: Callable):
        self.cache = cache
        self.data_source = data_source
        self.warmed_keys: Set[str] = set()
        self.warm_stats = {
            'total_keys': 0,
            'success_count': 0,
            'failure_count': 0,
            'start_time': None,
            'end_time': None
        }
    
    async def warm_cache(self, keys: List[str], batch_size: int = 10, 
                        concurrent_limit: int = 5) -> Dict[str, Any]:
        """预热缓存"""
        self.warm_stats['total_keys'] = len(keys)
        self.warm_stats['start_time'] = time.time()
        
        # 分批处理
        for i in range(0, len(keys), batch_size):
            batch = keys[i:i + batch_size]
            
            # 并发限制
            semaphore = asyncio.Semaphore(concurrent_limit)
            
            # 并发预热当前批次
            tasks = [self._warm_single_key(key, semaphore) for key in batch]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # 统计结果
            for j, result in enumerate(results):
                key = batch[j]
                if isinstance(result, Exception):
                    self.warm_stats['failure_count'] += 1
                    print(f"预热失败 {key}: {result}")
                else:
                    self.warm_stats['success_count'] += 1
                    self.warmed_keys.add(key)
        
        self.warm_stats['end_time'] = time.time()
        return self.get_warm_stats()
    
    async def _warm_single_key(self, key: str, semaphore: asyncio.Semaphore):
        """预热单个键"""
        async with semaphore:
            try:
                # 从数据源获取数据
                data = await self.data_source(key)
                if data is not None:
                    # 设置到缓存
                    await self.cache.set(key, data)
                    return True
                else:
                    raise Exception("数据源返回None")
            except Exception as e:
                raise e
    
    def get_warm_stats(self) -> Dict[str, Any]:
        """获取预热统计信息"""
        duration = 0
        if self.warm_stats['start_time'] and self.warm_stats['end_time']:
            duration = self.warm_stats['end_time'] - self.warm_stats['start_time']
        
        return {
            **self.warm_stats,
            'duration': duration,
            'success_rate': (
                self.warm_stats['success_count'] / max(self.warm_stats['total_keys'], 1)
            ),
            'keys_per_second': (
                self.warm_stats['success_count'] / max(duration, 0.001)
            )
        }
    
    def is_key_warmed(self, key: str) -> bool:
        """检查键是否已预热"""
        return key in self.warmed_keys

class SmartCacheWarmer:
    """智能缓存预热器"""
    
    def __init__(self, cache: SimpleCache, data_source: Callable):
        self.cache = cache
        self.data_source = data_source
        self.access_predictor = AccessPredictor()
    
    async def predictive_warm(self, time_window: int = 3600) -> Dict[str, Any]:
        """预测性预热"""
        # 1. 分析历史访问模式
        predicted_hot_keys = await self.access_predictor.predict_hot_keys(time_window)
        
        # 2. 基于业务规则预测
        business_hot_keys = await self._predict_business_hot_keys()
        
        # 3. 合并预测结果
        all_hot_keys = list(set(predicted_hot_keys + business_hot_keys))
        
        # 4. 执行预热
        warmer = CacheWarmer(self.cache, self.data_source)
        return await warmer.warm_cache(all_hot_keys)
    
    async def _predict_business_hot_keys(self) -> List[str]:
        """基于业务规则预测热点键"""
        business_hot_keys = []
        
        # 基于业务逻辑预测热点数据
        # 例如：活跃用户、热门商品、近期活动等
        
        # 模拟：活跃用户
        business_hot_keys.extend([f"user:{i}" for i in range(1, 101)])
        
        # 模拟：热门商品
        business_hot_keys.extend([f"product:hot:{i}" for i in range(1, 21)])
        
        # 模拟：系统配置
        business_hot_keys.extend(["config:system", "config:feature_flags"])
        
        return business_hot_keys

class AccessPredictor:
    """访问预测器"""
    
    def __init__(self):
        self.access_history: Dict[str, List[float]] = {}
        self.prediction_model = None
    
    async def record_access(self, key: str, access_time: float):
        """记录访问历史"""
        if key not in self.access_history:
            self.access_history[key] = []
        
        self.access_history[key].append(access_time)
        
        # 保持历史记录在合理范围内
        if len(self.access_history[key]) > 1000:
            self.access_history[key] = self.access_history[key][-500:]
    
    async def predict_hot_keys(self, time_window: int = 3600) -> List[str]:
        """预测热点键"""
        current_time = time.time()
        window_start = current_time - time_window
        
        key_scores = {}
        
        for key, access_times in self.access_history.items():
            # 过滤时间窗口内的访问
            recent_accesses = [t for t in access_times if t > window_start]
            
            if recent_accesses:
                # 计算访问频率和模式
                frequency = len(recent_accesses)
                consistency = self._calculate_consistency(recent_accesses)
                recency = self._calculate_recency(recent_accesses[-1], current_time)
                
                # 综合评分
                score = frequency * 0.4 + consistency * 0.3 + (1 - recency) * 0.3
                key_scores[key] = score
        
        # 选择评分最高的键作为预测热点
        hot_threshold = sorted(key_scores.values(), reverse=True)[min(20, len(key_scores))]
        hot_keys = [key for key, score in key_scores.items() if score >= hot_threshold]
        
        return hot_keys
    
    def _calculate_consistency(self, access_times: List[float]) -> float:
        """计算访问一致性"""
        if len(access_times) < 2:
            return 0
        
        # 计算访问间隔的标准差，标准差越小说明访问越规律
        intervals = [access_times[i] - access_times[i-1] 
                    for i in range(1, len(access_times))]
        
        if not intervals:
            return 0
        
        mean_interval = sum(intervals) / len(intervals)
        variance = sum((interval - mean_interval) ** 2 for interval in intervals) / len(intervals)
        std_dev = variance ** 0.5
        
        # 一致性分数：标准差越小，分数越高
        max_std = mean_interval * 2  # 假设合理的最大标准差
        consistency = max(0, 1 - (std_dev / max_std))
        return consistency
    
    def _calculate_recency(self, last_access: float, current_time: float) -> float:
        """计算访问新鲜度"""
        time_since_access = current_time - last_access
        # 归一化为0-1，越接近0表示越新鲜
        recency = min(1, time_since_access / 3600)  # 1小时内认为比较新鲜
        return recency

# 使用示例
async def demo_cache_warming():
    """演示缓存预热"""
    print("\n=== 缓存预热演示 ===")
    
    # 模拟数据源
    class MockDataSource:
        async def get(self, key: str):
            # 模拟数据库查询延迟
            await asyncio.sleep(0.05)
            return f"data_for_{key}"
    
    # 创建缓存和数据源
    cache = SimpleCache(max_size=1000, default_ttl=300)
    data_source = MockDataSource()
    
    # 创建预热器
    warmer = CacheWarmer(cache, data_source)
    
    # 准备预热键列表
    warm_keys = [f"user:{i}" for i in range(1, 101)] + \
               [f"product:{i}" for i in range(1, 51)]
    
    print(f"开始预热 {len(warm_keys)} 个键...")
    
    # 执行预热
    stats = await warmer.warm_cache(warm_keys, batch_size=20, concurrent_limit=10)
    
    print(f"预热完成:")
    print(f"  总键数: {stats['total_keys']}")
    print(f"  成功: {stats['success_count']}")
    print(f"  失败: {stats['failure_count']}")
    print(f"  耗时: {stats['duration']:.2f}秒")
    print(f"  成功率: {stats['success_rate']:.2%}")
    print(f"  速度: {stats['keys_per_second']:.1f} 键/秒")
```

### 3. 缓存更新策略
```python
from enum import Enum

class CacheUpdateStrategy(Enum):
    """缓存更新策略"""
    IMMEDIATE = "immediate"        # 立即更新
    DELAYED = "delayed"           # 延迟更新
    BATCHED = "batched"           # 批量更新
    EVENT_DRIVEN = "event_driven" # 事件驱动

class CacheUpdater:
    """缓存更新器"""
    
    def __init__(self, cache: SimpleCache, update_strategy: CacheUpdateStrategy):
        self.cache = cache
        self.strategy = update_strategy
        self.update_queue = asyncio.Queue()
        self.batch_size = 10
        self.batch_timeout = 5.0
        self.is_running = False
        self.batch_task = None
    
    async def start(self):
        """启动更新器"""
        if self.strategy == CacheUpdateStrategy.BATCHED:
            self.is_running = True
            self.batch_task = asyncio.create_task(self._batch_update_loop())
    
    async def stop(self):
        """停止更新器"""
        self.is_running = False
        if self.batch_task:
            self.batch_task.cancel()
            try:
                await self.batch_task
            except asyncio.CancelledError:
                pass
    
    async def update(self, key: str, value: Any):
        """更新缓存"""
        if self.strategy == CacheUpdateStrategy.IMMEDIATE:
            await self.cache.set(key, value)
        
        elif self.strategy == CacheUpdateStrategy.DELAYED:
            # 延迟更新
            await asyncio.sleep(self.batch_timeout)
            await self.cache.set(key, value)
        
        elif self.strategy == CacheUpdateStrategy.BATCHED:
            # 批量更新
            await self.update_queue.put((key, value))
        
        elif self.strategy == CacheUpdateStrategy.EVENT_DRIVEN:
            # 事件驱动更新
            await self._emit_update_event(key, value)
    
    async def _batch_update_loop(self):
        """批量更新循环"""
        batch = []
        last_batch_time = time.time()
        
        while self.is_running:
            try:
                # 尝试获取更新任务
                try:
                    key, value = await asyncio.wait_for(
                        self.update_queue.get(), timeout=1.0
                    )
                    batch.append((key, value))
                except asyncio.TimeoutError:
                    pass
                
                # 检查是否需要执行批量更新
                current_time = time.time()
                should_update = (
                    len(batch) >= self.batch_size or
                    (batch and current_time - last_batch_time >= self.batch_timeout)
                )
                
                if should_update and batch:
                    # 执行批量更新
                    for key, value in batch:
                        await self.cache.set(key, value)
                    
                    batch.clear()
                    last_batch_time = current_time
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"批量更新异常: {e}")
        
        # 清理剩余的批量任务
        while not self.update_queue.empty():
            try:
                key, value = self.update_queue.get_nowait()
                await self.cache.set(key, value)
            except asyncio.QueueEmpty:
                break
    
    async def _emit_update_event(self, key: str, value: Any):
        """发射更新事件"""
        event = {
            'type': 'cache_update',
            'key': key,
            'value': value,
            'timestamp': time.time()
        }
        print(f"发射缓存更新事件: {json.dumps(event, indent=2)}")
    
    async def invalidate(self, key: str):
        """失效缓存"""
        await self.cache.delete(key)
    
    async def invalidate_pattern(self, pattern: str):
        """失效匹配模式的缓存"""
        # 简化实现：扫描所有键
        keys_to_invalidate = []
        for key in self.cache.cache.keys():
            if pattern.replace('*', '') in key:
                keys_to_invalidate.append(key)
        
        for key in keys_to_invalidate:
            await self.cache.delete(key)

class EventDrivenCacheInvalidator:
    """事件驱动缓存失效器"""
    
    def __init__(self, cache: SimpleCache):
        self.cache = cache
        self.event_handlers = {}
        self.subscription_handlers = {}
    
    def subscribe(self, event_type: str, handler: Callable):
        """订阅事件"""
        if event_type not in self.event_handlers:
            self.event_handlers[event_type] = []
        self.event_handlers[event_type].append(handler)
    
    async def emit_event(self, event_type: str, event_data: Dict[str, Any]):
        """发射事件"""
        if event_type in self.event_handlers:
            for handler in self.event_handlers[event_type]:
                try:
                    await handler(event_data)
                except Exception as e:
                    print(f"事件处理器异常: {e}")
    
    async def handle_database_change(self, change_data: Dict[str, Any]):
        """处理数据库变更事件"""
        table = change_data.get('table')
        operation = change_data.get('operation')
        record_id = change_data.get('id')
        
        if table == 'users' and operation in ['UPDATE', 'DELETE']:
            # 用户数据变更，失效相关缓存
            cache_keys = [
                f"user:{record_id}",
                f"user:profile:{record_id}",
                f"user:stats:{record_id}"
            ]
            
            for key in cache_keys:
                await self.cache.delete(key)
                print(f"失效缓存键: {key}")
        
        elif table == 'products' and operation in ['UPDATE', 'DELETE']:
            # 产品数据变更，失效相关缓存
            cache_keys = [
                f"product:{record_id}",
                f"product:detail:{record_id}",
                f"product:inventory:{record_id}"
            ]
            
            for key in cache_keys:
                await self.cache.delete(key)
                print(f"失效缓存键: {key}")

# 使用示例
async def demo_cache_update_strategies():
    """演示缓存更新策略"""
    print("\n=== 缓存更新策略演示 ===")
    
    # 创建缓存
    cache = SimpleCache(max_size=100, default_ttl=300)
    
    # 演示不同的更新策略
    strategies = [
        CacheUpdateStrategy.IMMEDIATE,
        CacheUpdateStrategy.BATCHED,
        CacheUpdateStrategy.EVENT_DRIVEN
    ]
    
    for strategy in strategies:
        print(f"\n--- {strategy.value} 策略 ---")
        
        updater = CacheUpdater(cache, strategy)
        
        if strategy == CacheUpdateStrategy.BATCHED:
            await updater.start()
        
        # 执行一系列更新
        start_time = time.time()
        for i in range(5):
            await updater.update(f"key:{i}", f"value_{i}")
            await asyncio.sleep(0.1)
        
        if strategy == CacheUpdateStrategy.BATCHED:
            await asyncio.sleep(1)  # 等待批量更新完成
            await updater.stop()
        
        duration = time.time() - start_time
        print(f"更新耗时: {duration:.2f}秒")
        
        # 检查缓存状态
        print(f"缓存中的键: {list(cache.cache.keys())[:3]}...")  # 只显示前3个

# 事件驱动演示
async def demo_event_driven_invalidation():
    """演示事件驱动缓存失效"""
    print("\n=== 事件驱动缓存失效演示 ===")
    
    cache = SimpleCache(max_size=100, default_ttl=300)
    invalidator = EventDrivenCacheInvalidator(cache)
    
    # 订阅事件
    async def custom_invalidation_handler(event_data: Dict[str, Any]):
        if event_data.get('operation') == 'DELETE':
            # 自定义失效逻辑
            print(f"自定义失效处理: {event_data}")
    
    invalidator.subscribe('custom_invalidation', custom_invalidation_handler)
    
    # 预填充一些缓存数据
    await cache.set("user:123", {"name": "Alice", "age": 30})
    await cache.set("product:456", {"name": "Laptop", "price": 999})
    
    print("初始缓存键:", list(cache.cache.keys()))
    
    # 模拟数据库变更事件
    await invalidator.handle_database_change({
        'table': 'users',
        'operation': 'UPDATE',
        'id': 123
    })
    
    print("用户更新后的缓存键:", list(cache.cache.keys()))
    
    # 发射自定义事件
    await invalidator.emit_event('custom_invalidation', {
        'operation': 'DELETE',
        'data': 'custom_data'
    })
```

## 缓存一致性

### 1. 缓存与数据库一致性
```python
class DatabaseCacheConsistency:
    """数据库缓存一致性管理器"""
    
    def __init__(self, cache: SimpleCache, db_operations: Dict[str, Callable]):
        self.cache = cache
        self.db_operations = db_operations
        self.consistency_strategies = {
            'cache_aside': self._cache_aside_strategy,
            'write_through': self._write_through_strategy,
            'write_behind': self._write_behind_strategy,
            'read_repair': self._read_repair_strategy
        }
    
    async def read_data(self, key: str, strategy: str = 'cache_aside') -> Optional[Any]:
        """读取数据"""
        strategy_func = self.consistency_strategies.get(strategy, self._cache_aside_strategy)
        return await strategy_func(key, is_write=False)
    
    async def write_data(self, key: str, value: Any, strategy: str = 'cache_aside') -> bool:
        """写入数据"""
        strategy_func = self.consistency_strategies.get(strategy, self._cache_aside_strategy)
        return await strategy_func(key, value, is_write=True)
    
    async def _cache_aside_strategy(self, key: str, value: Any = None, is_write: bool = False) -> Any:
        """缓存旁路策略"""
        if is_write:
            # 写入：先写数据库，再删除缓存
            try:
                await self.db_operations['write'](key, value)
                await self.cache.delete(key)  # 删除缓存，迫使下次读时重新加载
                return True
            except Exception as e:
                print(f"缓存旁路写策略失败: {e}")
                return False
        else:
            # 读取：先读缓存，命中返回，未命中读数据库并更新缓存
            cached_value = await self.cache.get(key)
            if cached_value is not None:
                return cached_value
            
            # 缓存未命中，从数据库读取
            try:
                db_value = await self.db_operations['read'](key)
                if db_value is not None:
                    await self.cache.set(key, db_value)
                return db_value
            except Exception as e:
                print(f"缓存旁路读策略失败: {e}")
                return None
    
    async def _write_through_strategy(self, key: str, value: Any = None, is_write: bool = False) -> Any:
        """写透策略"""
        if is_write:
            # 写入：同时写数据库和缓存
            try:
                # 并发写入数据库和缓存
                db_task = self.db_operations['write'](key, value)
                cache_task = self.cache.set(key, value)
                
                await asyncio.gather(db_task, cache_task)
                return True
            except Exception as e:
                print(f"写透策略失败: {e}")
                return False
        else:
            # 读取：委托给缓存旁路
            return await self._cache_aside_strategy(key, value, is_write)
    
    async def _write_behind_strategy(self, key: str, value: Any = None, is_write: bool = False) -> Any:
        """写回策略"""
        if is_write:
            # 写入：只写缓存，异步写数据库
            try:
                await self.cache.set(key, value)
                
                # 异步写入数据库
                asyncio.create_task(self._async_write_to_db(key, value))
                return True
            except Exception as e:
                print(f"写回策略失败: {e}")
                return False
        else:
            # 读取：委托给缓存旁路
            return await self._cache_aside_strategy(key, value, is_write)
    
    async def _async_write_to_db(self, key: str, value: Any):
        """异步写入数据库"""
        try:
            await asyncio.sleep(0.1)  # 模拟异步延迟
            await self.db_operations['write'](key, value)
        except Exception as e:
            print(f"异步写入数据库失败: {e}")
    
    async def _read_repair_strategy(self, key: str, value: Any = None, is_write: bool = False) -> Any:
        """读修复策略"""
        if is_write:
            # 写入：委托给缓存旁路
            return await self._cache_aside_strategy(key, value, is_write)
        else:
            # 读取：先读缓存，如果数据不一致则修复
            cached_value = await self.cache.get(key)
            
            if cached_value is not None:
                # 验证缓存与数据库的一致性
                try:
                    db_value = await self.db_operations['read'](key)
                    if db_value != cached_value:
                        # 数据不一致，启动读修复
                        print(f"检测到数据不一致，开始修复: {key}")
                        await self.cache.set(key, db_value)
                        return db_value
                    return cached_value
                except Exception:
                    # 数据库读取失败，返回缓存值
                    return cached_value
            else:
                # 缓存未命中，从数据库读取
                return await self._cache_aside_strategy(key, value, is_write)

class ConsistencyChecker:
    """一致性检查器"""
    
    def __init__(self, cache: SimpleCache, db_operations: Dict[str, Callable]):
        self.cache = cache
        self.db_operations = db_operations
    
    async def check_consistency(self, keys: List[str]) -> Dict[str, Dict[str, Any]]:
        """检查一致性"""
        results = {}
        
        for key in keys:
            try:
                # 读取缓存值
                cache_value = await self.cache.get(key)
                
                # 读取数据库值
                db_value = await self.db_operations['read'](key)
                
                # 比较一致性
                is_consistent = cache_value == db_value
                
                results[key] = {
                    'cache_value': cache_value,
                    'db_value': db_value,
                    'is_consistent': is_consistent,
                    'timestamp': time.time()
                }
                
                if not is_consistent:
                    print(f"数据不一致: {key}")
                    print(f"  缓存值: {cache_value}")
                    print(f"  数据库值: {db_value}")
                
            except Exception as e:
                results[key] = {
                    'error': str(e),
                    'timestamp': time.time()
                }
        
        return results
    
    async def repair_inconsistency(self, key: str, repair_strategy: str = 'cache_to_db'):
        """修复不一致"""
        try:
            cache_value = await self.cache.get(key)
            db_value = await self.db_operations['read'](key)
            
            if cache_value != db_value:
                if repair_strategy == 'cache_to_db':
                    # 用缓存值覆盖数据库值
                    await self.db_operations['write'](key, cache_value)
                    print(f"用缓存值修复数据库: {key}")
                
                elif repair_strategy == 'db_to_cache':
                    # 用数据库值覆盖缓存值
                    await self.cache.set(key, db_value)
                    print(f"用数据库值修复缓存: {key}")
                
                elif repair_strategy == 'delete_both':
                    # 删除两边数据，迫使重新加载
                    await self.cache.delete(key)
                    # 假设数据库操作支持删除
                    if 'delete' in self.db_operations:
                        await self.db_operations['delete'](key)
                    print(f"删除两边数据: {key}")
            
        except Exception as e:
            print(f"修复失败 {key}: {e}")

# 使用示例
async def demo_database_cache_consistency():
    """演示数据库缓存一致性"""
    print("\n=== 数据库缓存一致性演示 ===")
    
    # 模拟数据库操作
    class MockDatabase:
        def __init__(self):
            self.data = {}
        
        async def read(self, key: str):
            await asyncio.sleep(0.05)  # 模拟数据库延迟
            return self.data.get(key)
        
        async def write(self, key: str, value: Any):
            await asyncio.sleep(0.1)   # 模拟写入延迟
            self.data[key] = value
        
        async def delete(self, key: str):
            if key in self.data:
                del self.data[key]
    
    # 初始化组件
    cache = SimpleCache(max_size=100, default_ttl=300)
    db = MockDatabase()
    db_operations = {
        'read': db.read,
        'write': db.write,
        'delete': db.delete
    }
    
    consistency_manager = DatabaseCacheConsistency(cache, db_operations)
    checker = ConsistencyChecker(cache, db_operations)
    
    # 测试不同策略
    strategies = ['cache_aside', 'write_through', 'read_repair']
    
    for strategy in strategies:
        print(f"\n--- 测试 {strategy} 策略 ---")
        
        # 1. 写入数据
        await consistency_manager.write_data("user:1", {"name": "Alice"}, strategy)
        print("写入用户数据")
        
        # 2. 读取数据（应该命中缓存）
        user1 = await consistency_manager.read_data("user:1", strategy)
        print(f"第一次读取: {user1}")
        
        # 3. 直接修改数据库（模拟外部修改）
        await db.write("user:1", {"name": "Bob"})
        print("直接修改数据库")
        
        # 4. 检查一致性
        if strategy == 'read_repair':
            # 读修复策略会在读取时自动修复
            user1_repaired = await consistency_manager.read_data("user:1", strategy)
            print(f"读修复后读取: {user1_repaired}")
        else:
            # 其他策略需要显式检查
            consistency_result = await checker.check_consistency(["user:1"])
            print(f"一致性检查: {consistency_result['user:1']['is_consistent']}")
            
            if not consistency_result['user:1']['is_consistent']:
                print("检测到不一致，进行修复...")
                await checker.repair_inconsistency("user:1", "db_to_cache")
```

这个缓存策略概述文档详细介绍了各种缓存技术和最佳实践：

1. **缓存架构模式** - Cache Aside、Write Through、Write Behind的完整实现
2. **缓存策略** - TTL管理、自适应TTL、缓存预热、智能预热等
3. **缓存更新策略** - 立即更新、延迟更新、批量更新、事件驱动更新
4. **缓存一致性** - 多种数据库缓存一致性策略和修复机制

每种策略都配有详细的Python代码实现，展示了如何在实际项目中实现高效的缓存系统。通过这些实现，可以构建高性能、可扩展的缓存解决方案。