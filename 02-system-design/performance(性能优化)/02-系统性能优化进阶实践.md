# 系统性能优化进阶实践与性能工程

## 概述

在现代分布式系统中，性能优化是一个持续的过程，需要从系统架构、代码实现、基础设施等多个层面进行系统性优化。本文档将深入探讨高级性能优化技术和工程化实践。

## 1. 高级性能分析技术

### 1.1 性能监控与分析框架

```python
import asyncio
import time
import psutil
import threading
from typing import Dict, List, Any, Callable, Optional
from dataclasses import dataclass, field
from collections import defaultdict
from contextlib import contextmanager
from concurrent.futures import ThreadPoolExecutor
import json
import logging

@dataclass
class PerformanceMetrics:
    """性能指标数据类"""
    timestamp: float
    cpu_usage: float
    memory_usage: float
    disk_io: Dict[str, int]
    network_io: Dict[str, int]
    active_connections: int
    request_count: int = 0
    error_count: int = 0
    response_time_avg: float = 0.0
    response_time_p99: float = 0.0

class PerformanceProfiler:
    """性能分析器"""
    
    def __init__(self, sample_interval: float = 1.0, max_history: int = 3600):
        self.sample_interval = sample_interval
        self.max_history = max_history
        self.metrics_history: List[PerformanceMetrics] = []
        self.is_running = False
        self.sampling_thread = None
        self.performance_counters = defaultdict(int)
        self.response_times = defaultdict(list)
        self.lock = threading.RLock()
        
    def start_monitoring(self):
        """开始性能监控"""
        if not self.is_running:
            self.is_running = True
            self.sampling_thread = threading.Thread(target=self._sampling_loop)
            self.sampling_thread.daemon = True
            self.sampling_thread.start()
    
    def stop_monitoring(self):
        """停止性能监控"""
        self.is_running = False
        if self.sampling_thread:
            self.sampling_thread.join()
    
    def _sampling_loop(self):
        """采样循环"""
        while self.is_running:
            try:
                metrics = self._collect_metrics()
                with self.lock:
                    self.metrics_history.append(metrics)
                    
                    # 保持历史记录限制
                    if len(self.metrics_history) > self.max_history:
                        self.metrics_history.pop(0)
                
                time.sleep(self.sample_interval)
            except Exception as e:
                logging.error(f"Error collecting metrics: {e}")
                time.sleep(self.sample_interval)
    
    def _collect_metrics(self) -> PerformanceMetrics:
        """收集系统指标"""
        # CPU和内存使用率
        cpu_usage = psutil.cpu_percent(interval=None)
        memory = psutil.virtual_memory()
        
        # 磁盘IO
        disk_io = psutil.disk_io_counters()
        disk_stats = {}
        if disk_io:
            disk_stats = {
                'read_bytes': disk_io.read_bytes,
                'write_bytes': disk_io.write_bytes,
                'read_count': disk_io.read_count,
                'write_count': disk_io.write_count
            }
        
        # 网络IO
        network_io = psutil.net_io_counters()
        network_stats = {}
        if network_io:
            network_stats = {
                'bytes_sent': network_io.bytes_sent,
                'bytes_recv': network_io.bytes_recv,
                'packets_sent': network_io.packets_sent,
                'packets_recv': network_io.packets_recv
            }
        
        # 活跃连接数
        connections = len(psutil.net_connections())
        
        return PerformanceMetrics(
            timestamp=time.time(),
            cpu_usage=cpu_usage,
            memory_usage=memory.percent,
            disk_io=disk_stats,
            network_io=network_stats,
            active_connections=connections,
            request_count=self.performance_counters['requests'],
            error_count=self.performance_counters['errors'],
            response_time_avg=self._calculate_avg_response_time(),
            response_time_p99=self._calculate_p99_response_time()
        )
    
    def _calculate_avg_response_time(self) -> float:
        """计算平均响应时间"""
        with self.lock:
            if not self.response_times['total']:
                return 0.0
            
            total_time = sum(sum(times) for times in self.response_times.values())
            total_count = sum(len(times) for times in self.response_times.values())
            
            return total_time / total_count if total_count > 0 else 0.0
    
    def _calculate_p99_response_time(self) -> float:
        """计算99%分位数响应时间"""
        with self.lock:
            all_times = []
            for times in self.response_times.values():
                all_times.extend(times)
            
            if not all_times:
                return 0.0
            
            all_times.sort()
            index = int(len(all_times) * 0.99)
            return all_times[min(index, len(all_times) - 1)]
    
    def record_request(self, endpoint: str, response_time: float, success: bool = True):
        """记录请求"""
        with self.lock:
            self.performance_counters['requests'] += 1
            self.response_times[endpoint].append(response_time)
            self.response_times['total'].append(response_time)
            
            # 保持每个端点的响应时间记录在合理范围内
            if len(self.response_times[endpoint]) > 1000:
                self.response_times[endpoint] = self.response_times[endpoint][-500:]
            
            if not success:
                self.performance_counters['errors'] += 1
    
    def get_performance_summary(self, minutes: int = 5) -> Dict[str, Any]:
        """获取性能摘要"""
        cutoff_time = time.time() - (minutes * 60)
        
        with self.lock:
            recent_metrics = [m for m in self.metrics_history if m.timestamp > cutoff_time]
            
            if not recent_metrics:
                return {}
            
            # 计算统计信息
            cpu_values = [m.cpu_usage for m in recent_metrics]
            memory_values = [m.memory_usage for m in recent_metrics]
            
            return {
                'period_minutes': minutes,
                'sample_count': len(recent_metrics),
                'cpu': {
                    'avg': sum(cpu_values) / len(cpu_values),
                    'max': max(cpu_values),
                    'min': min(cpu_values)
                },
                'memory': {
                    'avg': sum(memory_values) / len(memory_values),
                    'max': max(memory_values),
                    'min': min(memory_values)
                },
                'requests': {
                    'total': recent_metrics[-1].request_count,
                    'errors': recent_metrics[-1].error_count,
                    'error_rate': recent_metrics[-1].error_count / max(recent_metrics[-1].request_count, 1)
                },
                'response_times': {
                    'avg': recent_metrics[-1].response_time_avg,
                    'p99': recent_metrics[-1].response_time_p99
                }
            }

# 使用示例
async def demo_performance_profiler():
    """演示性能分析器"""
    import random
    
    profiler = PerformanceProfiler()
    profiler.start_monitoring()
    
    # 模拟请求
    for i in range(100):
        start_time = time.time()
        # 模拟请求处理
        await asyncio.sleep(random.uniform(0.01, 0.1))
        end_time = time.time()
        
        response_time = (end_time - start_time) * 1000  # 转换为毫秒
        success = random.random() > 0.05  # 5%失败率
        
        profiler.record_request(f"/api/endpoint{i%3}", response_time, success)
    
    # 等待采集数据
    await asyncio.sleep(3)
    
    # 获取性能摘要
    summary = profiler.get_performance_summary(1)
    print(f"Performance Summary:")
    print(f"  CPU: {summary.get('cpu', {}).get('avg', 0):.1f}%")
    print(f"  Memory: {summary.get('memory', {}).get('avg', 0):.1f}%")
    print(f"  Response Time (avg): {summary.get('response_times', {}).get('avg', 0):.1f}ms")
    print(f"  Response Time (p99): {summary.get('response_times', {}).get('p99', 0):.1f}ms")
    
    profiler.stop_monitoring()
```

## 2. 高级缓存优化技术

### 2.1 智能缓存预热系统

```python
import asyncio
from typing import Dict, List, Any, Optional, Callable, Set
from dataclasses import dataclass, field
from enum import Enum
import time
import logging

class CacheStrategy(Enum):
    LRU = "lru"
    LFU = "lfu"
    FIFO = "fifo"
    ADAPTIVE = "adaptive"

class PreheatingPriority(Enum):
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class CacheItem:
    key: str
    value: Any
    size: int
    access_count: int = 0
    last_accessed: float = field(default_factory=time.time)
    created_at: float = field(default_factory=time.time)
    ttl: Optional[float] = None
    priority: PreheatingPriority = PreheatingPriority.NORMAL

@dataclass
class PreheatingTask:
    key: str
    generator_func: Callable
    priority: PreheatingPriority
    scheduled_time: float
    attempts: int = 0
    max_attempts: int = 3

class SmartCachePreheater:
    """智能缓存预热系统"""
    
    def __init__(self, cache_size: int = 10000):
        self.cache_size = cache_size
        self.cache = {}
        self.access_order = []  # 用于LRU
        self.frequency_map = {}  # 用于LFU
        self.preheating_queue = asyncio.PriorityQueue()
        self.preheating_tasks = {}
        self.is_running = False
        self.preheating_workers = []
        
    async def start(self, num_workers: int = 4):
        """启动预热系统"""
        self.is_running = True
        
        # 启动预热工作线程
        for i in range(num_workers):
            worker = asyncio.create_task(self._preheating_worker(i))
            self.preheating_workers.append(worker)
    
    async def stop(self):
        """停止预热系统"""
        self.is_running = False
        
        # 等待所有工作线程结束
        await asyncio.gather(*self.preheating_workers, return_exceptions=True)
    
    async def _preheating_worker(self, worker_id: int):
        """预热工作线程"""
        while self.is_running:
            try:
                # 获取下一个预热任务
                task = await asyncio.wait_for(self.preheating_queue.get(), timeout=1.0)
                
                await self._execute_preheating_task(task)
                
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logging.error(f"Preheating worker {worker_id} error: {e}")
    
    async def _execute_preheating_task(self, task: PreheatingTask):
        """执行预热任务"""
        try:
            # 生成缓存数据
            value = await task.generator_func()
            
            # 添加到缓存
            cache_item = CacheItem(
                key=task.key,
                value=value,
                size=self._calculate_size(value),
                priority=task.priority
            )
            
            await self._add_to_cache(cache_item)
            
            logging.info(f"Preheated cache key: {task.key}")
            
        except Exception as e:
            logging.error(f"Failed to preheat key {task.key}: {e}")
            
            # 重试机制
            task.attempts += 1
            if task.attempts < task.max_attempts:
                # 延迟重试
                await asyncio.sleep(2 ** task.attempts)
                task.scheduled_time = time.time()
                await self.preheating_queue.put((5 - task.priority.value, task.scheduled_time, task))
    
    def _calculate_size(self, value: Any) -> int:
        """计算数据大小（简化版）"""
        if isinstance(value, str):
            return len(value)
        elif isinstance(value, (list, dict)):
            return len(str(value))
        else:
            return 64  # 默认大小
    
    async def _add_to_cache(self, item: CacheItem):
        """添加到缓存"""
        # 检查缓存大小限制
        if len(self.cache) >= self.cache_size:
            await self._evict_items(1)
        
        self.cache[item.key] = item
        self.access_order.append(item.key)
        self.frequency_map[item.key] = 0
    
    async def _evict_items(self, count: int):
        """驱逐缓存项"""
        for _ in range(count):
            if not self.cache:
                break
            
            # 选择驱逐的目标
            victim_key = min(self.cache.keys(), key=lambda k: self.cache[k].priority.value)
            if victim_key:
                del self.cache[victim_key]
                if victim_key in self.access_order:
                    self.access_order.remove(victim_key)
                del self.frequency_map[victim_key]
    
    async def schedule_preheating(self, key: str, generator_func: Callable, 
                                 priority: PreheatingPriority = PreheatingPriority.NORMAL,
                                 delay: float = 0):
        """调度预热任务"""
        task = PreheatingTask(
            key=key,
            generator_func=generator_func,
            priority=priority,
            scheduled_time=time.time() + delay
        )
        
        await self.preheating_queue.put((6 - priority.value, task.scheduled_time, task))
        self.preheating_tasks[key] = task
    
    async def get(self, key: str) -> Optional[Any]:
        """获取缓存值"""
        if key in self.cache:
            item = self.cache[key]
            
            # 检查TTL
            if item.ttl and time.time() - item.created_at > item.ttl:
                del self.cache[key]
                if key in self.access_order:
                    self.access_order.remove(key)
                del self.frequency_map[key]
                return None
            
            # 更新访问信息
            item.last_accessed = time.time()
            item.access_count += 1
            self.frequency_map[key] = self.frequency_map.get(key, 0) + 1
            
            return item.value
        
        return None
    
    def get_stats(self) -> Dict[str, Any]:
        """获取缓存统计"""
        return {
            'cache_size': len(self.cache),
            'max_cache_size': self.cache_size,
            'preheating_tasks': len(self.preheating_tasks),
            'queue_size': self.preheating_queue.qsize()
        }

# 使用示例
async def demo_smart_preheating():
    """演示智能预热系统"""
    import random
    
    # 创建预热系统
    preheater = SmartCachePreheater(cache_size=100)
    
    # 启动预热系统
    await preheater.start(num_workers=2)
    
    # 创建一些预热任务
    async def generate_user_profile(user_id: str):
        await asyncio.sleep(0.1)  # 模拟数据库查询
        return f"UserProfile_{user_id}"
    
    async def generate_product_catalog():
        await asyncio.sleep(0.2)  # 模拟复杂查询
        return "ProductCatalog_Data"
    
    # 调度预热任务
    await preheater.schedule_preheating("user_123", lambda: generate_user_profile("123"), PreheatingPriority.HIGH)
    await preheater.schedule_preheating("catalog", generate_product_catalog, PreheatingPriority.NORMAL)
    
    # 等待预热完成
    await asyncio.sleep(2)
    
    # 获取缓存数据
    user_data = await preheater.get("user_123")
    print(f"User data from cache: {user_data}")
    
    # 获取统计信息
    stats = preheater.get_stats()
    print(f"Cache stats: {stats}")
    
    # 停止预热系统
    await preheater.stop()
```

## 3. 高级负载均衡与性能优化

### 3.1 智能负载均衡器

```python
import asyncio
import random
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

class LoadBalancingStrategy(Enum):
    ROUND_ROBIN = "round_robin"
    WEIGHTED_ROUND_ROBIN = "weighted_round_robin"
    LEAST_CONNECTIONS = "least_connections"
    LEAST_RESPONSE_TIME = "least_response_time"
    ADAPTIVE = "adaptive"

@dataclass
class ServerNode:
    id: str
    host: str
    port: int
    weight: float = 1.0
    max_connections: int = 1000
    active_connections: int = 0
    total_requests: int = 0
    failed_requests: int = 0
    avg_response_time: float = 0.0
    is_healthy: bool = True

class IntelligentLoadBalancer:
    """智能负载均衡器"""
    
    def __init__(self, strategy: LoadBalancingStrategy = LoadBalancingStrategy.ADAPTIVE):
        self.servers: Dict[str, ServerNode] = {}
        self.strategy = strategy
        self.performance_weights = {}
    
    def add_server(self, server: ServerNode):
        """添加服务器节点"""
        self.servers[server.id] = server
        self.performance_weights[server.id] = server.weight
    
    def remove_server(self, server_id: str):
        """移除服务器节点"""
        if server_id in self.servers:
            del self.servers[server_id]
        if server_id in self.performance_weights:
            del self.performance_weights[server_id]
    
    async def get_server(self, request_context: Dict[str, Any] = None) -> Optional[ServerNode]:
        """获取最适合的服务器"""
        if not self.servers:
            return None
        
        # 过滤健康的服务器
        healthy_servers = {sid: server for sid, server in self.servers.items() if server.is_healthy}
        
        if not healthy_servers:
            # 如果没有健康的服务器，返回负载最轻的（即使不健康）
            if self.servers:
                return min(self.servers.values(), key=lambda s: s.active_connections / max(s.max_connections, 1))
            return None
        
        # 根据策略选择服务器
        if self.strategy == LoadBalancingStrategy.ADAPTIVE:
            return await self._select_server_adaptive(request_context)
        elif self.strategy == LoadBalancingStrategy.ROUND_ROBIN:
            return await self._select_server_round_robin()
        elif self.strategy == LoadBalancingStrategy.WEIGHTED_ROUND_ROBIN:
            return await self._select_server_weighted_round_robin()
        elif self.strategy == LoadBalancingStrategy.LEAST_CONNECTIONS:
            return await self._select_server_least_connections()
        elif self.strategy == LoadBalancingStrategy.LEAST_RESPONSE_TIME:
            return await self._select_server_least_response_time()
        
        return list(healthy_servers.values())[0]
    
    async def _select_server_adaptive(self, request_context: Dict[str, Any] = None) -> ServerNode:
        """自适应服务器选择"""
        healthy_servers = [s for s in self.servers.values() if s.is_healthy]
        
        if not healthy_servers:
            return list(self.servers.values())[0]
        
        # 计算每个服务器的综合评分
        scores = {}
        for server in healthy_servers:
            score = self._calculate_server_score(server)
            scores[server.id] = score
        
        # 选择评分最高的服务器
        best_server_id = max(scores.keys(), key=lambda k: scores[k])
        return self.servers[best_server_id]
    
    def _calculate_server_score(self, server: ServerNode) -> float:
        """计算服务器综合评分"""
        # 基础权重
        base_score = self.performance_weights.get(server.id, 1.0)
        
        # 连接负载因子（负载越低评分越高）
        connection_load = server.active_connections / max(server.max_connections, 1)
        connection_factor = 1.0 - connection_load
        
        # 响应时间因子（响应时间越短评分越高）
        response_time_factor = 1.0 / (1.0 + server.avg_response_time / 100.0)  # 标准化到0-1
        
        # 健康状态因子
        health_factor = 1.0 if server.is_healthy else 0.1
        
        # 成功率因子
        success_rate = (server.total_requests - server.failed_requests) / max(server.total_requests, 1)
        
        # 综合评分
        total_score = (
            base_score * 0.2 +
            connection_factor * 0.3 +
            response_time_factor * 0.2 +
            health_factor * 0.1 +
            success_rate * 0.2
        )
        
        return max(0.1, total_score)  # 确保评分不低于0.1
    
    async def _select_server_round_robin(self) -> ServerNode:
        """轮询选择"""
        healthy_servers = [s for s in self.servers.values() if s.is_healthy]
        if not healthy_servers:
            return list(self.servers.values())[0]
        
        # 简单的轮询实现
        total_requests = sum(s.total_requests for s in healthy_servers)
        return healthy_servers[total_requests % len(healthy_servers)]
    
    async def _select_server_weighted_round_robin(self) -> ServerNode:
        """加权轮询选择"""
        healthy_servers = [s for s in self.servers.values() if s.is_healthy]
        if not healthy_servers:
            return list(self.servers.values())[0]
        
        # 计算总权重
        total_weight = sum(self.performance_weights.get(s.id, s.weight) for s in healthy_servers)
        
        # 随机选择
        random_weight = random.uniform(0, total_weight)
        current_weight = 0
        
        for server in healthy_servers:
            current_weight += self.performance_weights.get(server.id, server.weight)
            if current_weight >= random_weight:
                return server
        
        return healthy_servers[0]
    
    async def _select_server_least_connections(self) -> ServerNode:
        """最少连接选择"""
        healthy_servers = [s for s in self.servers.values() if s.is_healthy]
        if not healthy_servers:
            return list(self.servers.values())[0]
        
        return min(healthy_servers, key=lambda s: s.active_connections)
    
    async def _select_server_least_response_time(self) -> ServerNode:
        """最少响应时间选择"""
        healthy_servers = [s for s in self.servers.values() if s.is_healthy]
        if not healthy_servers:
            return list(self.servers.values())[0]
        
        return min(healthy_servers, key=lambda s: s.avg_response_time)
    
    async def record_request(self, server_id: str, response_time: float, success: bool = True):
        """记录请求统计"""
        if server_id in self.servers:
            server = self.servers[server_id]
            
            server.total_requests += 1
            if not success:
                server.failed_requests += 1
            
            # 更新平均响应时间（简化版）
            server.avg_response_time = (server.avg_response_time + response_time) / 2

# 使用示例
async def demo_load_balancer():
    """演示智能负载均衡器"""
    import random
    
    # 创建负载均衡器
    lb = IntelligentLoadBalancer(LoadBalancingStrategy.ADAPTIVE)
    
    # 添加服务器
    servers = [
        ServerNode("server1", "192.168.1.10", 8000, weight=2.0),
        ServerNode("server2", "192.168.1.11", 8000, weight=1.5),
        ServerNode("server3", "192.168.1.12", 8000, weight=1.0),
    ]
    
    for server in servers:
        lb.add_server(server)
    
    # 模拟请求
    for i in range(20):
        server = await lb.get_server()
        if server:
            # 模拟请求处理
            response_time = random.uniform(50, 200)  # 50-200ms
            success = random.random() > 0.1  # 90%成功率
            
            await lb.record_request(server.id, response_time, success)
            
            # 模拟连接管理
            server.active_connections += 1
            await asyncio.sleep(random.uniform(0.01, 0.05))  # 处理时间
            server.active_connections -= 1
            
            print(f"Request {i+1}: {server.id} - {response_time:.1f}ms - {'Success' if success else 'Failed'}")
    
    # 获取统计信息
    print("\nServer Statistics:")
    for server_id, server in lb.servers.items():
        success_rate = (server.total_requests - server.failed_requests) / max(server.total_requests, 1)
        print(f"  {server_id}:")
        print(f"    Requests: {server.total_requests}")
        print(f"    Success rate: {success_rate*100:.1f}%")
        print(f"    Avg response time: {server.avg_response_time:.1f}ms")
        print(f"    Performance weight: {lb.performance_weights.get(server_id, server.weight):.2f}")
        print(f"    Healthy: {server.is_healthy}")
```

## 4. 性能工程实践

### 4.1 自动化性能测试框架

```python
import asyncio
import time
import statistics
from typing import Dict, List, Any, Callable, Optional
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor

@dataclass
class PerformanceTestConfig:
    """性能测试配置"""
    name: str
    target_function: Callable
    concurrent_users: int = 10
    test_duration: float = 60.0  # 秒
    ramp_up_time: float = 10.0  # 秒
    think_time: float = 1.0  # 秒

@dataclass
class PerformanceTestResult:
    """性能测试结果"""
    test_name: str
    start_time: float
    end_time: float
    total_duration: float
    total_requests: int
    successful_requests: int
    failed_requests: int
    response_times: List[float]
    throughput: float  # requests per second
    avg_response_time: float
    p50_response_time: float
    p95_response_time: float
    p99_response_time: float
    min_response_time: float
    max_response_time: float
    error_rate: float

class AutomatedPerformanceTestFramework:
    """自动化性能测试框架"""
    
    def __init__(self):
        self.test_results = {}
    
    async def run_load_test(self, config: PerformanceTestConfig) -> PerformanceTestResult:
        """运行负载测试"""
        print(f"Starting load test: {config.name}")
        print(f"Concurrent users: {config.concurrent_users}")
        print(f"Test duration: {config.test_duration}s")
        
        start_time = time.time()
        results = []
        
        # 创建并发用户
        users = []
        for user_id in range(config.concurrent_users):
            user = asyncio.create_task(
                self._simulate_user(config, user_id, start_time + config.ramp_up_time, start_time + config.test_duration)
            )
            users.append(user)
        
        # 等待所有用户完成
        user_results = await asyncio.gather(*users, return_exceptions=True)
        
        # 收集结果
        all_response_times = []
        successful_requests = 0
        failed_requests = 0
        
        for user_result in user_results:
            if isinstance(user_result, Exception):
                failed_requests += 1
                continue
            
            response_times, success_count, failure_count = user_result
            all_response_times.extend(response_times)
            successful_requests += success_count
            failed_requests += failure_count
        
        end_time = time.time()
        total_duration = end_time - start_time
        total_requests = len(all_response_times)
        
        # 计算统计数据
        if all_response_times:
            avg_response_time = statistics.mean(all_response_times)
            p50_response_time = statistics.median(all_response_times)
            p95_response_time = self._percentile(all_response_times, 95)
            p99_response_time = self._percentile(all_response_times, 99)
            min_response_time = min(all_response_times)
            max_response_time = max(all_response_times)
        else:
            avg_response_time = p50_response_time = p95_response_time = p99_response_time = 0
            min_response_time = max_response_time = 0
        
        throughput = total_requests / total_duration if total_duration > 0 else 0
        error_rate = failed_requests / (total_requests + failed_requests) if (total_requests + failed_requests) > 0 else 0
        
        result = PerformanceTestResult(
            test_name=config.name,
            start_time=start_time,
            end_time=end_time,
            total_duration=total_duration,
            total_requests=total_requests,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            response_times=all_response_times,
            throughput=throughput,
            avg_response_time=avg_response_time,
            p50_response_time=p50_response_time,
            p95_response_time=p95_response_time,
            p99_response_time=p99_response_time,
            min_response_time=min_response_time,
            max_response_time=max_response_time,
            error_rate=error_rate
        )
        
        self.test_results[config.name] = result
        return result
    
    async def _simulate_user(self, config: PerformanceTestConfig, user_id: int, 
                           start_time: float, end_time: float) -> tuple:
        """模拟用户行为"""
        import random
        
        response_times = []
        success_count = 0
        failure_count = 0
        
        # 等待开始时间
        await asyncio.sleep(max(0, start_time - time.time()))
        
        current_time = time.time()
        
        while current_time < end_time:
            try:
                request_start = time.time()
                
                # 执行目标函数
                if asyncio.iscoroutinefunction(config.target_function):
                    await config.target_function()
                else:
                    config.target_function()
                
                request_end = time.time()
                response_time = (request_end - request_start) * 1000  # 转换为毫秒
                
                response_times.append(response_time)
                success_count += 1
                
            except Exception as e:
                failure_count += 1
                print(f"User {user_id} request failed: {e}")
            
            # 模拟用户思考时间
            await asyncio.sleep(config.think_time)
            current_time = time.time()
        
        return response_times, success_count, failure_count
    
    def _percentile(self, data: List[float], percentile: int) -> float:
        """计算百分位数"""
        if not data:
            return 0.0
        
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        return sorted_data[min(index, len(sorted_data) - 1)]
    
    def generate_performance_report(self, results: Dict[str, PerformanceTestResult]) -> str:
        """生成性能测试报告"""
        report = []
        report.append("# Performance Test Report\n")
        
        for test_name, result in results.items():
            report.append(f"## {test_name}\n")
            report.append(f"- **Test Duration**: {result.total_duration:.1f}s")
            report.append(f"- **Total Requests**: {result.total_requests}")
            report.append(f"- **Successful Requests**: {result.successful_requests}")
            report.append(f"- **Failed Requests**: {result.failed_requests}")
            report.append(f"- **Throughput**: {result.throughput:.2f} req/s")
            report.append(f"- **Error Rate**: {result.error_rate*100:.2f}%")
            report.append(f"- **Average Response Time**: {result.avg_response_time:.2f}ms")
            report.append(f"- **P50 Response Time**: {result.p50_response_time:.2f}ms")
            report.append(f"- **P95 Response Time**: {result.p95_response_time:.2f}ms")
            report.append(f"- **P99 Response Time**: {result.p99_response_time:.2f}ms")
            report.append(f"- **Min Response Time**: {result.min_response_time:.2f}ms")
            report.append(f"- **Max Response Time**: {result.max_response_time:.2f}ms")
            report.append("")
        
        return "\n".join(report)

# 使用示例
async def demo_performance_testing():
    """演示性能测试框架"""
    import random
    
    # 模拟要测试的函数
    async def sample_api_call():
        # 模拟API调用
        await asyncio.sleep(random.uniform(0.05, 0.2))
        return "API response"
    
    # 创建测试配置
    load_test_config = PerformanceTestConfig(
        name="API Load Test",
        target_function=sample_api_call,
        concurrent_users=5,
        test_duration=30.0,
        ramp_up_time=5.0,
        think_time=0.5
    )
    
    framework = AutomatedPerformanceTestFramework()
    
    # 运行负载测试
    load_result = await framework.run_load_test(load_test_config)
    
    print("\n" + "="*50)
    print("LOAD TEST RESULTS")
    print("="*50)
    print(f"Test Name: {load_result.test_name}")
    print(f"Total Duration: {load_result.total_duration:.1f}s")
    print(f"Total Requests: {load_result.total_requests}")
    print(f"Successful Requests: {load_result.successful_requests}")
    print(f"Failed Requests: {load_result.failed_requests}")
    print(f"Throughput: {load_result.throughput:.2f} req/s")
    print(f"Error Rate: {load_result.error_rate*100:.2f}%")
    print(f"Average Response Time: {load_result.avg_response_time:.2f}ms")
    print(f"P95 Response Time: {load_result.p95_response_time:.2f}ms")
    print(f"P99 Response Time: {load_result.p99_response_time:.2f}ms")
    
    # 生成报告
    report = framework.generate_performance_report({"load_test": load_result})
    print("\n" + "="*50)
    print("PERFORMANCE REPORT")
    print("="*50)
    print(report)
```

## 5. 性能监控与告警

### 5.1 实时性能监控系统

```python
import asyncio
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum
from collections import deque

class AlertSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"

@dataclass
class PerformanceAlert:
    id: str
    timestamp: float
    metric: str
    severity: AlertSeverity
    message: str
    current_value: float
    threshold: float
    resolved: bool = False

@dataclass
class SystemMetrics:
    timestamp: float
    cpu_usage: float
    memory_usage: float
    response_time_avg: float
    response_time_p95: float
    throughput: float
    error_rate: float
    server_id: str = "system"

class RealTimePerformanceMonitor:
    """实时性能监控系统"""
    
    def __init__(self, sample_interval: float = 5.0):
        self.sample_interval = sample_interval
        self.metrics_history = deque(maxlen=1000)
        self.alerts = deque(maxlen=500)
        self.alert_rules = {}
        self.is_monitoring = False
        self.monitoring_task = None
        
        # 默认告警规则
        self._setup_default_alert_rules()
    
    def _setup_default_alert_rules(self):
        """设置默认告警规则"""
        self.alert_rules = {
            'cpu_usage': {'warning': 70.0, 'critical': 90.0},
            'memory_usage': {'warning': 80.0, 'critical': 95.0},
            'response_time_p95': {'warning': 1000.0, 'critical': 3000.0},
            'error_rate': {'warning': 0.05, 'critical': 0.10},
            'throughput': {'warning': 10.0, 'critical': 5.0}  # 低吞吐量告警
        }
    
    def add_metric(self, metrics: SystemMetrics):
        """添加系统指标"""
        self.metrics_history.append(metrics)
        
        # 检查告警规则
        self._check_alert_rules(metrics)
    
    def _check_alert_rules(self, metrics: SystemMetrics):
        """检查告警规则"""
        current_metrics = {
            'cpu_usage': metrics.cpu_usage,
            'memory_usage': metrics.memory_usage,
            'response_time_p95': metrics.response_time_p95,
            'error_rate': metrics.error_rate,
            'throughput': metrics.throughput
        }
        
        for metric_name, value in current_metrics.items():
            if metric_name in self.alert_rules:
                rules = self.alert_rules[metric_name]
                
                # 检查关键告警
                if metric_name in ['error_rate'] and value > rules.get('critical', float('inf')):
                    self._create_alert(metric_name, value, rules['critical'], AlertSeverity.CRITICAL)
                elif metric_name == 'throughput' and value < rules.get('critical', float('inf')):
                    self._create_alert(metric_name, value, rules['critical'], AlertSeverity.CRITICAL)
                elif value > rules.get('critical', float('inf')):
                    self._create_alert(metric_name, value, rules['critical'], AlertSeverity.CRITICAL)
                elif value > rules.get('warning', float('inf')):
                    self._create_alert(metric_name, value, rules['warning'], AlertSeverity.WARNING)
    
    def _create_alert(self, metric: str, current_value: float, threshold: float, severity: AlertSeverity):
        """创建告警"""
        import uuid
        
        alert = PerformanceAlert(
            id=str(uuid.uuid4()),
            timestamp=time.time(),
            metric=metric,
            severity=severity,
            message=f"{metric} is {current_value:.2f}, threshold: {threshold:.2f}",
            current_value=current_value,
            threshold=threshold
        )
        
        self.alerts.append(alert)
        
        # 打印告警信息
        print(f"[{severity.value.upper()}] {alert.message}")
    
    def get_performance_summary(self, minutes: int = 5) -> Dict[str, Any]:
        """获取性能摘要"""
        cutoff_time = time.time() - (minutes * 60)
        
        recent_metrics = [m for m in self.metrics_history if m.timestamp > cutoff_time]
        
        if not recent_metrics:
            return {}
        
        # 计算统计信息
        cpu_values = [m.cpu_usage for m in recent_metrics]
        memory_values = [m.memory_usage for m in recent_metrics]
        
        return {
            'period_minutes': minutes,
            'sample_count': len(recent_metrics),
            'cpu': {
                'avg': sum(cpu_values) / len(cpu_values),
                'max': max(cpu_values),
                'min': min(cpu_values)
            },
            'memory': {
                'avg': sum(memory_values) / len(memory_values),
                'max': max(memory_values),
                'min': min(memory_values)
            },
            'throughput': {
                'avg': sum(m.throughput for m in recent_metrics) / len(recent_metrics)
            },
            'response_time_p95': {
                'avg': sum(m.response_time_p95 for m in recent_metrics) / len(recent_metrics)
            },
            'error_rate': {
                'avg': sum(m.error_rate for m in recent_metrics) / len(recent_metrics)
            }
        }
    
    def get_active_alerts(self, severity: AlertSeverity = None) -> List[PerformanceAlert]:
        """获取活跃告警"""
        if severity:
            return [alert for alert in self.alerts if alert.severity == severity and not alert.resolved]
        
        return [alert for alert in self.alerts if not alert.resolved]

# 使用示例
async def demo_performance_monitoring():
    """演示性能监控"""
    import random
    import psutil
    
    # 创建监控系统
    monitor = RealTimePerformanceMonitor()
    
    # 模拟系统运行
    for i in range(50):
        # 模拟系统指标
        cpu_usage = random.uniform(30, 90)
        memory_usage = random.uniform(40, 85)
        response_time = random.uniform(100, 500)
        throughput = random.uniform(50, 200)
        error_rate = random.uniform(0, 0.1)
        
        metrics = SystemMetrics(
            timestamp=time.time(),
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            response_time_avg=response_time * 0.8,
            response_time_p95=response_time,
            throughput=throughput,
            error_rate=error_rate
        )
        
        monitor.add_metric(metrics)
        
        await asyncio.sleep(1)  # 每秒采样一次
    
    # 获取性能摘要
    summary = monitor.get_performance_summary(1)
    print("\n" + "="*50)
    print("PERFORMANCE SUMMARY")
    print("="*50)
    print(f"CPU Usage (avg): {summary.get('cpu', {}).get('avg', 0):.1f}%")
    print(f"Memory Usage (avg): {summary.get('memory', {}).get('avg', 0):.1f}%")
    print(f"Throughput (avg): {summary.get('throughput', {}).get('avg', 0):.2f} req/s")
    print(f"P95 Response Time (avg): {summary.get('response_time_p95', {}).get('avg', 0):.2f}ms")
    print(f"Error Rate (avg): {summary.get('error_rate', {}).get('avg', 0)*100:.2f}%")
    
    # 获取告警信息
    active_alerts = monitor.get_active_alerts()
    print(f"\nActive Alerts: {len(active_alerts)}")
    for alert in active_alerts[-5:]:  # 显示最近5个告警
        print(f"  [{alert.severity.value}] {alert.metric}: {alert.message}")
```

## 6. 性能优化最佳实践

### 6.1 性能优化策略

1. **系统级优化**
   - 硬件资源优化：CPU、内存、存储、网络
   - 操作系统调优：内核参数、文件描述符限制
   - 容器和虚拟化优化

2. **应用级优化**
   - 代码优化：算法复杂度、内存管理
   - 并发处理：异步编程、线程池优化
   - 缓存策略：多级缓存、缓存失效策略

3. **数据库优化**
   - 查询优化：索引优化、SQL调优
   - 连接池管理
   - 数据库分片和读写分离

4. **网络优化**
   - 负载均衡策略
   - CDN和静态资源优化
   - HTTP/2、HTTP/3等协议优化

### 6.2 性能测试方法论

1. **负载测试**：验证系统在预期负载下的性能
2. **压力测试**：测试系统在高负载下的极限
3. **容量测试**：确定系统最大处理能力
4. **稳定性测试**：长期运行稳定性验证
5. **尖峰测试**：测试突发负载处理能力

## 7. 总结

高性能系统设计是一个系统工程，需要从架构设计、代码实现、运维监控等多个维度进行综合考虑。通过采用先进的性能分析工具、智能负载均衡策略、自动化测试框架和实时监控系统，可以构建出高性能、高可用的现代化系统。

关键要素：
- 持续监控和度量
- 自动化测试和部署
- 智能化资源调度
- 自适应性能调优
- 预测性故障预防

性能优化是一个持续的过程，需要在系统演进过程中不断监控、分析和优化。