# 负载测试框架与实践

## 1. 负载测试基础概念

### 负载测试类型

**并发测试（Concurrent Testing）**
- 测试系统在预期并发用户数下的性能表现
- 验证系统能否稳定处理目标并发请求
- 主要关注响应时间和系统稳定性

**压力测试（Stress Testing）**
- 逐步增加系统负载直到系统达到极限
- 确定系统的最大承载能力
- 发现系统在极限情况下的行为

**容量测试（Volume Testing）**
- 测试系统在大量数据下的性能
- 验证数据库和存储系统的性能
- 检查内存和磁盘使用情况

**耐久性测试（Endurance Testing）**
- 长时间运行的稳定性测试
- 验证系统在持续负载下的表现
- 发现内存泄漏和性能衰减问题

### 核心测试指标
```python
import time
from typing import Dict, List

class LoadTestMetrics:
    """负载测试核心指标"""
    def __init__(self):
        self.response_times = []
        self.error_count = 0
        self.total_requests = 0
    
    def add_request(self, response_time: float, is_success: bool):
        """记录请求结果"""
        self.response_times.append(response_time)
        self.total_requests += 1
        if not is_success:
            self.error_count += 1
    
    def get_summary(self) -> Dict:
        """获取测试摘要"""
        if not self.response_times:
            return {}
        
        sorted_times = sorted(self.response_times)
        n = len(sorted_times)
        
        return {
            'total_requests': self.total_requests,
            'error_rate': self.error_count / self.total_requests,
            'avg_response_time': sum(self.response_times) / n,
            'min_response_time': min(self.response_times),
            'max_response_time': max(self.response_times),
            'p50_response_time': sorted_times[int(n * 0.5)],
            'p95_response_time': sorted_times[int(n * 0.95)],
            'p99_response_time': sorted_times[int(n * 0.99)]
        }
```

### 负载测试配置示例
```python
class LoadTestConfig:
    """负载测试配置"""
    def __init__(self, **kwargs):
        self.target_url = kwargs.get('target_url', 'http://localhost:8080')
        self.concurrent_users = kwargs.get('concurrent_users', 10)
        self.duration = kwargs.get('duration', 60)  # 测试持续时间（秒）
        self.ramp_up_time = kwargs.get('ramp_up_time', 10)  # 逐渐增加负载时间
        self.think_time = kwargs.get('think_time', 1)  # 用户思考时间
        self.max_response_time = kwargs.get('max_response_time', 2.0)  # 最大允许响应时间
        self.max_error_rate = kwargs.get('max_error_rate', 0.01)  # 最大错误率

# 示例配置
config = LoadTestConfig(
    target_url='http://api.example.com',
    concurrent_users=100,
    duration=300,  # 5分钟
    ramp_up_time=30,
    max_response_time=1.5,
    max_error_rate=0.005
)
```

### 简单负载测试实现
```python
import requests
import threading
from concurrent.futures import ThreadPoolExecutor
import time

class SimpleLoadTester:
    """简单负载测试器"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.metrics = LoadTestMetrics()
        self.results = []
    
    def run_single_request(self):
        """执行单次请求"""
        try:
            start_time = time.time()
            response = requests.get(
                self.config.target_url,
                timeout=30
            )
            end_time = time.time()
            
            response_time = end_time - start_time
            is_success = 200 <= response.status_code < 300
            
            self.metrics.add_request(response_time, is_success)
            self.results.append({
                'response_time': response_time,
                'status_code': response.status_code,
                'success': is_success
            })
        
        except Exception as e:
            self.metrics.add_request(0, False)
    
    def run_load_test(self):
        """执行负载测试"""
        print(f"开始负载测试: {self.config.concurrent_users} 并发用户, 持续 {self.config.duration} 秒")
        
        start_time = time.time()
        end_time = start_time + self.config.duration
        
        # 使用线程池执行并发请求
        with ThreadPoolExecutor(max_workers=self.config.concurrent_users) as executor:
            while time.time() < end_time:
                executor.submit(self.run_single_request)
                time.sleep(self.config.think_time)  # 模拟用户思考时间
        
        # 等待所有请求完成
        time.sleep(2)
        
        # 生成报告
        summary = self.metrics.get_summary()
        print(f"测试完成! 总请求数: {summary['total_requests']}")
        print(f"平均响应时间: {summary['avg_response_time']:.3f}s")
        print(f"错误率: {summary['error_rate']:.2%}")
        
        return summary

# 使用示例
if __name__ == "__main__":
    config = LoadTestConfig(
        target_url='http://localhost:8080/api/health',
        concurrent_users=50,
        duration=120
    )
    
    tester = SimpleLoadTester(config)
    results = tester.run_load_test()
```

## 2. 负载测试策略

### 渐进式负载测试
```python
def progressive_load_test(base_url: str, start_users: int = 10, end_users: int = 100):
    """渐进式负载测试"""
    results = []
    
    for users in range(start_users, end_users + 1, 10):
        print(f"测试 {users} 并发用户...")
        
        config = LoadTestConfig(
            target_url=base_url,
            concurrent_users=users,
            duration=60
        )
        
        tester = SimpleLoadTester(config)
        summary = tester.run_load_test()
        summary['concurrent_users'] = users
        
        results.append(summary)
        
        # 检查是否达到性能瓶颈
        if summary['error_rate'] > config.max_error_rate:
            print(f"在 {users} 并发用户时错误率过高，停止测试")
            break
    
    return results
```

### 峰值测试
```python
def spike_test(base_url: str):
    """峰值测试：模拟突发流量"""
    # 第一阶段：正常负载
    normal_config = LoadTestConfig(
        target_url=base_url,
        concurrent_users=20,
        duration=60
    )
    
    # 第二阶段：高峰负载
    spike_config = LoadTestConfig(
        target_url=base_url,
        concurrent_users=200,
        duration=30
    )
    
    # 第三阶段：恢复正常
    recovery_config = LoadTestConfig(
        target_url=base_url,
        concurrent_users=20,
        duration=60
    )
    
    normal_results = SimpleLoadTester(normal_config).run_load_test()
    spike_results = SimpleLoadTester(spike_config).run_load_test()
    recovery_results = SimpleLoadTester(recovery_config).run_load_test()
    
    return {
        'normal': normal_results,
        'spike': spike_results,
        'recovery': recovery_results
    }
```

## 3. 性能基准设置

### 性能标准定义
```python
PERFORMANCE_THRESHOLDS = {
    'api_response_time': {
        'p95': 1.0,  # 95%的请求应在1秒内完成
        'p99': 2.0   # 99%的请求应在2秒内完成
    },
    'webpage_load_time': {
        'p95': 3.0,
        'p99': 5.0
    },
    'error_rate': 0.001,  # 错误率应低于0.1%
    'throughput': {
        'minimum': 1000,   # 最低吞吐量要求
        'target': 5000     # 目标吞吐量
    }
}

def evaluate_performance(results: Dict, thresholds: Dict) -> Dict:
    """评估性能是否达标"""
    evaluation = {
        'overall_status': 'PASS',
        'issues': [],
        'warnings': []
    }
    
    # 检查响应时间
    if 'avg_response_time' in results:
        if results['avg_response_time'] > thresholds['api_response_time']['p95']:
            evaluation['overall_status'] = 'FAIL'
            evaluation['issues'].append(f"平均响应时间过长: {results['avg_response_time']:.3f}s")
    
    # 检查错误率
    if 'error_rate' in results:
        if results['error_rate'] > thresholds['error_rate']:
            evaluation['overall_status'] = 'FAIL'
            evaluation['issues'].append(f"错误率过高: {results['error_rate']:.2%}")
    
    return evaluation
```

## 4. 负载测试最佳实践

### 测试前准备
- **环境准备**：确保测试环境与生产环境一致
- **数据准备**：准备足够数量的测试数据
- **监控配置**：配置必要的性能监控工具
- **团队协调**：通知相关团队测试计划

### 测试执行要点
- **渐进式增加**：逐步增加负载避免系统崩溃
- **多轮测试**：进行多轮测试验证结果一致性
- **实时监控**：监控关键性能指标
- **日志收集**：收集详细的测试日志

### 测试后分析
- **性能瓶颈分析**：识别系统瓶颈点
- **资源使用分析**：分析CPU、内存、网络使用情况
- **错误模式分析**：分析错误类型和频率
- **优化建议**：提出具体的性能优化建议

## 5. 常见负载测试工具

### 开源工具
- **JMeter**：功能强大的Java压力测试工具
- **Gatling**：基于Scala的高性能负载测试工具
- **Artillery**：Node.js开发的负载测试框架
- **K6**：现代化的负载测试工具

### 云服务
- **AWS Load Testing**：Amazon提供的云端负载测试服务
- **Azure Load Testing**：Microsoft Azure的负载测试服务
- **BlazeMeter**：基于JMeter的云端性能测试平台

## 6. 监控和报告

### 实时监控指标
```python
class LoadTestMonitor:
    """负载测试实时监控"""
    def __init__(self):
        self.current_metrics = {
            'active_requests': 0,
            'completed_requests': 0,
            'failed_requests': 0,
            'current_rps': 0
        }
    
    def update_metrics(self, request_completed: bool, is_success: bool):
        """更新实时指标"""
        if request_completed:
            self.current_metrics['completed_requests'] += 1
            if not is_success:
                self.current_metrics['failed_requests'] += 1
        
        self.current_metrics['current_rps'] = self._calculate_rps()
    
    def _calculate_rps(self) -> float:
        """计算当前RPS（简化实现）"""
        return self.current_metrics['completed_requests'] / 60  # 假设每分钟计算一次
```

## 总结

负载测试是确保系统性能的重要手段。关键要点：

1. **明确测试目标** - 确定性能基准和验收标准
2. **选择合适的测试类型** - 根据需求选择并发、压力、容量或耐久性测试
3. **合理设置测试参数** - 并发用户数、测试持续时间、思考时间等
4. **渐进式执行测试** - 避免系统崩溃，获得完整的性能曲线
5. **深度分析测试结果** - 识别瓶颈点，提出优化建议

通过系统性的负载测试，可以提前发现性能问题，确保系统在生产环境中的稳定运行。
                success=False,
                error_message=str(e)
            )

class AsyncLoadTester:
    """异步HTTP负载测试器"""
    
    def __init__(self, base_url: str, max_connections: int = 100):
        self.base_url = base_url
        self.max_connections = max_connections
        self.connector = aiohttp.TCPConnector(limit=max_connections)
    
    async def make_request(self, method: str, endpoint: str, **kwargs) -> RequestResult:
        """发起异步HTTP请求"""
        url = f"{self.base_url}{endpoint}"
        start_time = time.time()
        
        async with aiohttp.ClientSession(
            connector=self.connector,
            timeout=aiohttp.ClientTimeout(total=30)
        ) as session:
            try:
                async with session.request(
                    method=method,
                    url=url,
                    **kwargs
                ) as response:
                    response_time = time.time() - start_time
                    
                    return RequestResult(
                        timestamp=start_time,
                        response_time=response_time,
                        status_code=response.status,
                        success=200 <= response.status < 300
                    )
            
            except Exception as e:
                response_time = time.time() - start_time
                
                return RequestResult(
                    timestamp=start_time,
                    response_time=response_time,
                    status_code=0,
                    success=False,
                    error_message=str(e)
                )

class LoadTestScenario:
    """负载测试场景"""
    
    def __init__(self, name: str):
        self.name = name
        self.steps = []
    
    def add_step(self, method: str, endpoint: str, weight: int = 1, 
                 request_builder: Callable[[], Dict] = None):
        """添加测试步骤"""
        self.steps.append({
            'method': method,
            'endpoint': endpoint,
            'weight': weight,
            'request_builder': request_builder or (lambda: {})
        })
    
    def get_weighted_step(self):
        """获取加权随机步骤"""
        total_weight = sum(step['weight'] for step in self.steps)
        random_weight = random.randint(1, total_weight)
        
        current_weight = 0
        for step in self.steps:
            current_weight += step['weight']
            if random_weight <= current_weight:
                return step
        
        return self.steps[-1]  # 默认返回最后一个

class LoadTestEngine:
    """负载测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.tester = None
        self.scenarios = []
        self.result = LoadTestResult(config)
        self.is_running = False
        self.active_users = 0
        self.lock = threading.Lock()
    
    def add_scenario(self, scenario: LoadTestScenario):
        """添加测试场景"""
        self.scenarios.append(scenario)
    
    def _create_user_session(self) -> Callable[[], None]:
        """创建用户会话"""
        def user_session():
            session_start = time.time()
            
            while self.is_running and (time.time() - session_start) < self.config.test_duration:
                try:
                    # 选择测试场景
                    if self.scenarios:
                        step = random.choice(self.scenarios).get_weighted_step()
                    else:
                        step = {'method': 'GET', 'endpoint': '/health', 'request_builder': lambda: {}}
                    
                    # 构建请求
                    request_data = step['request_builder']()
                    
                    # 执行请求
                    if self.tester:
                        result = self.tester.make_request(step['method'], step['endpoint'], **request_data)
                        self.result.add_request_result(result)
                    
                    # 思考时间
                    think_time = random.uniform(self.config.think_time_min, self.config.think_time_max)
                    time.sleep(think_time)
                    
                except Exception as e:
                    error_result = RequestResult(
                        timestamp=time.time(),
                        response_time=0,
                        status_code=0,
                        success=False,
                        error_message=str(e)
                    )
                    self.result.add_request_result(error_result)
        
        return user_session
    
    def run_sync_test(self) -> LoadTestResult:
        """运行同步负载测试"""
        self.result.start_timestamp = time.time()
        self.is_running = True
        
        # 预热阶段
        print("Starting warmup phase...")
        self._run_warmup()
        
        # 渐进加载阶段
        print("Starting ramp-up phase...")
        self._run_ramp_up()
        
        # 稳定负载阶段
        print("Starting steady load phase...")
        self._run_steady_load()
        
        self.result.end_timestamp = time.time()
        self.result.finalize_metrics()
        self.is_running = False
        
        return self.result
    
    def _run_warmup(self):
        """运行预热阶段"""
        warmup_end_time = time.time() + self.config.warmup_duration
        warmup_tester = HttpLoadTester(self.tester.base_url if self.tester else "http://localhost:8080")
        
        with ThreadPoolExecutor(max_workers=min(10, self.config.concurrent_users)) as executor:
            futures = []
            
            while time.time() < warmup_end_time and self.is_running:
                if len(futures) < self.config.concurrent_users:
                    future = executor.submit(warmup_tester.make_request, 'GET', '/health')
                    futures.append(future)
                
                # 检查完成的任务
                completed = [f for f in futures if f.done()]
                for future in completed:
                    try:
                        result = future.result()
                        # 预热阶段的结果不计入正式测试
                    except Exception:
                        pass
                    futures.remove(future)
                
                time.sleep(0.1)
    
    def _run_ramp_up(self):
        """运行渐进加载阶段"""
        ramp_up_end_time = time.time() + self.config.ramp_up_time
        target_users = self.config.concurrent_users
        
        with ThreadPoolExecutor(max_workers=target_users) as executor:
            user_sessions = []
            
            # 逐步增加用户数
            while time.time() < ramp_up_end_time and self.is_running:
                progress = (time.time() - (ramp_up_end_time - self.config.ramp_up_time)) / self.config.ramp_up_time
                current_users = int(target_users * progress)
                
                # 启动新用户
                while len(user_sessions) < current_users and len(user_sessions) < target_users:
                    future = executor.submit(self._create_user_session())
                    user_sessions.append(future)
                    with self.lock:
                        self.active_users += 1
                
                time.sleep(1)
    
    def _run_steady_load(self):
        """运行稳定负载阶段"""
        steady_end_time = time.time() + (self.config.test_duration - self.config.warmup_duration - self.config.ramp_up_time)
        
        with ThreadPoolExecutor(max_workers=self.config.concurrent_users) as executor:
            futures = []
            
            # 启动所有用户
            for _ in range(self.config.concurrent_users):
                future = executor.submit(self._create_user_session())
                futures.append(future)
            
            # 监控执行情况
            while time.time() < steady_end_time and self.is_running:
                completed_futures = [f for f in futures if f.done()]
                
                for future in completed_futures:
                    try:
                        future.result()  # 等待用户会话完成
                    except Exception as e:
                        print(f"User session error: {e}")
                
                futures = [f for f in futures if not f.done()]
                
                # 如果所有用户会话都完成了，重新启动
                if not futures:
                    for _ in range(self.config.concurrent_users):
                        future = executor.submit(self._create_user_session())
                        futures.append(future)
                
                time.sleep(1)

class AsyncLoadTestEngine:
    """异步负载测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.tester = None
        self.scenarios = []
        self.result = LoadTestResult(config)
        self.is_running = False
    
    async def run_async_test(self) -> LoadTestResult:
        """运行异步负载测试"""
        self.result.start_timestamp = time.time()
        self.is_running = True
        
        # 预热阶段
        print("Starting async warmup phase...")
        await self._run_async_warmup()
        
        # 稳定负载阶段
        print("Starting async steady load phase...")
        await self._run_async_steady_load()
        
        self.result.end_timestamp = time.time()
        self.result.finalize_metrics()
        self.is_running = False
        
        return self.result
    
    async def _run_async_warmup(self):
        """异步预热"""
        warmup_end_time = time.time() + self.config.warmup_duration
        
        async with AsyncLoadTester("http://localhost:8080") as tester:
            tasks = []
            
            while time.time() < warmup_end_time and self.is_running:
                if len(tasks) < 50:  # 限制并发预热请求数
                    task = asyncio.create_task(
                        tester.make_request('GET', '/health')
                    )
                    tasks.append(task)
                
                # 检查完成的任务
                done_tasks = [t for t in tasks if t.done()]
                for task in done_tasks:
                    try:
                        await task  # 预热结果不计入正式测试
                    except Exception:
                        pass
                    tasks.remove(task)
                
                await asyncio.sleep(0.1)
    
    async def _run_async_steady_load(self):
        """异步稳定负载"""
        test_end_time = time.time() + (self.config.test_duration - self.config.warmup_duration)
        
        async with AsyncLoadTester("http://localhost:8080") as tester:
            self.tester = tester
            
            # 创建用户任务
            user_tasks = []
            for _ in range(self.config.concurrent_users):
                task = asyncio.create_task(self._run_user_session())
                user_tasks.append(task)
            
            # 等待测试完成
            await asyncio.gather(*user_tasks, return_exceptions=True)
    
    async def _run_user_session(self):
        """运行用户会话"""
        session_start = time.time()
        
        while self.is_running and (time.time() - session_start) < self.config.test_duration:
            try:
                # 选择测试场景
                if self.scenarios:
                    step = random.choice(self.scenarios).get_weighted_step()
                else:
                    step = {'method': 'GET', 'endpoint': '/health', 'request_builder': lambda: {}}
                
                # 构建请求
                request_data = step['request_builder']()
                
                # 执行异步请求
                result = await self.tester.make_request(step['method'], step['endpoint'], **request_data)
                self.result.add_request_result(result)
                
                # 思考时间
                think_time = random.uniform(self.config.think_time_min, self.config.think_time_max)
                await asyncio.sleep(think_time)
                
            except Exception as e:
                error_result = RequestResult(
                    timestamp=time.time(),
                    response_time=0,
                    status_code=0,
                    success=False,
                    error_message=str(e)
                )
                self.result.add_request_result(error_result)
```

## 2. 高级负载测试模式

### 峰值测试
```python
class SpikeTestEngine(LoadTestEngine):
    """峰值测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        super().__init__(config)
        self.spike_patterns = []
    
    def add_spike_pattern(self, duration: int, target_rps: int, pattern_type: str = "linear"):
        """添加峰值模式"""
        self.spike_patterns.append({
            'duration': duration,
            'target_rps': target_rps,
            'pattern_type': pattern_type
        })
    
    def run_spike_test(self) -> LoadTestResult:
        """运行峰值测试"""
        self.result.start_timestamp = time.time()
        self.is_running = True
        
        total_duration = sum(pattern['duration'] for pattern in self.spike_patterns)
        current_time = 0
        
        with ThreadPoolExecutor(max_workers=100) as executor:
            for pattern in self.spike_patterns:
                pattern_end_time = time.time() + pattern['duration']
                
                print(f"Running spike pattern: {pattern['target_rps']} RPS for {pattern['duration']} seconds")
                
                # 根据目标RPS计算需要的线程数
                target_threads = min(pattern['target_rps'], 100)
                
                futures = []
                while time.time() < pattern_end_time and self.is_running:
                    # 维持目标RPS
                    current_rps = self._calculate_current_rps()
                    
                    if current_rps < pattern['target_rps']:
                        # 启动新线程
                        if len(futures) < target_threads:
                            future = executor.submit(self._create_user_session())
                            futures.append(future)
                    
                    # 清理完成的线程
                    completed_futures = [f for f in futures if f.done()]
                    for future in completed_futures:
                        futures.remove(future)
                    
                    time.sleep(0.1)
        
        self.result.end_timestamp = time.time()
        self.result.finalize_metrics()
        self.is_running = False
        
        return self.result
    
    def _calculate_current_rps(self) -> float:
        """计算当前RPS"""
        # 在实际实现中，这里需要从性能计数器中获取当前的RPS
        # 简化实现，返回估算值
        recent_requests = [r for r in self.result.request_results 
                          if time.time() - r.timestamp < 1]
        return len(recent_requests)

class StressTestEngine(LoadTestEngine):
    """压力测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        super().__init__(config)
        self.max_rps = config.target_rps
        self.step_size = max(10, self.max_rps // 10)
        self.stability_threshold = 60  # 稳定阈值（秒）
    
    def run_stress_test(self) -> LoadTestResult:
        """运行压力测试"""
        self.result.start_timestamp = time.time()
        self.is_running = True
        
        current_rps = self.step_size
        stability_start = None
        
        while current_rps <= self.max_rps and self.is_running:
            print(f"Testing at {current_rps} RPS...")
            
            # 在当前RPS下运行测试
            test_result = self._run_stress_step(current_rps, 60)  # 每步测试60秒
            
            # 分析结果
            if test_result.metrics.error_rate > self.config.error_rate_threshold:
                print(f"Breaking at {current_rps} RPS due to high error rate: {test_result.metrics.error_rate}")
                break
            
            if test_result.metrics.p95_response_time > self.config.max_response_time:
                print(f"Breaking at {current_rps} RPS due to high response time: {test_result.metrics.p95_response_time}")
                break
            
            # 检查稳定性
            if test_result.metrics.error_rate < 0.001 and test_result.metrics.p95_response_time < self.config.max_response_time * 0.5:
                if stability_start is None:
                    stability_start = time.time()
                elif time.time() - stability_start > self.stability_threshold:
                    print(f"System stable at {current_rps} RPS")
                    break
            else:
                stability_start = None
            
            current_rps += self.step_size
        
        self.result.end_timestamp = time.time()
        self.result.finalize_metrics()
        self.is_running = False
        
        return self.result
    
    def _run_stress_step(self, target_rps: int, duration: int) -> LoadTestResult:
        """运行压力测试步骤"""
        step_result = LoadTestResult(self.config)
        step_result.start_timestamp = time.time()
        
        with ThreadPoolExecutor(max_workers=min(target_rps, 100)) as executor:
            futures = []
            step_end_time = time.time() + duration
            
            while time.time() < step_end_time and self.is_running:
                # 维持目标RPS
                current_requests_in_second = len([r for r in step_result.request_results 
                                                 if time.time() - r.timestamp < 1])
                
                if current_requests_in_second < target_rps and len(futures) < 100:
                    future = executor.submit(self._create_stress_request())
                    futures.append(future)
                
                # 处理完成的请求
                completed_futures = [f for f in futures if f.done()]
                for future in completed_futures:
                    try:
                        result = future.result()
                        step_result.add_request_result(result)
                    except Exception as e:
                        error_result = RequestResult(
                            timestamp=time.time(),
                            response_time=0,
                            status_code=0,
                            success=False,
                            error_message=str(e)
                        )
                        step_result.add_request_result(error_result)
                    futures.remove(future)
                
                time.sleep(0.01)
        
        step_result.end_timestamp = time.time()
        step_result.finalize_metrics()
        
        # 合并到主结果中
        for result in step_result.request_results:
            self.result.add_request_result(result)
        
        return step_result
    
    def _create_stress_request(self) -> RequestResult:
        """创建压力测试请求"""
        if self.tester:
            return self.tester.make_request('GET', '/health')
        else:
            # 模拟请求
            start_time = time.time()
            time.sleep(random.uniform(0.01, 0.1))  # 模拟处理时间
            response_time = time.time() - start_time
            
            return RequestResult(
                timestamp=start_time,
                response_time=response_time,
                status_code=200,
                success=True
            )
```

### 容量测试
```python
class VolumeTestEngine(LoadTestEngine):
    """容量测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        super().__init__(config)
        self.data_sizes = [1000, 10000, 100000, 1000000]  # 数据量级别
        self.current_data_level = 0
    
    def run_volume_test(self, data_generator: Callable[[int], List[Dict]]) -> Dict:
        """运行容量测试"""
        results = {}
        
        for data_size in self.data_sizes:
            print(f"Testing with {data_size} records...")
            
            # 生成测试数据
            test_data = data_generator(data_size)
            
            # 运行写入测试
            write_result = self._run_write_test(test_data)
            
            # 运行读取测试
            read_result = self._run_read_test(data_size)
            
            results[data_size] = {
                'write_metrics': write_result.generate_report(),
                'read_metrics': read_result.generate_report()
            }
        
        return results
    
    def _run_write_test(self, test_data: List[Dict]) -> LoadTestResult:
        """运行写入测试"""
        write_config = LoadTestConfig(
            test_type=LoadTestType.VOLUME_TEST,
            target_rps=50,  # 写入通常较慢
            test_duration=300,
            concurrent_users=10
        )
        
        engine = LoadTestEngine(write_config)
        
        # 创建写入场景
        write_scenario = LoadTestScenario("write_scenario")
        write_scenario.add_step('POST', '/api/data', request_builder=lambda: {'json': random.choice(test_data)})
        
        engine.add_scenario(write_scenario)
        engine.tester = self.tester
        
        return engine.run_sync_test()
    
    def _run_read_test(self, data_size: int) -> LoadTestResult:
        """运行读取测试"""
        read_config = LoadTestConfig(
            test_type=LoadTestType.VOLUME_TEST,
            target_rps=200,  # 读取通常较快
            test_duration=300,
            concurrent_users=20
        )
        
        engine = LoadTestEngine(read_config)
        
        # 创建读取场景
        read_scenario = LoadTestScenario("read_scenario")
        read_scenario.add_step('GET', f'/api/data/{random.randint(1, data_size)}')
        
        engine.add_scenario(read_scenario)
        engine.tester = self.tester
        
        return engine.run_sync_test()
```

### 耐久性测试
```python
class EnduranceTestEngine:
    """耐久性测试引擎"""
    
    def __init__(self, config: LoadTestConfig):
        self.config = config
        self.result = LoadTestResult(config)
        self.is_running = False
        self.performance_samples = []
        self.memory_samples = []
        self.cpu_samples = []
    
    def run_endurance_test(self, duration_hours: int = 24) -> Dict:
        """运行耐久性测试"""
        test_duration_seconds = duration_hours * 3600
        self.result.start_timestamp = time.time()
        self.is_running = True
        
        print(f"Starting endurance test for {duration_hours} hours...")
        
        # 创建负载生成器
        load_generator = LoadTestEngine(self.config)
        
        # 启动监控线程
        monitor_thread = threading.Thread(target=self._monitor_system_resources, daemon=True)
        monitor_thread.start()
        
        try:
            # 运行长时间负载测试
            load_thread = threading.Thread(target=load_generator.run_sync_test, daemon=True)
            load_thread.start()
            
            # 等待测试完成
            load_thread.join(timeout=test_duration_seconds)
            
        except KeyboardInterrupt:
            print("Endurance test interrupted by user")
        
        finally:
            self.is_running = False
            self.result.end_timestamp = time.time()
            self.result.finalize_metrics()
        
        return self._generate_endurance_report()
    
    def _monitor_system_resources(self):
        """监控系统资源"""
        import psutil
        
        while self.is_running:
            try:
                # 收集系统指标
                self.cpu_samples.append({
                    'timestamp': time.time(),
                    'cpu_percent': psutil.cpu_percent(),
                    'memory_percent': psutil.virtual_memory().percent
                })
                
                # 保持样本数量在合理范围
                if len(self.cpu_samples) > 1000:
                    self.cpu_samples = self.cpu_samples[-500:]
                
                time.sleep(10)  # 每10秒采样一次
                
            except Exception as e:
                print(f"Resource monitoring error: {e}")
                break
    
    def _generate_endurance_report(self) -> Dict:
        """生成耐久性测试报告"""
        test_duration = self.result.end_timestamp - self.result.start_timestamp
        hours = test_duration / 3600
        
        # 计算系统资源统计
        if self.cpu_samples:
            cpu_usage = [sample['cpu_percent'] for sample in self.cpu_samples]
            memory_usage = [sample['memory_percent'] for sample in self.cpu_samples]
            
            cpu_stats = {
                'avg_cpu': sum(cpu_usage) / len(cpu_usage),
                'max_cpu': max(cpu_usage),
                'min_cpu': min(cpu_usage)
            }
            
            memory_stats = {
                'avg_memory': sum(memory_usage) / len(memory_usage),
                'max_memory': max(memory_usage),
                'min_memory': min(memory_usage)
            }
        else:
            cpu_stats = memory_stats = {}
        
        return {
            'test_duration_hours': round(hours, 2),
            'performance_metrics': self.result.generate_report(),
            'system_resources': {
                'cpu_stats': cpu_stats,
                'memory_stats': memory_stats
            },
            'test_stability': self._analyze_stability(),
            'recommendations': self._generate_recommendations()
        }
    
    def _analyze_stability(self) -> Dict:
        """分析测试稳定性"""
        if len(self.result.response_times) < 100:
            return {'stability_score': 0, 'analysis': 'Insufficient data'}
        
        # 计算性能漂移
        window_size = 100
        windows = [self.result.response_times[i:i+window_size] 
                  for i in range(0, len(self.result.response_times) - window_size, window_size//2)]
        
        window_avgs = [sum(window)/len(window) for window in windows]
        
        # 计算平均值的变化
        if len(window_avgs) > 1:
            max_variation = max(window_avgs) - min(window_avgs)
            avg_response_time = sum(self.result.response_times) / len(self.result.response_times)
            stability_score = max(0, 100 - (max_variation / avg_response_time) * 100)
        else:
            stability_score = 100
        
        return {
            'stability_score': round(stability_score, 2),
            'performance_drift': round(max_variation, 3) if 'max_variation' in locals() else 0,
            'analysis': 'Stable' if stability_score > 80 else 'Unstable'
        }
    
    def _generate_recommendations(self) -> List[str]:
        """生成优化建议"""
        recommendations = []
        
        # 基于错误率的建议
        if self.result.metrics.error_rate > 0.01:
            recommendations.append("High error rate detected. Check system stability and error handling.")
        
        # 基于响应时间的建议
        if self.result.metrics.p95_response_time > self.config.max_response_time:
            recommendations.append("High P95 response time. Consider performance optimization.")
        
        # 基于系统资源的建议
        if self.cpu_samples:
            avg_cpu = sum(sample['cpu_percent'] for sample in self.cpu_samples) / len(self.cpu_samples)
            avg_memory = sum(sample['memory_percent'] for sample in self.cpu_samples) / len(self.cpu_samples)
            
            if avg_cpu > 80:
                recommendations.append("High CPU usage detected. Consider scaling up or optimizing algorithms.")
            
            if avg_memory > 80:
                recommendations.append("High memory usage detected. Check for memory leaks and optimize data structures.")
        
        return recommendations
```

## 3. 负载测试报告和分析

### 测试结果分析
```python
class LoadTestAnalyzer:
    """负载测试结果分析器"""
    
    def __init__(self):
        self.thresholds = {
            'response_time_p95': 2.0,
            'response_time_p99': 5.0,
            'error_rate': 0.01,
            'availability': 0.999
        }
    
    def analyze_test_results(self, results: List[Dict]) -> Dict:
        """分析多个测试结果"""
        analysis = {
            'summary': self._generate_summary(results),
            'performance_trends': self._analyze_performance_trends(results),
            'bottlenecks': self._identify_bottlenecks(results),
            'recommendations': self._generate_recommendations(results),
            'comparative_analysis': self._comparative_analysis(results)
        }
        
        return analysis
    
    def _generate_summary(self, results: List[Dict]) -> Dict:
        """生成测试摘要"""
        total_tests = len(results)
        passed_tests = sum(1 for result in results if result.get('test_passed', False))
        
        avg_rps = sum(result['metrics']['rps'] for result in results) / total_tests
        avg_error_rate = sum(result['metrics']['error_rate'] for result in results) / total_tests
        avg_p95_response_time = sum(result['metrics']['p95_response_time'] for result in results) / total_tests
        
        return {
            'total_tests': total_tests,
            'passed_tests': passed_tests,
            'failed_tests': total_tests - passed_tests,
            'success_rate': passed_tests / total_tests,
            'average_metrics': {
                'rps': round(avg_rps, 2),
                'error_rate': round(avg_error_rate, 4),
                'p95_response_time': round(avg_p95_response_time, 3)
            }
        }
    
    def _analyze_performance_trends(self, results: List[Dict]) -> Dict:
        """分析性能趋势"""
        if len(results) < 2:
            return {'trend': 'insufficient_data', 'change_percent': 0}
        
        # 按测试时间排序
        sorted_results = sorted(results, key=lambda x: x.get('start_time', 0))
        
        # 计算性能变化
        first_rps = sorted_results[0]['metrics']['rps']
        last_rps = sorted_results[-1]['metrics']['rps']
        
        rps_change = ((last_rps - first_rps) / first_rps) * 100 if first_rps > 0 else 0
        
        first_error_rate = sorted_results[0]['metrics']['error_rate']
        last_error_rate = sorted_results[-1]['metrics']['error_rate']
        
        error_rate_change = ((last_error_rate - first_error_rate) / first_error_rate) * 100 if first_error_rate > 0 else 0
        
        return {
            'rps_trend': 'improving' if rps_change > 5 else 'degrading' if rps_change < -5 else 'stable',
            'rps_change_percent': round(rps_change, 2),
            'error_rate_trend': 'improving' if error_rate_change < -5 else 'degrading' if error_rate_change > 5 else 'stable',
            'error_rate_change_percent': round(error_rate_change, 2)
        }
    
    def _identify_bottlenecks(self, results: List[Dict]) -> List[Dict]:
        """识别性能瓶颈"""
        bottlenecks = []
        
        for i, result in enumerate(results):
            metrics = result['metrics']
            
            # 检查响应时间瓶颈
            if metrics['p95_response_time'] > self.thresholds['response_time_p95']:
                bottlenecks.append({
                    'test_index': i,
                    'type': 'response_time',
                    'severity': 'high' if metrics['p95_response_time'] > self.thresholds['response_time_p99'] else 'medium',
                    'description': f"P95 response time {metrics['p95_response_time']}s exceeds threshold",
                    'value': metrics['p95_response_time'],
                    'threshold': self.thresholds['response_time_p95']
                })
            
            # 检查错误率瓶颈
            if metrics['error_rate'] > self.thresholds['error_rate']:
                bottlenecks.append({
                    'test_index': i,
                    'type': 'error_rate',
                    'severity': 'high' if metrics['error_rate'] > self.thresholds['error_rate'] * 2 else 'medium',
                    'description': f"Error rate {metrics['error_rate']:.4f} exceeds threshold",
                    'value': metrics['error_rate'],
                    'threshold': self.thresholds['error_rate']
                })
            
            # 检查可用性瓶颈
            availability = 1 - metrics['error_rate']
            if availability < self.thresholds['availability']:
                bottlenecks.append({
                    'test_index': i,
                    'type': 'availability',
                    'severity': 'high',
                    'description': f"Availability {availability:.4f} below threshold",
                    'value': availability,
                    'threshold': self.thresholds['availability']
                })
        
        return bottlenecks
    
    def _generate_recommendations(self, results: List[Dict]) -> List[str]:
        """生成优化建议"""
        recommendations = []
        
        # 基于瓶颈分析的建议
        bottlenecks = self._identify_bottlenecks(results)
        
        response_time_bottlenecks = [b for b in bottlenecks if b['type'] == 'response_time']
        if response_time_bottlenecks:
            recommendations.append("Address response time issues by optimizing database queries, implementing caching, or scaling horizontally.")
        
        error_rate_bottlenecks = [b for b in bottlenecks if b['type'] == 'error_rate']
        if error_rate_bottlenecks:
            recommendations.append("Investigate and resolve error sources. Check system logs, improve error handling, and verify external dependencies.")
        
        # 基于性能趋势的建议
        trends = self._analyze_performance_trends(results)
        if trends['rps_trend'] == 'degrading':
            recommendations.append("Performance is degrading over time. Consider investigating memory leaks or resource exhaustion.")
        
        if trends['error_rate_trend'] == 'degrading':
            recommendations.append("Error rate is increasing. System may be approaching its limits or experiencing degradation.")
        
        # 基于整体指标的建议
        avg_metrics = sum(results, key=lambda x: x['metrics'])['average_metrics']
        
        if avg_metrics['error_rate'] > 0.005:
            recommendations.append("Overall error rate is high. Implement circuit breakers, improve resilience patterns, and add monitoring.")
        
        if avg_metrics['p95_response_time'] > 1.0:
            recommendations.append("Response times are elevated. Consider performance profiling, database optimization, and infrastructure scaling.")
        
        return recommendations
    
    def _comparative_analysis(self, results: List[Dict]) -> Dict:
        """比较分析"""
        if len(results) < 2:
            return {'comparison': 'insufficient_data'}
        
        # 找出最佳和最差性能
        best_result = max(results, key=lambda x: x['metrics']['rps'])
        worst_result = min(results, key=lambda x: x['metrics']['rps'])
        
        return {
            'best_performance': {
                'index': results.index(best_result),
                'rps': best_result['metrics']['rps'],
                'error_rate': best_result['metrics']['error_rate']
            },
            'worst_performance': {
                'index': results.index(worst_result),
                'rps': worst_result['metrics']['rps'],
                'error_rate': worst_result['metrics']['error_rate']
            },
            'performance_gap': {
                'rps_gap': best_result['metrics']['rps'] - worst_result['metrics']['rps'],
                'error_rate_gap': worst_result['metrics']['error_rate'] - best_result['metrics']['error_rate']
            }
        }

class LoadTestReporter:
    """负载测试报告生成器"""
    
    def __init__(self, analyzer: LoadTestAnalyzer):
        self.analyzer = analyzer
    
    def generate_html_report(self, results: List[Dict], output_path: str):
        """生成HTML报告"""
        analysis = self.analyzer.analyze_test_results(results)
        
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Load Test Report</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ background-color: #f0f0f0; padding: 20px; border-radius: 5px; }}
                .metric {{ display: inline-block; margin: 10px; padding: 15px; background-color: #e0e0e0; border-radius: 5px; }}
                .bottleneck {{ color: red; font-weight: bold; }}
                .recommendation {{ background-color: #fffacd; padding: 10px; margin: 5px 0; border-radius: 3px; }}
                table {{ border-collapse: collapse; width: 100%; }}
                th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>Load Test Report</h1>
                <p>Generated at: {time.strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
            
            <h2>Summary</h2>
            <div class="metric">Total Tests: {analysis['summary']['total_tests']}</div>
            <div class="metric">Success Rate: {analysis['summary']['success_rate']:.2%}</div>
            <div class="metric">Average RPS: {analysis['summary']['average_metrics']['rps']}</div>
            
            <h2>Performance Trends</h2>
            <p>RPS Trend: {analysis['performance_trends']['rps_trend']} ({analysis['performance_trends']['rps_change_percent']:+.2f}%)</p>
            <p>Error Rate Trend: {analysis['performance_trends']['error_rate_trend']}</p>
            
            <h2>Bottlenecks</h2>
            {"".join([f'<div class="bottleneck">{b["description"]}</div>' for b in analysis['bottlenecks']])}
            
            <h2>Recommendations</h2>
            {"".join([f'<div class="recommendation">{rec}</div>' for rec in analysis['recommendations']])}
            
            <h2>Detailed Results</h2>
            <table>
                <tr>
                    <th>Test Index</th>
                    <th>RPS</th>
                    <th>Error Rate</th>
                    <th>P95 Response Time</th>
                    <th>Status</th>
                </tr>
                {self._generate_result_table_rows(results)}
            </table>
        </body>
        </html>
        """
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
    
    def _generate_result_table_rows(self, results: List[Dict]) -> str:
        """生成结果表格行"""
        rows = []
        for i, result in enumerate(results):
            status = "PASS" if result.get('test_passed', False) else "FAIL"
            status_color = "green" if result.get('test_passed', False) else "red"
            
            rows.append(f"""
                <tr>
                    <td>{i}</td>
                    <td>{result['metrics']['rps']}</td>
                    <td>{result['metrics']['error_rate']:.4f}</td>
                    <td>{result['metrics']['p95_response_time']:.3f}s</td>
                    <td style="color: {status_color};">{status}</td>
                </tr>
            """)
        
        return "".join(rows)
```

## 4. 负载测试最佳实践

### 测试准备
1. **环境准备**: 确保测试环境与生产环境相似
2. **数据准备**: 准备真实的测试数据集
3. **监控准备**: 部署性能监控和日志收集
4. **基线建立**: 建立性能基线和阈值标准

### 测试执行
1. **渐进测试**: 从低负载开始，逐步增加负载
2. **多轮测试**: 执行多轮测试以确保结果一致性
3. **长期监控**: 对于耐久性测试，进行长期监控
4. **错误分析**: 详细记录和分析错误信息

### 结果分析
1. **多维度分析**: 从响应时间、吞吐量、错误率等多个维度分析
2. **趋势分析**: 分析性能随时间的变化趋势
3. **瓶颈识别**: 准确识别系统瓶颈点
4. **可重现性**: 确保测试结果可重现

通过以上负载测试框架和实践，可以系统性地评估系统在不同负载条件下的性能表现，为系统优化和扩容决策提供可靠的数据支持。